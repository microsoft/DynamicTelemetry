{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"docs/","title":"Introduction","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/index.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/#dynamic-telemetry","title":"Dynamic Telemetry","text":"<p>Introducing DynamicTelemetry, an OpenSource, diagnostic compliment to OpenTelemetry.</p> <p>The DynamicTelemetry development team wants to make debugging highly scaled production software as easy and enjoyable as debugging one application locally. We want you to be able to diagnose and explore live production systems without compromising reliability, performance, or customer privacy.</p> <p>In this introduction, you will learn about DynamicTelemetry, an open-source diagnostic tool that blends traditional symbolic debuggers with advanced new complements to your existing OpenTelemetry assets and workflows. You will be presented with five architectural components that, when used together, bring the peace and calm of local debugging into the distributed cloud.</p> <p>Before diving into the overall architecture, let's watch a quick demonstration that will showcase the end-to-end workflow.</p> <p>In this high-level demonstration, we've added DynamicTelemetry to the standard OpenTelemetry Kubernetes sample but otherwise have not modified (or even recompiled) any code from the OpenTelemetry sample.</p> <p>After the demo, please 'choose your own adventure' by continuing to read along one of the five scenarios themes found below.</p>"},{"location":"docs/#scenarios","title":"Scenarios","text":"<ul> <li> <p> Performance and Diagnostics</p> <p>Disable diagnostic telemetry when systems are stable; enable it when they are not. Quickly trigger memory dumps or collect CPU samples during production issues. Deploy observers to monitor telemetry and gather extra diagnostic data, only when needed.</p> <p></p> </li> <li> <p> Privacy and Security</p> <p>Detect and immediately suppress sensitive (or expensive) fields within Logs, should they inadvertently contain sensitive information such as PATs, IP addresses, user information, or crypto keys. Remove these, at their source, instantly - without rebuild or redeploy.</p> </li> <li> <p> Reliability</p> <p>Test your services more effectively; make your Production code self diagnose. Couple the self diagnostics with Actions that toggle up and down telemetry volume, collect memory dumps, and CPU samples.</p> </li> <li> <p> Durability - Dashboards and Alerts</p> <p>Develop flexible schemas in your logs, metrics, and traces that enhance the durability of your dashboards and streamline communication between coworkers. Enable AI to find problems on your behalf.</p> </li> <li> <p> Cost Reduction</p> <p>Convert verbose logs into concise metrics, suppress large payloads, or drop unnecessary logs.</p> <p></p> </li> </ul>"},{"location":"docs/Applications.FlightRecorder.MemoryLeak.document/","title":"Applications.FlightRecorder.MemoryLeak.document","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Applications.FlightRecorder.MemoryLeak.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Applications.FlightRecorder.MemoryLeak.document/#interesting-application-flightrecorder-into-memory-leak","title":"Interesting Application : FlightRecorder into Memory Leak","text":""},{"location":"docs/Applications.FlightRecorder.MemoryLeak.document/#scenario-summary","title":"Scenario Summary","text":"<p>Even in managed languages, determining why memory is being consumed can be a complicated matter. We've all encountered a linked list that holds a pointer to memory and doesn't shrink as it should. While some may argue whether this constitutes a memory leak, the system inevitably starts to slow down and thrash as memory pressure exceeds the hardware's capabilities.</p> <p>A powerful use of a Flight Recorder is to track the insertion or deletion from such a list, or the add reference and release, or malloc() and free() operations in unmanaged languages.</p> <p>This is achieved either through standard logging or by inserting a dynamic probe on the malloc() and free() calls.</p> <p>By using a probe that indicates the amount of memory load on a machine, coupled with an action to collect this type of memory Flight Recorder, a developer can obtain a high-fidelity glimpse into the machine's memory usage over a long duration without negatively impacting performance.</p> <p>Best of all, once the project is complete and the memory leak is understood, dynamic telemetry can disable all of this logging, including the flight recorder, allowing the machines to operate at high speed.</p>"},{"location":"docs/Applications.FlightRecorder.MemoryLeak.document/#scenario-expansion","title":"Scenario Expansion","text":""},{"location":"docs/Applications.FlightRecorder.PriorToCrash.document/","title":"Applications.FlightRecorder.PriorToCrash.document","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Applications.FlightRecorder.PriorToCrash.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Applications.FlightRecorder.PriorToCrash.document/#interesting-application-flightrecorder-into-memory-dump","title":"Interesting Application : FlightRecorder into Memory Dump","text":""},{"location":"docs/Applications.FlightRecorder.PriorToCrash.document/#scenario-summary","title":"Scenario Summary","text":"<p>Imagine a long-running Flight Recorder that collects 100 times the logging that would normally stream through something similar to OpenTelemetry.</p> <p>This logging would be very verbose, containing information like function entry and exit, web requests, queue lengths, open file pointers, file indexes, and so on.</p> <p>Normally, this type of information would clutter up a backend database and be useless in most contexts.</p> <p>However, when collected during a process crash, this information is sufficiently inexpensive and can significantly boost productivity.</p> <p>A Flight Recorder like this is not free; the logs will have to go into a circular buffer, which does cause CPU load. But when done well, for example, using something similar to ETW or user events on Linux, this CPU load can be very inexpensive compared to other techniques.</p> <p>When the process crashes, this log can be collected and will serve as a set of breadcrumbs leading to that process crash.</p> <p>Pretty fantastic.</p> <p>This approach also has a positive impact on the developer's mindset. Developers often struggle with the need to suppress logging messages due to cost, security, and privacy concerns imposed by business and finance teams.</p> <p>With the availability of Flight Recorders, developers can feel reassured. Knowing that in the event of a process crash, they will have access to the critical logs leading up to the incident, alleviates their concerns and allows them to focus on more productive tasks.</p>"},{"location":"docs/Applications.FlightRecorder.PriorToCrash.document/#scenario-expansion","title":"Scenario Expansion","text":""},{"location":"docs/Applications.InterestingApplications.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Applications.InterestingApplications.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Applications.InterestingApplications.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Applications.Overview.InterestingApplications.document/","title":"Applications.Overview.InterestingApplications.document","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Applications.Overview.InterestingApplications.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.CPUSample.document/","title":"CPUSample","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.CPUSample.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.CPUSample.document/#cpu-sampling-coming-soon","title":"CPU Sampling : COMING SOON","text":""},{"location":"docs/Architecture.Action.ConfigCollection.document/","title":"ConfigCollection","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.ConfigCollection.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.ConfigCollection.document/#configuration-collection-coming-soon","title":"Configuration Collection : COMING SOON","text":""},{"location":"docs/Architecture.Action.Explanation.document/","title":"Action Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.Explanation.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.Explanation.document/#understanding-actions","title":"Understanding Actions","text":"<p>Understanding an action in Dynamic Telemetry is crucial for grasping its workflows. An action involves diagnostic operations that do not alter system state and can be dynamically enabled or disabled using a provided program.</p> <p>Unlike mitigation actions, these do not modify system state.</p> <p>Examples of actions unsuitable for Dynamic Telemetry include restarting a service, rebooting a machine, writing to a file, or changing a config setting.</p> <p>Suitable actions might involve enabling CPU sampling, which could impact performance but doesn't intentionally modify system state.</p> <p>The following sections will discuss sample actions within the scope of Dynamic Telemetry, such as collecting configurations, enabling CPU sampling, managing Flight Recorders, inducing memory dumps, and collecting other state types.</p>"},{"location":"docs/Architecture.Action.FileCollection.document/","title":"FileCollection","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.FileCollection.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.FileCollection.document/#file-collections-coming-soon","title":"File Collections : COMING SOON","text":""},{"location":"docs/Architecture.Action.FlightRecorder.document/","title":"FlightRecorder","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.FlightRecorder.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.FlightRecorder.document/#flight-recorder-action-start-stop-coming-soon","title":"Flight Recorder Action (Start / Stop) - COMING SOON","text":"<ol> <li>Create a Flight Recorder, with an identifier</li> <li>Describe the Logs that should be recorded</li> </ol>"},{"location":"docs/Architecture.Action.MemoryDump.document/","title":"MemoryDump","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.MemoryDump.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.MemoryDump.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.Action.PacketCapture.document/","title":"PacketCapture","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.PacketCapture.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.PacketCapture.document/#coming-soon-packet-capture-action","title":"Coming Soon : Packet Capture Action","text":""},{"location":"docs/Architecture.Action.ProcessExecution.document/","title":"ProcessExecution","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.ProcessExecution.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.ProcessExecution.document/#process-executionlaunch-coming-soon","title":"Process Execution/Launch : COMING SOON","text":""},{"location":"docs/Architecture.Action.StateCollection.document/","title":"StateCollection","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.StateCollection.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.StateCollection.document/#state-collection-coming-soon","title":"State Collection : COMING SOON","text":""},{"location":"docs/Architecture.Action.VerboseLogs.document/","title":"Verbose Logs","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Action.VerboseLogs.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Action.VerboseLogs.document/#verbose-logs-coming-soon","title":"Verbose Logs : COMING SOON","text":""},{"location":"docs/Architecture.Components.FileBased.Observability.document/","title":"File Based","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.FileBased.Observability.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.FileBased.Observability.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.Components.FiltersAndRouters.document/","title":"Filters / Routers Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.FiltersAndRouters.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.FiltersAndRouters.document/#filters-and-routers","title":"Filters and Routers","text":"<ol> <li>Drops Logs, based on Durable ID</li> <li>Routes Logs into Flight Recorders</li> <li>Can be identified; controllable by Actions</li> <li>Toggles on and off both routes and drops - based on Actions</li> </ol>"},{"location":"docs/Architecture.Components.Observer.External.OffBox.document/","title":"External, off-box Observer","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Observer.External.OffBox.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Observer.External.OffBox.document/#offbox-processor-coming-soon","title":"Offbox Processor Coming Soon","text":"<p>This processor has a unique characteristic of being off-box and separate from the machine being monitored. This is likely the least risky location to start the migration of dynamic telemetry. It acts as a filter or data shaper. Because it simply morphs telemetry after being produced, the machine producing it is unaware of its presence.</p> <p>For example, this is a good location for initial security or privacy scrubbing. Tokens would be emitted from the machine but dropped prior to being ingested into a database.</p>"},{"location":"docs/Architecture.Components.Observer.External.OnBox.document/","title":"External, on-box Observer","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Observer.External.OnBox.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Observer.External.OnBox.document/#onbox-observer-coming-soon","title":"OnBox Observer: Coming Soon","text":"<p>The processor runs in user mode on the machine being observed, but it is not in the kernel. This is the final protocol conversion between the kernel's telemetry system and the remote processor. In OpenTelemetry, the OLTP protocol is utilized; however, gRPC or other protocols may also be used.</p>"},{"location":"docs/Architecture.Components.Observer.InProcess.document/","title":"Internal Observer","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Observer.InProcess.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Observer.InProcess.document/#in-process-observer-coming-soon","title":"In Process Observer: Coming Soon","text":"<p>In summary, this document will explain that a dynamic telemetry processor can be inserted into the process emitting content. This insertion occurs in such a way that it is intercepted before entering the kernel of the machine being observed.</p>"},{"location":"docs/Architecture.Components.Observer.Kernel.document/","title":"Kernel Observer","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Observer.Kernel.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Observer.Kernel.document/#kernel-observer-coming-soon","title":"Kernel Observer: Coming Soon","text":"<p>This observer runs in the kernel of a monitored machine. It accepts telemetry from multiple processes or services within the same machine and has the unique ability to drop and modify telemetry data. This is done with the scope of the entire user mode of the machine.</p> <p>This is an excellent location for Flight Recorders.</p>"},{"location":"docs/Architecture.Components.Processor.Language/","title":"Language","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Processor.Language.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Processor.Language/#processor-language","title":"Processor : Language","text":"<p>The Language Processor is one of the most versatile and capable Processors within Dynamic Telemetry; however, it also poses certain risks. The language Processor in Dynamic Telemetry enables the insertion of programming language into the telemetry and logging stream of a process. These instructions will have the full functionality of the supporting programming language and runtime.</p>"},{"location":"docs/Architecture.Components.Processor.Language/#introduction-to-language-processor","title":"Introduction to Language Processor","text":"<p>By incorporating a programming model into a telemetry stream, advanced observability and diagnostics can be achieved. For example, memory variables can be created, aggregates can be managed, individual threads can be monitored, and references can be tracked.</p> <p>Additionally, complex triggering scenarios can be established, such as capturing a memory dump of a process when a reference count exceeds nominal and expected values.</p>"},{"location":"docs/Architecture.Components.Processor.Language/#simple-code-example-hashing-files","title":"Simple Code Example; hashing files","text":"<pre><code>public string HashFile(string imageName)\n{\n    try\n    {\n        // 1. Log the start of the hashing process\n        LogStartingFileHash(m_logger, imageName);\n\n        // 2. Open the file and hash it\n        using (FileStream fileStream = File.OpenRead(imageName))\n        {\n            string hashValue = Convert.ToBase64String(m_SHA256.ComputeHash(fileStream));\n\n            // 3. Log the end of the hashing process\n            LogEndFileHash(m_logger, imageName, hashValue);\n            return hashValue;\n        }\n    }\n    catch (Exception e)\n    {\n        // Log any exceptions that occur\n        ErrorHashing(m_logger, imageName, e);\n        throw;\n    }\n}\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Starting FileHash {fileName}.\")]\nstatic partial void LogStartingFileHash(ILogger logger, string fileName);\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Ending FileHash {fileName}, hash={hashValue}.\")]\nstatic partial void LogEndFileHash(ILogger logger, string fileName, string hashValue);\n\n[LoggerMessage(Level = LogLevel.Warning, Message = \"Unable to hash image {fileName}\")]\nstatic partial void ErrorHashing(ILogger logger, string fileName, Exception e);\n</code></pre>"},{"location":"docs/Architecture.Components.Processor.Language/#sample-code-overview","title":"Sample Code Overview","text":"<p>In this example you'll notice that the example code</p> <ol> <li>Logs when we begin hashing</li> <li>Hashs the file; or otherwise perform business logic</li> <li>Logs when we've completed the hashing of the file</li> </ol> <p>This workflow outlines a typical sequence of operations for a developer. Log messages may be disabled before entering production, used during diagnostics, or employed to indicate failure and success in traditional testing.</p>"},{"location":"docs/Architecture.Components.Processor.Language/#modeling-live-system-behavior-with-a-language-processor","title":"Modeling Live System Behavior, with a Language Processor","text":"<p>In this scenario, where a file is being hashed, assume there is a bug in the hashing algorithm. For example, the implementation of the hashing algorithm might have race conditions or, in exceptional cases, memory misalignment. If one of these issues occurs, the hash for the input file will be incorrect, making it challenging to debug in a production system.</p> <p>A Dynamic Telemetry Language Processor could be particularly useful for advanced diagnostics and tracking of this faulty hashing algorithm.</p> <p>in this example one could imagine the pseudo code below being utilized in a randomized pattern and deployed using Dynamic Telemetry into a production environment as you can see in the pseudo code periodically the hash of a file will be doubly computed once in the production code and secondarily in the telemetry code</p> <p>when or if hash is detected to be incorrect the Dynamic Telemetry language Processor is able to emit extra to diagnostic telemetry that indicates to the programmer who is monitoring the back end databases that in fact the hashing algorithm is failing</p> <p>Lets look at a few examples, as they likely will help tell the tale</p> <p>Image a piece of code that looks something like this:</p> <pre><code>    flowchart TD\n        Unknown((Unknown))\n        HashingFile((HashingFile))\n        Unknown --&gt; | LogStartingFileHash | HashingFile\n        HashingFile--&gt; |LogEndFileHash | Unknown\n</code></pre>"},{"location":"docs/Architecture.Components.Processor.Language/#verifying-hash-algorithm","title":"Verifying Hash Algorithm","text":"<pre><code>void OnLog(LogMessage log)\n{\n    // Skip all logs, but the ending hash\n    if(log.LogId == \"LogEndFileHash\")\n    {\n        string hashGeneratedInProduction = log.GetValue(\"hashValue\");\n        string file = log.GetValue(\"fileName\");\n\n        string comparisonHash = GenerateVerificationHash(file);\n\n        if (hashGeneratedInProduction != comparisonHash)\n        {\n            m_Actions.GenerateNewLog(file, hashGeneratedInProduction, comparisonHash);\n        }\n    }\n}\n\n[LoggerMessage(Level = LogLevel.Error, Message = \"ERROR: Language Processor detected production hash bug {fileName}\")]\nstatic partial void ErrorInProductionHash(ILogger logger, string fileName, string productHash, string comparisonHash);\n</code></pre>"},{"location":"docs/Architecture.Components.Processor.Language/#introducing-actions-to-the-dynamic-telemetry-language-processor","title":"Introducing Actions to the Dynamic Telemetry Language Processor","text":""},{"location":"docs/Architecture.Components.Processor.Language/#useful-actions","title":"Useful Actions","text":"<ul> <li>CPU Sampling</li> <li>Verbose Logs</li> <li>Memory Dump</li> </ul>"},{"location":"docs/Architecture.Components.Processor.Language/#example-scenarios","title":"Example Scenarios","text":""},{"location":"docs/Architecture.Components.Processor.Overview.document/","title":"Processors Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Processor.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Processor.Overview.document/#processor","title":"Processor","text":"<p>A Dynamic Telemetry Processor is a small piece of software that resides in the OpenTelemetry data stream and reads telemetry as it passes. The Processor connects various architectural components, such as an action or a probe, enabling the transformation of a log into a metric, the removal of a log, or the removal of a field within a log.</p> <p>Dynamic Telemetry categorizes Processors into three distinct types, each with varying levels of complexity and associated risk. These types are a Language Processor, a Query Language Processor, and a State Machine Processor.</p> <p>Before delving into the differences among these three types, it is essential to discuss the four different locations that can house a query Processor.</p>"},{"location":"docs/Architecture.Components.Processor.Overview.document/#locations-in-opentelemetry-that-may-contain-a-processor","title":"Locations in OpenTelemetry that may contain a Processor","text":""},{"location":"docs/Architecture.Components.Processor.Overview.document/#processor-types","title":"Processor Types","text":"<p>It's expected within Dynamic Telemetry that multiple different Processor types are created over the course of time because there are requirements on the Processor in order to meet other obligations, such as safety and performance, all Processors must meet certain set of requirements, specifically in the event they are running out of specification they are all configured to automatically disable.</p> <p>There are three different types of Processors each with varying degrees of complexity first is a simple query language Processor where the durable identifier structure payloads are utilized to simply drop or simply transform a log message.</p> <p>The second is a state model Processor, which is similar to a query language Processor but introduces actions and probes. These capabilities include triggering CPU sampling, performing memory dumps, or temporarily toggling the verbosity of logging and sampling.</p> <p>The third component is a language Processor, which is the most complex of the three. A language Processor introduces scriptability or programming capabilities in line with the production of telemetry. Due to the requirements on the Processor (discussed further below), it is likely that language Processors will resemble something similar to eBPF. These Processors execute within a sandbox that restricts both the memory accessed and the number of instructions executed.</p>"},{"location":"docs/Architecture.Components.Processor.Overview.document/#query-language-processor","title":"Query Language Processor","text":"<p>A Query Language Processor is the simplest type of Processor. It acts as a filter that is applied directly to the OpenTelemetry data stream, allowing for straightforward transformations or the removal of specific log messages.</p> <p>As demonstrated in the example from our sample using the Kusto Query Language (KQL), we identify and drop an individual log message.</p> <pre><code>traces\n| where customDimensions.EventName != \"LogWelcomeBanner\"\n</code></pre> <p>In the example below, we are modifying the log message to drop a particular field.</p> <pre><code>traces\n| extend customDimensions = iif(customDimensions.EventName == \"LogWelcomeBanner\",\n    bag_remove_keys(customDimensions, dynamic(['secret'])), customDimensions)\n</code></pre> <p>By using your imagination, you can see many opportunities for this KQL language. For example, you could filter out logs that are not relevant to a specific analysis, transform log data to fit a particular schema, or even aggregate data to generate metrics on the fly.</p>"},{"location":"docs/Architecture.Components.Processor.Overview.document/#state-model-processor","title":"State Model Processor","text":"<p>A State Model Processor is our next most sophisticated and complex Processor. Similar to a Query Language Processor, the State Model Processor uses a simple configuration file. However, instead of merely providing filtering and aggregation, it allows for the construction of simple state machines that operate on the code as it runs.</p> <p>The State Model Processor also introduces the concept of probes and actions, which are discussed in further sections.</p> <p>Simple applications of a State Model Processor might include the dynamic enablement and disablement of verbose logs in specific situations. For example, when an error occurs, you may wish to enable higher volume telemetry for a period of five minutes.</p> <p>Other actions include the ability to capture a memory dump. For instance, you might capture a memory dump if a particular error is emitted in a log.</p>"},{"location":"docs/Architecture.Components.Processor.Overview.document/#language-processor","title":"Language Processor","text":"<p>The Language Processor is the most complex type of Processor. In addition to the ability to dynamically migrate state transitions, it introduces the capability to allocate small amounts of memory and perform simple computations and calculations.</p> <p>Like other Processors, the Language Processor is governed and managed according to the strict requirements found in Dynamic Telemetry. You can read more about the taxonomy that Dynamic Telemetry uses to classify and manage risks in this section of the documentation.</p> <p>Dynamic Telemetry proposes using a technology similar to eBPF, where a sandboxed virtual machine is employed to ensure performance and reliability guarantees.</p>"},{"location":"docs/Architecture.Components.Processor.Overview.document/#requirements-on-a-processor","title":"Requirements on a Processor","text":"<p>A Processor is more complicated than it may seem at first blush. Simply injecting code in line to a telemetry pipeline sounds great at first, but there can be real risks as described in the Observer Effect section of this documentation.</p> <p>In short, the Observer Effect is a reality where the act of observing a system can actually result in changes to the system, often with detrimental irony.</p> <p>To address this, a Processor must meet the following requirements:</p> <ol> <li>By design, it does not modify the system state.</li> <li>Each pillar in Probe Risk is    supported by a measurement mechanism.</li> <li>Each measurement is communicated to the user in a simple and understandable    manner.</li> <li>Each measurement has an upper bound or ceiling that is always enforced in    conjunction with the Processor.</li> <li>Should the upper bound be exceeded, the Processor will automatically disable.</li> </ol> <p>These requirements are serious and will influence how Dynamic Telemetry is used in practice.</p> <p>There will be scenarios where Dynamic Telemetry could be useful that will not be applicable as a result. And this is OK.</p> <p>It is the belief of Dynamic Telemetry's designers that having limitations to the application is necessary in order to provide a trustworthy diagnostic system that is suitable for use within a large cloud environment.</p> <p>In short, we take the Observer Effect seriously.</p>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/","title":"Query Language","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Processor.QueryLanguage.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#processor-query-language","title":"Processor : Query Language","text":"<p>The Query Language Processor is one of the most straightforward available. It presents minimal risk while still providing valuable capabilities for dynamic modeling and system understanding. The query language Processor can be likened to command line tools found on all operating systems, which manipulate standard IO subsystems.</p>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#introduction-to-query-language-processor","title":"Introduction to Query Language Processor","text":"<p>The query language Processor integrates into the logging stream, monitoring events by applying straightforward query language filtering and aggregate functions. Unlike other Processors within dynamic telemetry, the query language Processor is designed solely for filtering and aggregating data. It does not enable the invocation of actions, which significantly reduces its associated risks in the risk taxonomy.</p>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#simple-code-example-hashing-files","title":"Simple Code Example; hashing files","text":"<pre><code>public string HashFile(string imageName)\n{\n    try\n    {\n        // 1. Log the start of the hashing process\n        LogStartingFileHash(m_logger, imageName);\n\n        // 2. Open the file and hash it\n        using (FileStream fileStream = File.OpenRead(imageName))\n        {\n            string hashValue = Convert.ToBase64String(m_SHA256.ComputeHash(fileStream));\n\n            // 3. Log the end of the hashing process\n            LogEndFileHash(m_logger, imageName, hashValue);\n            return hashValue;\n        }\n    }\n    catch (Exception e)\n    {\n        // Log any exceptions that occur\n        ErrorHashing(m_logger, imageName, e);\n        throw;\n    }\n}\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Starting FileHash {fileName}.\")]\nstatic partial void LogStartingFileHash(ILogger logger, string fileName);\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Ending FileHash {fileName}, hash={hashValue}.\")]\nstatic partial void LogEndFileHash(ILogger logger, string fileName, string hashValue);\n\n[LoggerMessage(Level = LogLevel.Warning, Message = \"Unable to hash image {fileName}\")]\nstatic partial void ErrorHashing(ILogger logger, string fileName, Exception e);\n</code></pre>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#query-language-overview","title":"Query Language Overview","text":"<p>In this example you'll notice that the example code</p> <ol> <li>Logs when we begin hashing</li> <li>Hashs the file; or otherwise perform business logic</li> <li>Logs when we've completed the hashing of the file</li> </ol> <p>This workflow outlines a typical sequence of operations for a developer. Log messages may be disabled before entering production, used during diagnostics, or employed to indicate failure and success in traditional testing.</p>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#modeling-live-system-behavior-with-a-query-language-processor","title":"Modeling Live System Behavior, with a Query Language Processor","text":"<p>An example use of the query language Processor is to suppress highly chatty events. Suppose we find that we are hashing many files and want to keep track of the count without needing file names or statuses. This often happens after deployment when it's realized that such functionality costs more than anticipated.</p> <p>To address this, a simple aggregate function can be sent to the Dynamic Telemetry Query Language Processor to filter these events or aggregate in-memory statistics if they are still needed.</p>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#suppressing-unneeded-chatty-events","title":"Suppressing Unneeded / Chatty Events","text":""},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#aggregating-chatty-events","title":"Aggregating Chatty Events","text":"<p>Lets look at a few examples, as they likely will help tell the tale</p> <p>Image a piece of code that looks something like this:</p> <pre><code>    flowchart TD\n        Unknown((Unknown))\n        HashingFile((HashingFile))\n        Unknown --&gt; | LogStartingFileHash | HashingFile\n        HashingFile--&gt; |LogEndFileHash | Unknown\n</code></pre>"},{"location":"docs/Architecture.Components.Processor.QueryLanguage.document/#example-scenarios","title":"Example Scenarios","text":""},{"location":"docs/Architecture.Components.Processor.StateMachine.document/","title":"StateMachine","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Processor.StateMachine.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#processor-state-machine","title":"Processor : State Machine","text":"<p>The State Machine Processor is a relatively simple yet highly effective component within Dynamic Telemetry. Essentially, this Processor listens to all log messages that pass by, identifying significant events and managing a state machine based on those events. When the state machine Processor detects an interesting log message, it transitions to a new state, potentially initiating an action as part of this transition.</p>"},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#introduction-to-state-machine-processor","title":"Introduction to State Machine Processor","text":"<p>The State Machine Processor operates as a Directed Graph, where transitions occur upon the observation of specific logs by the Processor. This state machine is employed for tasks such as timing, counting, and measuring in contexts that pose significant challenges. The state machine is often accompanied by various actions and is utilized to initiate complex or resource-intensive operations.</p> <p>Its primary function is to monitor logs and transition between states based on the analysis of log names and parameters. Initially, the state machine starts in an undefined state and then dynamically adjusts its state in response to the events it processes. This method is particularly effective for tasks such as timing, counting, and measuring in difficult contexts.</p> <p>To provide an example, consider generating unique hashes of a file, such as data files or JPEG images.</p>"},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#simple-code-example-hashing-files","title":"Simple Code Example; hashing files","text":"<pre><code>public string HashFile(string imageName)\n{\n    try\n    {\n        // 1. Log the start of the hashing process\n        LogStartingFileHash(m_logger, imageName);\n\n        // 2. Open the file and hash it\n        using (FileStream fileStream = File.OpenRead(imageName))\n        {\n            string hashValue = Convert.ToBase64String(m_SHA256.ComputeHash(fileStream));\n\n            // 3. Log the end of the hashing process\n            LogEndFileHash(m_logger, imageName, hashValue);\n            return hashValue;\n        }\n    }\n    catch (Exception e)\n    {\n        // Log any exceptions that occur\n        ErrorHashing(m_logger, imageName, e);\n        throw;\n    }\n}\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Starting FileHash {fileName}.\")]\nstatic partial void LogStartingFileHash(ILogger logger, string fileName);\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Ending FileHash {fileName}, hash={hashValue}.\")]\nstatic partial void LogEndFileHash(ILogger logger, string fileName, string hashValue);\n\n[LoggerMessage(Level = LogLevel.Warning, Message = \"Unable to hash image {fileName}\")]\nstatic partial void ErrorHashing(ILogger logger, string fileName, Exception e);\n</code></pre>"},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#sample-code-overview","title":"Sample Code Overview","text":"<p>In this example you'll notice that the example code</p> <ol> <li>Logs when we begin hashing</li> <li>Hashs the file; or otherwise perform business logic</li> <li>Logs when we've completed the hashing of the file</li> </ol> <p>This workflow outlines a typical sequence of operations for a developer. Log messages may be disabled before entering production, used during diagnostics, or employed to indicate failure and success in traditional testing.</p>"},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#modeling-live-system-behavior-with-a-state-machine-processor","title":"Modeling Live System Behavior, with a State Machine Processor","text":"<p>Consider the state model Processor as a tool to quickly and safely understand the system's operational characteristics after deployment.</p> <p>The state machine Processor is typically beneficial in scenarios where software has been deployed into a production environment, and it cannot be rapidly altered or redeployed. It should be viewed as a diagnostic tool that can be employed extensively without affecting user security, privacy, or performance.</p> <p>After a conclusion is reached by the state machine Processor, the production code is frequently modified to implement a more suitable and permanent solution. Consequently, the state machine Processor can be deactivated once the revised deployment is completed.</p> <p>Lets look at a few examples, as they likely will help tell the tale</p> <p>Image a piece of code that looks something like this:</p> <pre><code>    flowchart TD\n        Unknown((Unknown))\n        HashingFile((HashingFile))\n        Unknown --&gt; | LogStartingFileHash | HashingFile\n        HashingFile--&gt; |LogEndFileHash | Unknown\n</code></pre>"},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#introducing-actions-to-the-dynamic-telemetry-state-machine","title":"Introducing Actions to the Dynamic Telemetry State Machine","text":""},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#useful-actions","title":"Useful Actions","text":"<ul> <li>CPU Sampling</li> <li>Verbose Logs</li> <li>Memory Dump</li> </ul>"},{"location":"docs/Architecture.Components.Processor.StateMachine.document/#example-scenarios","title":"Example Scenarios","text":""},{"location":"docs/Architecture.Components.ProcessorInstallation.Overview.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.ProcessorInstallation.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.ProcessorInstallation.Overview.document/#proessor-installation-overview-coming-soon","title":"Proessor Installation Overview : COMING SOON","text":"<p>In short, there are four locations that Can accept one of the three different dynamic telemetry processors.</p> <p></p> <ol> <li> <p>In process</p> </li> <li> <p>In kernel</p> </li> <li> <p>In    aggregator or collector</p> </li> <li> <p>Off box</p> </li> </ol>"},{"location":"docs/Architecture.Components.Streaming.Observability.document/","title":"Streaming","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Components.Streaming.Observability.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Components.Streaming.Observability.document/#coming-soon","title":"Coming Soon","text":"<p>Streaming telemetry is data that may or may not be stored on the local machine's disk and is always transmitted in a streaming manner.</p> <p>The primary difference between streaming telemetry and file-based telemetry is that streaming telemetry provides remote awareness of a machine, even when there is no failure.</p>"},{"location":"docs/Architecture.DesignPatterns.Counters.document/","title":"Counters","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.DesignPatterns.Counters.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.DesignPatterns.Counters.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.DesignPatterns.DesignPatterns.Overview.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.DesignPatterns.DesignPatterns.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.DesignPatterns.DesignPatterns.Overview.document/#coming-soon","title":"Coming Soon","text":"<p>Please see Rude Q&amp;A</p>"},{"location":"docs/Architecture.DesignPatterns.Queues.document/","title":"Queues","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.DesignPatterns.Queues.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.DesignPatterns.Queues.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.DesignPatterns.Toggles.document/","title":"Toggles","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.DesignPatterns.Toggles.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.DesignPatterns.Toggles.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.DesignPatterns.Triggers.document/","title":"Triggers","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.DesignPatterns.Triggers.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.DesignPatterns.Triggers.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.DesignPatterns.Valves.document/","title":"Valves","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.DesignPatterns.Valves.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.DesignPatterns.Valves.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.FlightRecorder.CubbyHole.document/","title":"Cubby Hole","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.FlightRecorder.CubbyHole.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.FlightRecorder.CubbyHole.document/#cubby-hole-horizon-coming-soon","title":"Cubby Hole Horizon : COMING SOON","text":""},{"location":"docs/Architecture.FlightRecorder.LongHorizons.document/","title":"Long Horizons","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.FlightRecorder.LongHorizons.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.FlightRecorder.LongHorizons.document/#long-horizon-flight-recorder","title":"Long Horizon Flight Recorder","text":"<p>A Long Horizon Flight Recorder is a specialized type of Flight Recorder designed to study long-running issues that are typically very difficult to understand and capture. For example, imagine a long-running asynchronous operation that takes hours or days to complete, such as writing the entirety of a large tape or managing client operating system metadata attached to a long-running Bluetooth connection.</p> <p>In these situations, you would prefer not to emit all of the logging into the back ends due to volume, data costs, and potential security and privacy concerns.</p> <p>Instead, you'd like to have verbose logging localized to a particular transaction, but only collect / harvest this logging should that transaction fail.</p> <p>Using a combination of Probes that log into a Long Horizon Flight Recorder and Actions that initiate the egress of that recorder upon transaction failure, very interesting and novel diagnostic situations can often be created.</p> <p>We often call these \"nets\" as an analogy to fishing, where a net is cast over the side of a boat and collects only what is too big to fit through the net (e.g., the action).</p>"},{"location":"docs/Architecture.FlightRecorder.LongHorizons.document/#criteria-and-differentiators-from-long-horizons","title":"Criteria (and differentiators from 'Long Horizons')","text":"<p>Just like a Short Horizon Flight Recorder. Or really any Flight Recorder. There's no preset criteria to differentiate them. The primary purpose in having a long and a short horizon Flight Recorder is to initiate a conversation about how this recorder will be used in practice.</p> <p>Typically a Long Horizon Flight Recorder will Have</p> <ol> <li>A large memory buffer.</li> <li>A very restrictive filter. That is very selective in what is captured.</li> </ol>"},{"location":"docs/Architecture.FlightRecorder.LongHorizons.document/#long-horizon-flight-recorders-in-the-cloud","title":"Long Horizon Flight Recorders in the Cloud","text":"<p>A keen observer may realize that the value proposition of a Long Horizon flight recorder in a cloud system may not be very significant. This is true because a Long Horizon Flight Recorder has a very restrictive filter on the logs that are placed into the Flight Recorder. By design, the Flight Recorder will not be very chatty and therefore may be suitable for immediate streaming using standard stream-based telemetry.</p> <p>Without question, a Long Horizon Flight Recorder is not something every engineer utilizes in their day-to-day work. It is a specialized tool designed for specific scenarios where long-running processes need detailed logging and diagnostics. Its use is typically reserved for complex systems where understanding and troubleshooting extended operations is crucial.</p> <p>However, this does not mean that a Long Horizon Flight Recorder is of no value. There are some situations where one can be beneficial:</p> <ol> <li>When a Long Horizon Flight Recorder is dynamically    created and triggered    based on the starting and stopping of a transaction. In this case, there are    many Long Horizon Flight Recorders, and the sum of all would be prohibitive    to emit.</li> <li>In an operating system, where it is considered best practice to emit very    little telemetry that is not of a diagnostic nature.</li> </ol> <p>This likely will not be the case in aAn operating system.</p>"},{"location":"docs/Architecture.FlightRecorder.LongHorizons.document/#sample-applications-and-use-cases","title":"Sample Applications and Use Cases","text":"<ol> <li>Following long running transactions, where logs are only desirable should the    transaction fails</li> <li>Long running sessions; bluetooth, TCP, etc</li> </ol> <p>Long Horizon Flight Recorders are ideally suited for diagnosing problems that develop gradually over extended periods or under complex, long-running conditions. They capture logs and metrics selectively, focusing on events important for troubleshooting systemic issues that wouldn't manifest in real-time. As a result, they can be a powerful complement to Short Horizon Flight Recorders when an organization needs both short-term bursts of data collection and deeper, continuous insight.</p> <p>Common Use Cases:</p> <ul> <li>Monitoring days-long or multi-week processes where intermittent bugs may crop   up.</li> <li>Collecting critical trace points for applications performing bulk data   operations (like large file syncs, or tape transactions).</li> <li>Capturing persistent system logs for embedded or industrial software that runs   24/7.</li> </ul> <p>By limiting their scope to just the essential data, Long Horizon recorders avoid overwhelming (or undesirable) storage costs while still offering critical coverage. They also provide a \"rolling window\" of vital analytics, maintaining an ongoing record to pinpoint when and why an anomaly occurred.</p>"},{"location":"docs/Architecture.FlightRecorder.LongHorizons.document/#when-you-should-consider-a-long-horizon-flight-recorder","title":"When You Should Consider a Long Horizon Flight Recorder","text":"<ul> <li>You need historical context that spans multiple machine states or workflow   phases.</li> <li>You're operating in an environment requiring strict cost management but still   need essential traces for in-depth root cause analysis.</li> <li>You have a pipeline of analytics jobs that need periodic or event-based data   snapshots over days or weeks.</li> </ul> <p>They may not be the default choice for every developer, but in the right circumstances, Long Horizon Flight Recorders offer unmatched visibility into hidden or slow-growing system behaviors. By tuning logs and collection intervals carefully, teams can strike the right balance between detail and performance overhead.</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/","title":"Flight Recorder Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.FlightRecorder.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#flight-recorder-overview","title":"Flight Recorder Overview","text":"<p>A Flight Recorder is essentially a ring buffer that stores logging data that is only uploaded to a backend, when instructed by a triggering Action.  Unlike standard streaming telemetry, this telemetry is only emitted when instructed, usually on failure.</p> <p>In this capacity, it serves as an alternative and compliment to standard Streaming Observability.  In fact, users of flight recorders. Typically report that their presence turns the frustrating act of debugging a live system into something a lot more fun and interactive, almost like a video game.</p> <p>A quick recap:</p> <ol> <li>A Probe is a form of logging    that flows into OpenTelemetry</li> <li>A Filter or Router    is a piece of code situated in the middle of an OpenTelemetry pipe that    routes or filters logs</li> <li>A Flight Recorder is a circular log that is never emitted unless there's a    reason</li> <li>An Action provides the    reason</li> </ol> <p>Think of a Flight Recorder as a way to enhance your logging capabilities. It provides flexibility and additional options for addressing complex issues. Imagine needing a specific log when something goes wrong</p> <p>A Flight Recorder offers a unique approach where logs are collected but not uploaded unless a problem arises. The challenge and creative opportunity lie in defining the triggering Ation for when the issue you're monitoring occurs.</p> <p>Now we're playing cat and mouse with our bugs and that is a lot of fun.</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#what-is-a-flight-recorder","title":"What is a Flight Recorder?","text":"<p>Technically, a Flight Recorder comprises a ring buffer with fixed capacity, typically residing in memory or (maybe) on disk, such that the data continually overwrites older data with newer entries. This design is naturally lossy, yet it captures essential insights about system events and states in near real time.</p> <p>What is contained in a Flight Recorder, is simply redirected standard Logging - this be from any Probe technology that emits into OpenTelemetry.</p> <p>Think of a Flight Recorder as just routed Observability, that goes nowhere, unless asked. If you imagine the pipe analogy in the Umbilical document, a Flight Recorder is just a cut Observability pipe, that is redirected into a circular buffer, instead of streamed directly to a a backend.</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#special-characteristics-of-a-flight-recorder","title":"Special Characteristics of a Flight Recorder","text":"<p>In Dynamic Telemetry, one one machine, there can be hundreds - if not thousands of Flight Recorders. Some are as small as a log record or two, others may contain megabytes of Logs, any of which can be collected as instructed by an Action.</p> <p>The most special characteristic of a Flight Recorder, is that each can be uniquely identified by a dedicated tag or name. This allows for quick recognition among multiple data sources and ensures streamlined retrieval when logs need to be collected by an Action.</p> <p>This on-demand egress is a core feature, enabling data extraction whenever deeper investigation is necessary. By preserving a snapshot of the overwritten data, the Flight Recorder helps diagnose issues by making past telemetry accessible for post-mortem analysis.</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#how-to-collect-a-flight-recorder","title":"How to collect a Flight Recorder","text":"<p>A Flight Recorder augments standard streaming telemetry by capturing data from multiple probes, such as OpenTelemetry logging, ETW (Windows), user_events, or syslog into a circular buffer. Logs remain local unless triggered to leave the machine, delivering deeper insights through real-time and localized data analysis.</p> <p>By storing high-verbosity traces locally, a Flight Recorder retains critical details for post-event analysis. Logs remain accessible when needed, even if they might not be retained long-term.</p> <p>This solution can provide both performance benefits and cost savings. To learn more, refer to the position papers on scarcity and triggered Flight Recorders.</p> <p>The basic steps to collect a Flight Recorder are to know through some mechanism its identifier and then to use a triggering action to collect it.</p> <p>Steps Involved in Collecting a Flight Recorder</p> <ol> <li>Route high volume Logging to a Flight Recorder</li> <li>Note its Identifier</li> <li>Use the Flight Recorder egress action, to collect the Flight Recorder</li> </ol>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#trace-horizons","title":"Trace 'Horizons'","text":"<p>Flight Recorders often collect high volume logs that remain local until a triggering event prompts upload. This approach introduces different trace horizons. One horizon might capture logs leading to a process crash or other diagnostic event. Because these logs can be high in volume, ring buffers overwrite older data frequently. This arrangement is commonly referred to as a \"short-horizon\" Flight Recorder.</p> <p>In contrast, some logging applies only to specific failures that may take minutes or days to occur. Examples include Bluetooth sessions on a client operating system, long-running transactions, or writing data to a slow medium like tape. These scenarios require maintaining a Flight Recorder over an extended period, ensuring that all pertinent logs remain accessible when needed.</p> <p>These lower volume but long duration Flight Recorders are known as long-horizon Flight Recorders. They are designed to capture and retain logs over extended periods, ensuring that all relevant data is available for analysis when needed.</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#interesting-applications-of-flight-recorders","title":"Interesting Applications of Flight Recorders","text":"<p>Flight Recorders are an extremely interesting and fun concept. As you gain proficiency in using them, you'll find applications everywhere. They offer a unique way to capture and analyze telemetry data, providing insights that are not possible with traditional logging methods.</p> <p>Below are some of our favorite applications:</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#recording-information-leading-into-a-process-crash","title":"Recording Information leading into a process crash","text":"<p>Imagine a long-running Flight Recorder that collects 100 times the logging that would normally stream through something similar to OpenTelemetry.</p> <p>This logging would be very verbose, containing information like function entry and exit, web requests, queue lengths, open file pointers, file indexes, and so on.</p> <p>Normally, this type of information would clutter up a backend database and be useless in most contexts.</p> <p>However, when collected during a process crash, this information is sufficiently inexpensive and can significantly boost productivity.</p> <p>A Flight Recorder like this is not free; the logs will have to go into a circular buffer, which does cause CPU load. But when done well, for example, using something similar to ETW or user events on Linux, this CPU load can be very inexpensive compared to other techniques.</p> <p>When the process crashes, this log can be collected and will serve as a set of breadcrumbs leading to that process crash.</p> <p>Pretty fantastic.</p> <p>This approach also has a positive impact on the developer's mindset. Developers often struggle with the need to suppress logging messages due to cost, security, and privacy concerns imposed by business and finance teams.</p> <p>With the availability of Flight Recorders, developers can feel reassured. Knowing that in the event of a process crash, they will have access to the critical logs leading up to the incident, alleviates their concerns and allows them to focus on more productive tasks.</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#tracking-memory-leaks","title":"Tracking Memory Leaks","text":"<p>Even in managed languages, determining why memory is being consumed can be a complicated matter. We've all encountered a linked list that holds a pointer to memory and doesn't shrink as it should. While some may argue whether this constitutes a memory leak, the system inevitably starts to slow down and thrash as memory pressure exceeds the hardware's capabilities.</p> <p>A powerful use of a Flight Recorder is to track the insertion or deletion from such a list, or the add reference and release, or malloc() and free() operations in unmanaged languages.</p> <p>This is achieved either through standard logging or by inserting a dynamic probe on the malloc() and free() calls.</p> <p>By using a probe that indicates the amount of memory load on a machine, coupled with an action to collect this type of memory Flight Recorder, a developer can obtain a high-fidelity glimpse into the machine's memory usage over a long duration without negatively impacting performance.</p> <p>Best of all, once the project is complete and the memory leak is understood, dynamic telemetry can disable all of this logging, including the flight recorder, allowing the machines to operate at high speed.</p>"},{"location":"docs/Architecture.FlightRecorder.Overview.document/#references","title":"References","text":"<ol> <li> <p>File and Streaming</p> </li> <li> <p>Telemetry Umbilical</p> </li> <li> <p>Scarcity and Humans</p> </li> <li> <p>triggered Flight Recorders.</p> </li> </ol>"},{"location":"docs/Architecture.FlightRecorder.ShortHorizons.document/","title":"Short Horizons","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.FlightRecorder.ShortHorizons.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.FlightRecorder.ShortHorizons.document/#short-horizon-flight-recorder","title":"Short Horizon Flight Recorder","text":"<p>A Short Horizon Flight Recorder is a focused Flight Recorder, designed to capture and telemetry that is too verbose for steady-state streaming via OpenTelemetry.  It's a Flight Recorder you only collect, when something goes wrong, based on an Action</p> <p>A Short Horizon Flight Recorder employs broad and loosely filtered logs to collect as much logging as possible, with a goal of keeping a few minutes of verbose Logging, leading into a problem.</p> <p>By capturing high-volume telemetry right before events like crashes or lockups, the Short Horizon recorder streamlines failure analysis. It empowers engineering teams to isolate race conditions, examine deadlocks, or retrieve critical logs without excessive overhead or wasted storage. This targeted method contrasts with \"Long Horizons\" which rely on more extended data retention (with less telemetry volume), for root cause analysis.</p> <p>Adopting a Short Horizon approach offers operational benefits and an extra layer of confidence.</p> <p>A well-implemented Short Horizon Flight Recorder can be thought of as a vault or an airplane's Flight Recorder, capturing all problems regardless of the situation.</p> <p>When used this way, the Short Horizon Flight Recorder becomes the developer's best friend as well as a communication tool for project managers.</p> <p>Expectations can be set with development, test, and operations teams so that anytime a problem occurs, it is always expected that this short horizon flight record will be collected.</p> <p>In some circles, this is conventionally known as pressing THE BIG RED BUTTON. When a problem manifests, the culture expects that \"something\" pressed the BigRed button.</p> <p></p> <p>This consistency is a place of investment, anytime a problem manifests, no matter which team is involved, the expectation is that someone (or more likely an Action) pressed this 'button'</p> <p>By ensuring that every incident is logged and analyzed with the content of a Long Horizon Flight Recorder, your teams will build trust and develop custom diagnostic processors around the Flight Recorder. he Short Horizon Flight Recorder fosters a culture of accountability and continuous improvement. Teams can review logs to understand what went wrong, learn from mistakes, and implement better practices.</p> <p>This iterative process enhances overall software quality and when used well, will encourage cost reduction, privacy improvements, and security hardening.</p> <p>This is because a log that is not emitted is the most cost-effective, private, and secure log.</p>"},{"location":"docs/Architecture.FlightRecorder.ShortHorizons.document/#criteria-and-differentiators-from-long-horizons","title":"Criteria (and differentiators from 'Long Horizons')","text":"<p>While the exact memory budget and sampling criteria for a Short Horizon Flight Recorder can vary, there are some established guidelines that have proven effective over time. These criteria help ensure that the recorder captures useful data without overwhelming system resources. Key considerations include:</p> <ul> <li>Fixed memory budget: Typically, a predefined limit such as 32MB is set to   ensure that the recorder does not consume excessive memory.</li> <li>Broad collection scope: The recorder should capture a wide range of events,   but focus on a narrow set of critical events to avoid unnecessary data.</li> <li>Performance impact: The recorder may affect system performance, so it is often   used in conjunction with filters to manage the volume of collected data.</li> </ul> <p>These guidelines help create an efficient and effective Short Horizon Flight Recorder that balances comprehensive data collection with system performance and resource constraints.</p>"},{"location":"docs/Architecture.FlightRecorder.ShortHorizons.document/#sample-applications","title":"Sample Applications","text":"<p>There are numerous applications for a Short Horizon Flight Recorder. Here are a few personal favorites of the author:</p> <ol> <li>Excellent for creating management processes around diagnosing failures and    standardizing diagnostic procedures.</li> <li>Useful for zooming into problematic areas to catch bugs with a 'net'    as detailed here.</li> <li>Ideal for high-volume logging when verbosity is needed prior to an event,    such as a crash.</li> <li>Effective for identifying race conditions, deadlocks, and other concurrency    issues.</li> <li>Provides emotional relief for engineers by offering a reliable tool during    cost-saving initiatives.</li> </ol>"},{"location":"docs/Architecture.FlightRecorder.TraceHorizons.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.FlightRecorder.TraceHorizons.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.FlightRecorder.TraceHorizons.document/#understanding-trace-horizons","title":"Understanding Trace Horizons","text":"<p>The concept of a trace horizon is straightforward. It refers to the amount of time that can typically be stored in a circular buffer.</p> <p>When a Flight Recorder is discussed, it is often described by its trace length, which is the duration of time it covers. For example, you might say, \"Every time a process crashes, we collect a 5-minute Flight Recorder leading up to the crash.\"</p> <p>Your Trace Horizon, in this case, is 5 minutes.</p> <p>Achieving an exact 5-minute trace horizon is more of an ideal than a reality. In practice, the trace length will vary, and it requires continuous refinement and iteration over time. Your team will need to develop conventions and processes to manage and adjusting the trace horizon effectively over time.</p> <p>The variable involved in your Horizon are:</p> <ol> <li>The amount of memory provided to the Flight Recorder.</li> <li>The verbosity of logs that have been sampled in by the filter.</li> </ol> <p>Imagine a simple example where your software is running smoothly, and the Flight Recorder is operating nominally. No Flight Recorders are emitted - they cost nothing in your backends/databases, and almost nothing on the machines being monitored. Suddenly, however, your code goes into a failure mode where the logging for errors dramatically spikes up.</p> <p>In this example, you've configured your filter to collect these logs into a fixed memory Flight Recorder where they remain until an issue triggers an .Action. These logs are stored in the Flight Recorder, where they stay until either the buffer wraps or the .Action emits the entire log into your observability backends.</p> <p>When in .Action does trigger the egressing Flight Recorder. It'll go into your standard observability backends where your developers can enjoy a higher fidelity amount of logging than when operating in an nominal case.</p> <p>It's not uncommon for teams to discover that they either have too much information and would prefer a longer trace horizon, or they would like to shuffle the logging that is stored. Typically, after some analysis, they'll want to reconfigure the filter that serves this Flight Recorder.</p> <p>Their options will include:</p> <ol> <li>Filtering out the chatty logs</li> <li>Converting the chatty logs into a Metric</li> <li>Increasing the memory dedicated to the Flight Recorder</li> </ol> <p>The key takeaway for this section is that the trace horizon is a critical aspect of Dynamic Telemetry.</p> <ol> <li>Dev + Ops teams specify their desired trace horizon along with their memory    budgets.</li> <li>This is enforced with the Dynamic Telemetry filter that routes log messages    into the Flight Recorder.</li> <li>It is expected that the trace horizon will be within a reasonable tolerance    of the desired value. However, predicting which log messages will be chatty,    especially in a failure condition, can be challenging.</li> </ol>"},{"location":"docs/Architecture.KeyConstructs.Overview.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.KeyConstructs.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.KeyConstructs.Overview.document/#overview-of-key-constructs-probes-filters-flight-recorders-and-actions","title":"Overview of Key Constructs; Probes, Filters, Flight Recorders, and Actions","text":"<p>If there is any aspect of Dynamic Telemetry that requires thorough understanding, it is the critical distinction between static telemetry and Dynamic Telemetry. At its core, this distinction represents the transition from hard-coded, static assets to more versatile and reconfigurable Dynamic Telemetry. This concept forms the foundation of Dynamic Telemetry.</p> <p>A deeper discussion will be presented in subsequent subsections, for each construct, but for now lets look into each.</p> <p>The four Constructs of Dynamic Telemetry are</p> <ol> <li>a Probe</li> <li>a Filter</li> <li>a Flight Recorder</li> <li>a Action</li> </ol>"},{"location":"docs/Architecture.KeyConstructs.Overview.document/#what-is-a-probe","title":"What is a Probe","text":"<p>A Dynamic Telemetry Probe is a lightweight mechanism that emits events (logs) within a running system. A Probe is usually specific to the operating system and native to that environment. For example, it could be the Event Tracing for Windows (ETW) system within Windows, user events within Linux syslog, or even OpenTelemetry on cross-platforms.</p> <p>In essence, a Probe is a logging event. In a static telemetry system, it represents the legacy-based approach.</p>"},{"location":"docs/Architecture.KeyConstructs.Overview.document/#what-is-a-filterrouter","title":"What is a Filter/Router","text":"<p>A filter is a Dynamic Telemetry construct used to filter and route logging that is already inside an OpenTelemetry pipeline.</p> <p>Imagine an OpenTelemetry pipeline as a pipe of water. Cutting the pipe and adding a filter or diverter would allow you to control the flow. A fully blocking filter could be considered a valve. This valve or diverter acts as a filter or router.</p>"},{"location":"docs/Architecture.KeyConstructs.Overview.document/#what-is-a-flight-recorder","title":"What is a Flight Recorder","text":"<p>A flight recorder is an identified collector of routed logging. In a simple case, a flight recorder might be a memory buffer. In other systems, it could be a file on disk.</p> <p>The two key characteristics of a flight recorder are:</p> <ol> <li>that it is uniquely identifiable</li> <li>that it contains logs</li> </ol>"},{"location":"docs/Architecture.KeyConstructs.Overview.document/#what-is-an-action","title":"What is an Action","text":"<p>An Action is a architectural construct that can do work based on logging that it sees Passing through a pipe.</p> <p>You can imagine a Log message that indicates that a transAction fails, If a listener. Of this Log message decides to take Action, for example collecting a memory dump or starting a CPU sample. This actor would be called an Action.</p> <p>By configuring a Filter to detect memory management logs, you can then direct those logs to a specialized Flight Recorder Action built for diagnosing memory leaks. This Flight Recorder can capture snapshots of heap usage or detailed allocation patterns whenever the filter's trigger conditions are met, enabling quick identification of problematic regions within the application's memory footprint without continuously running resource-intensive diagnostics.</p>"},{"location":"docs/Architecture.Overview.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Overview.document/#dynamic-telemetry-philosophy","title":"Dynamic Telemetry Philosophy","text":"<p>DynamicTelemetry is an articulation of the embodiment of a suite of Observability tools, designed to manage, control, and reshape telemetry in Production systems.</p> <p>Essentially, DynamicTelemetry is a set of enforced conventions that enable various sophisticated diagnostic systems to work in harmony. It ensures compatibility with user privacy and security needs. Simultaneously, DynamicTelemetry provides businesses with the ability to adjust their Observability based on necessity. This allows resources to be allocated when needed and restricts telemetry when it's not required.</p> <p>This document aims to delve into the philosophy of DynamicTelemetry, exploring the intricate balance between complex realities. While this document serves as a comprehensive spiritual guide, some readers might find it beneficial to start with the usage scenarios to get a better understanding of the system.</p>"},{"location":"docs/Architecture.Overview.document/#dynamic-telemetry-in-a-nutshell","title":"Dynamic Telemetry, in a nutshell","text":"<p>Demos are a great way to go hands on with DynamicTelemetry, but before diving in to the complex realities DynamicTelemetry seeks to resolve, it's important to have a general understanding of usage.</p> <p>Image yourself as a DEVELOPER. You're focused on the latest business needs from your PROJECTMANAGER. You're worried about solving business problems, keeping costs in check,</p>"},{"location":"docs/Architecture.Overview.document/#onbox-architecture","title":"OnBox Architecture","text":""},{"location":"docs/Architecture.Overview.document/#tenants","title":"Tenants","text":"<pre><code>--&gt;\n\n1. **Leverage existing technology**, before creating new\n1. Be **philosophically indifferent to tooling**, operating systems, or\n   environment\n1. **Offer recommendable decisions**, make decisions, to those who ask\n1. By intent do not modify system state and minimize the Observer Effect\n1. Be clear where the Observer Effect can impact, with clear awareness and\n   options for mitigation\n\n&lt;!--\n</code></pre>"},{"location":"docs/Architecture.Probe.Breakpoint.document/","title":"Breakpoint","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.Breakpoint.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.Breakpoint.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/Architecture.Probe.Breakpoint.document/#notes-breakpoint-probe","title":"Notes (Breakpoint Probe)","text":"<p>A breakpoint probe is a type of probe that utilizes a software or hardware breakpoint, depending on the programming language.</p> <p>This is a riskier probe type because the instruction pointer will transfer into the underlying kernel facilities. However, it is not as risky as a traditional debugger, as the instruction pointer will not be frozen. Instead, it will simply collect the memory and exit using standard OpenTelemetry.</p> <p>Some types of breakpoint probes may include.</p> <ol> <li>uProbe</li> <li>dotnet</li> <li>pTrace</li> <li>dtrace (etc)</li> </ol>"},{"location":"docs/Architecture.Probe.DTrace.document/","title":"DTrace","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.DTrace.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.DTrace.document/#probe-dtrace-probedtracedocument","title":"PROBE : DTrace (Probe.DTrace.document)","text":""},{"location":"docs/Architecture.Probe.DTrace.document/#introduction-to-dtrace","title":"Introduction to DTrace","text":""},{"location":"docs/Architecture.Probe.ETW.document/","title":"ETW","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.ETW.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.ETW.document/#probe-etw","title":"PROBE : ETW","text":""},{"location":"docs/Architecture.Probe.OpenTelemetry.document/","title":"OpenTelemetry","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.OpenTelemetry.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.OpenTelemetry.document/#probe-opentelemetry","title":"PROBE : OpenTelemetry","text":""},{"location":"docs/Architecture.Probe.eBPF.document/","title":"eBPF","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.eBPF.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.eBPF.document/#probe-ebpf","title":"PROBE : eBPF","text":""},{"location":"docs/Architecture.Probe.ptrace.document/","title":"ptrace","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.ptrace.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.ptrace.document/#probe-ptrace","title":"PROBE : pTrace","text":""},{"location":"docs/Architecture.Probe.uprobes.document/","title":"uprobes","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.uprobes.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.uprobes.document/#probe-uprobe","title":"PROBE : uprobe","text":""},{"location":"docs/Architecture.Probe.user_events.document/","title":"user_events","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probe.user_events.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probe.user_events.document/#probe-user_events","title":"PROBE : user_events","text":""},{"location":"docs/Architecture.Probes.Overview.document/","title":"Probe Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Architecture.Probes.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Architecture.Probes.Overview.document/#probe-explanation","title":"Probe Explanation","text":"<p>In DynamicTelemetry a \"PROBE\" is the base case abstraction for all means of measure. PROBES extract information from the working system, and convert them into a schematized OpenTelemetry Log, Metric, or Trace.</p>"},{"location":"docs/Architecture.Probes.Overview.document/#introduction","title":"Introduction","text":"<p>In the realm of system monitoring and data analysis, DynamicTelemetry introduces a unique and efficient component known as a \"probe\". A probe, in the context of DynamicTelemetry, is a dynamic element that is capable of producing small quantities of valuable data. This data, often derived from various operations and processes within the system, serves as a rich source of information for analysis and troubleshooting.</p> <p>The defining characteristic of these probes is their non-disruptive nature. They are designed to operate seamlessly within the system without causing any disruption to the machine's performance or quality. This means that while these probes are actively extracting and producing data, they do not cause any noticeable slowdown or alteration in the system's operations.</p> <p>This non-intrusive and efficient data production makes probes an integral part of DynamicTelemetry, enabling it to monitor system performance, detect anomalies, and provide valuable insights for system optimization. The use of probes underscores DynamicTelemetry's commitment to maintaining system integrity while providing a robust and comprehensive monitoring solution.</p>"},{"location":"docs/Architecture.Probes.Overview.document/#course-types-of-probes","title":"Course Types of Probes","text":""},{"location":"docs/Architecture.Probes.Overview.document/#static-probes","title":"Static probes","text":"<p>These tools are always active, monitoring the system continuously. They pose less risk but consume more resources. Examples include ETW on Windows, syslog, LTTG user events, and perf on Linux.</p>"},{"location":"docs/Architecture.Probes.Overview.document/#dynamic-probes","title":"Dynamic Probes","text":"<p>On the other hand, Dynamic Telemetry probes can be enabled or disabled as required. They offer greater flexibility and can quickly provide comprehensive information when activated. However, they carry a higher risk as they might alter the system, such as with EBPF, uProbes, kProbes, or DTrace..</p> <p>DynamicTelemetry facilitates the dynamic and rapid activation of probes to collect data and integrate it into your existing OpenTelemetry workflows. This functionality is particularly beneficial in production systems where a probe may need to be deactivated after use or should a performance issue be detected.</p> <p>It is important to note that the use of probes, particularly dynamic ones, could potentially affect system performance. Consequently, DynamicTelemetry includes safeguards to minimize this impact.</p>"},{"location":"docs/Architecture.Probes.Overview.document/#examples-of-probes","title":"Examples of Probes","text":"<p>Probes can be found in various systems, each tailored to the specific environment and requirements of that system. They are designed to seamlessly integrate with the system's operations, providing valuable data without causing any disruption.</p> <p>On Windows, one such example of a probe is Event Tracing for Windows (ETW). ETW is a powerful tracing tool provided by the Windows operating system. It allows developers to both log real-time binary events and instrument their applications and the system to capture events. These events can then be used to analyze the performance and diagnose issues, making ETW a valuable probe in the Windows environment.</p> <p>In the Linux ecosystem, there are several examples of probes. Syslog, for instance, is a standard for message logging. It allows for the separation of the software that generates messages, the system that stores them, and the software that reports and analyzes them. This makes Syslog a versatile and valuable probe in a Linux environment.</p> <p>Another example in Linux is LTTNG (Linux Trace Toolkit) and user_events. These are a type of probe that provides a mechanism to trace and monitor user-space applications and correlate activities with kernel-space events. This correlation provides a comprehensive view of the system's behavior, making LTTG user events a valuable probe.</p> <p>Perf is yet another example of a probe in Linux. It is a powerful tool that can be used to count events and monitor certain aspects of software and hardware, providing valuable data for performance analysis.</p> <p>These examples illustrate the diversity and adaptability of probes across different systems. Despite their differences, all probes share the common goal of providing valuable, non-disruptive data for system monitoring and analysis.</p>"},{"location":"docs/Architecture.Probes.Overview.document/#use-of-probes-in-dynamictelemetry","title":"Use of Probes in DynamicTelemetry","text":"<p>In the DynamicTelemetry system, probes serve as dynamic data sources that can be enabled or disabled as needed. This flexibility is crucial in a production environment where unnecessary data collection can lead to performance degradation.</p> <p>When a probe is disabled, it remains dormant within the system, not contributing any data or consuming any resources. However, the true power of probes comes to light when they are enabled. With DynamicTelemetry, users can dynamically enable a probe when they need to extract specific information from the system. This process is quick and efficient, allowing users to gather valuable data on-demand without any significant impact on system performance.</p> <p>Once a probe is enabled, it begins to emit data that is then egressed into the OpenTelemetry workflows. For instance, a user could turn on a uprobe to monitor the return value for a particular function. This data is then sent to Open Telemetry for further processing and analysis.</p> <p>The role of DynamicTelemetry in this process is to facilitate the dynamic enabling of probes and the initial extraction of data. Once the data is emitted to OpenTelemetry, DynamicTelemetry's role ends. The data is then handled by the standard egressing mechanisms of OpenTelemetry, which could involve various processes such as aggregation, counting, or direct emission as a log.</p> <p>This dynamic and on-demand use of probes makes DynamicTelemetry a powerful tool for real-time system monitoring and data extraction. It allows users to gather rich, valuable data when they need it, providing insights that can help optimize system performance and troubleshoot issues.</p>"},{"location":"docs/Architecture.Probes.Overview.document/#performance-impact-and-safeguards-of-probes-in-dynamictelemetry","title":"Performance Impact and Safeguards of Probes in DynamicTelemetry","text":"<p>The use of probes in DynamicTelemetry can potentially impact system performance. This is primarily due to the frequent emission of logs, which could consume system resources and affect performance. However, DynamicTelemetry is designed with this consideration in mind and includes several safeguards to mitigate this impact.</p> <p>One of the key principles of DynamicTelemetry is to ensure that the use of probes does not compromise system performance. To achieve this, DynamicTelemetry has implemented mechanisms to restrict the frequency and volume of log emissions, as well as counters (and caps) on the number of instructions executed. These mechanisms are designed to balance the need for detailed data with the necessity of maintaining optimal system performance.</p> <p>For instance, DynamicTelemetry may limit the number of logs that a probe can emit within a certain timeframe. This prevents a probe from overwhelming the system with excessive data. Additionally, DynamicTelemetry may also implement safeguards at the probe level, such as limiting the amount of data that a probe can extract or the resources that it can consume.</p> <p>These safeguards ensure that the use of probes in DynamicTelemetry remains efficient and non-disruptive. They allow DynamicTelemetry to provide detailed and valuable data without compromising the performance of the system. This makes DynamicTelemetry a reliable tool for system monitoring and data analysis, capable of providing rich insights while maintaining system integrity and performance.</p> <p>ToDo:</p> <ul> <li>Risk vs. Perf axis</li> <li>Discuss operations that can occur to a probe</li> <li>Contrast a probe from a breakpoint</li> <li>Talk about how Logs/Traces can be used as probes</li> <li>Link to Observer Effect</li> <li>Link to Risk Levels</li> </ul>"},{"location":"docs/Architecture.Probes.Overview.document/#probe-characteristics","title":"Probe Characteristics","text":"<ol> <li> <p>Intentionally READ-ONLY; this is a 'hard and fast' rule in OpenTelemetry that    may box out some very powerful opportunities.</p> </li> <li> <p>Intentionally INEXPENSIVE to performance</p> </li> </ol>"},{"location":"docs/Architecture.Probes.Overview.document/#readonly","title":"READONLY","text":""},{"location":"docs/Architecture.Probes.Overview.document/#inexpensive","title":"INEXPENSIVE","text":""},{"location":"docs/Architecture.Probes.Overview.document/#probe-risk","title":"Probe Risk","text":"<p>Probes inherently pose risks to Production systems. These risks manifest in various forms. DynamicTelemetry aims to mitigate these risks across five different dimensions: Privacy, Security, Reliability, Cost, and Performance.</p> <p>This document provides a framework for understanding these risks and the mitigation techniques used, as discussed in the Observer Effect.</p>"},{"location":"docs/Architecture.Probes.Overview.document/#probe-risk-mitigations","title":"Probe Risk mitigation's","text":""},{"location":"docs/Architecture.Probes.Overview.document/#privacy","title":"Privacy","text":"<p>Mitigation:</p> <ol> <li> <p>READ-ONLY: intentionally a PROBE does not alter the functionally of a system</p> </li> <li> <p>Configuration Deployment;    PROBE configurations are always deployed with the same oversight as    production code.</p> </li> <li> <p>Privacy</p> </li> </ol>"},{"location":"docs/Architecture.Probes.Overview.document/#security","title":"Security","text":""},{"location":"docs/Architecture.Probes.Overview.document/#reliability","title":"Reliability","text":""},{"location":"docs/Architecture.Probes.Overview.document/#cost","title":"Cost","text":""},{"location":"docs/Architecture.Probes.Overview.document/#performance","title":"Performance","text":""},{"location":"docs/Architecture.Probes.Overview.document/#probe-values","title":"Probe Values","text":"<ul> <li>Local Suppression</li> <li>Remote Suppression</li> </ul> <p>| Value | Remote Mitigations | Local Mitigations | | -- | -- | -- | | 1 (low risk) |  |  | | 2 (med risk) | |  | | 3 (high risk) | | |</p>"},{"location":"docs/Architecture.Probes.Overview.document/#linux-probe-types-and-their-risks","title":"Linux Probe Types (and their risks)","text":""},{"location":"docs/Architecture.Probes.Overview.document/#opentelemetry","title":"OpenTelemetry","text":""},{"location":"docs/Architecture.Probes.Overview.document/#dtrace","title":"DTrace","text":""},{"location":"docs/Architecture.Probes.Overview.document/#ebpf","title":"eBPF","text":""},{"location":"docs/Architecture.Probes.Overview.document/#ptrace","title":"ptrace","text":""},{"location":"docs/Architecture.Probes.Overview.document/#uprobes","title":"uprobes","text":""},{"location":"docs/Architecture.Probes.Overview.document/#user_events","title":"user_events","text":""},{"location":"docs/Architecture.Probes.Overview.document/#windows-probe-types-and-their-risks","title":"Windows Probe Types (and their risks)","text":""},{"location":"docs/Architecture.Probes.Overview.document/#etw","title":"ETW","text":""},{"location":"docs/Architecture.Probes.Overview.document/#ebpf-windows","title":"eBPF (Windows)","text":""},{"location":"docs/Definitions.document/","title":"Definitions","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Definitions.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Definitions.document/#definitions","title":"Definitions","text":"TERM DEFINITION BUGBEACON A library of 'active comments' - an SDK that emits on schematized OpenTelemetry, to maximize the impact of in-place  bservability. Simplifying and maximizing use with  ynamicTelemetry. <p>| PROBE | In DynamicTelemetry a PROBE is the base case abstraction for all means of measure.PROBES extract information from the working system, and convert them into a schematized OpenTelemetry Log, Metric, or Trace. Comfortable (and common) examples include ETW, SYSLOG, USER_EVENTS. More advanced examples include UPROBES and DTRACE.|</p> <p>|ETW = Event Tracing, Windows | Windows in box tracing. There are a few 'flavors' of ETW - TraceLogging is the preferred flavor for DynamicTelemetry, because it's internally manifested' and its events are self describing, such that they can be decoded without manifest.|</p> <p>| UPROBE | kernel.org. Basically a kernel supported breakpoint mechanism.|</p> <p>|DTRACE | msdn| |SYSLOG|TBD| |USER_EVENTS|TBD|</p>"},{"location":"docs/Demos.0.DynamicID/","title":"Understanding Durable ID","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Demos.0.DynamicID.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Demos.0.DynamicID/#demo-0-durable-ids-explanation","title":"Demo 0 - Durable ID's Explanation","text":""},{"location":"docs/Demos.0.DynamicID/#using-durableid-in-opentelemetry-to-locate-the-source-of-the-the-expense","title":"Using DurableID in OpenTelemetry, to locate the source of the the expense","text":"<p>Not all software using OpenTelemetry will utilize a durable identifier, though it is considered best practice. A durable identifier functions like a GPS or homing beacon, mapping any row of telemetry to a specific line of code.</p> <p>In microsoft.net platform the durable identifier is created automatically at compile time for OpenTelemetry assuming the author of the software follows best practices.</p>"},{"location":"docs/Demos.0.DynamicID/#contrasting-c-that-makes-use-of-durable-ids-with-c-that-does-not","title":"Contrasting C# that makes use of Durable ID's, with C# that does not","text":"<p>Let's examine code that makes use a durable identifier versus one that doesn't. We'll inspect both in Application Insights, so we can spot the difference.</p> <p>It's important to understand that Dynamic Telemetry functions with and without a DurableID, however the experience without is less enjoyable and less efficient. Following best practices is highly encouraged.</p>"},{"location":"docs/Demos.0.DynamicID/#seeing-the-durableid-in-azures-application-insights","title":"Seeing the DurableID in Azures Application Insights","text":""},{"location":"docs/Demos.0.DynamicID/#recommended-way-to-log","title":"Recommended Way to Log","text":"<pre><code>private void LogWithDurableID()\n{\n    //\n    // Log a message with a DurableID; 'behind the scenes' the dotnet compiler will\n    //     generate two ID's - one numerical, and one a string\n    //\n    // Behind the scenes, the compiler uses this syntax to create identifiers that are included\n    //     into the telemetry row, that can be used visually, and in automation, to map\n    //     from row of telemetry, to line of code - very useful when extending the capabilities\n    //     of your telemetry assets\n    //\n    // NOTE: adding the _instanceID is to showcase how, we can more easily locate this line\n    //     of code, as compared with the earlier 'flattened' version.  The compiler will attach\n    //     an 'EventName' property with the value of our function name \"LogLaunch\".  We can use this\n    //     instead of regular expressions to locate and aggregate\n    //\n    LogLaunch(_logger, _version, _instanceID);\n}\n\n// StartSearchExample:LogLaunch\n[LoggerMessage(Level = LogLevel.Information, Message = \"Launch, ver={version}, instantion={instantionID}\")]\nstatic partial void LogLaunch(ILogger logger, string version, Guid instantionID);\n// EndSearchExample:LogLaunch\n</code></pre>"},{"location":"docs/Demos.0.DynamicID/#not-recommended-way-to-log","title":"Not Recommended Way to Log","text":"<pre><code>private void LogWithoutDurableID()\n{\n    //\n    // Log a message without a DurableID;  while simple, this log will provide struggles later\n    //    because while we receive a property bag of the variables (_version), we will not know\n    //    which line of code emitted the telemetry - as our only identtifer will be the\n    //    'flattened' payload string\n    //\n    // NOTE: adding the _instanceID is to showcase how, once 'flattened' this unrecommendable\n    //    method of logging makes for tricky (and expensive) backend searching\n    //\n    _logger.LogInformation($\"Launch, ver={_version}, instantion={_instanceID}\");\n}\n</code></pre>"},{"location":"docs/Demos.0.DynamicID/#full-example-code","title":"Full Example Code","text":"<pre><code>using Microsoft.AspNetCore.Mvc.RazorPages;\nusing System.Diagnostics.Metrics;\n\nnamespace DynamicTelemetry_Demo_DurableIds.Pages\n{\n    public partial class IndexModel : PageModel\n    {\n        private readonly ILogger&lt;IndexModel&gt; _logger;\n        private static string _version = \"0.0.4\";\n        private Guid _instanceID = Guid.NewGuid();\n        //private static Counter&lt;int&gt; ? _getCounter;\n\n        public IndexModel(ILogger&lt;IndexModel&gt; logger, IMeterFactory meterFactory)\n        {\n            _logger = logger;\n\n            //var meter = meterFactory.Create(\"DynamicTelemetry.Metric.Conversion\");\n            //_getCounter = meter.CreateCounter&lt;int&gt;(\"LogLaunch\");\n\n            // On Launch emit two logs - seemingly identical, one has a DurableID\n            //_getCounter.Add(1);\n            LogWithDurableID();\n            LogWithoutDurableID();\n        }\n\n        // StartExample:NoDurableId\n        private void LogWithoutDurableID()\n        {\n            //\n            // Log a message without a DurableID;  while simple, this log will provide struggles later\n            //    because while we receive a property bag of the variables (_version), we will not know\n            //    which line of code emitted the telemetry - as our only identtifer will be the\n            //    'flattened' payload string\n            //\n            // NOTE: adding the _instanceID is to showcase how, once 'flattened' this unrecommendable\n            //    method of logging makes for tricky (and expensive) backend searching\n            //\n            _logger.LogInformation($\"Launch, ver={_version}, instantion={_instanceID}\");\n        }\n        // EndExample:NoDurableId\n\n\n        // StartExample:DurableId\n        private void LogWithDurableID()\n        {\n            //\n            // Log a message with a DurableID; 'behind the scenes' the dotnet compiler will\n            //     generate two ID's - one numerical, and one a string\n            //\n            // Behind the scenes, the compiler uses this syntax to create identifiers that are included\n            //     into the telemetry row, that can be used visually, and in automation, to map\n            //     from row of telemetry, to line of code - very useful when extending the capabilities\n            //     of your telemetry assets\n            //\n            // NOTE: adding the _instanceID is to showcase how, we can more easily locate this line\n            //     of code, as compared with the earlier 'flattened' version.  The compiler will attach\n            //     an 'EventName' property with the value of our function name \"LogLaunch\".  We can use this\n            //     instead of regular expressions to locate and aggregate\n            //\n            LogLaunch(_logger, _version, _instanceID);\n        }\n\n        // StartSearchExample:LogLaunch\n        [LoggerMessage(Level = LogLevel.Information, Message = \"Launch, ver={version}, instantion={instantionID}\")]\n        static partial void LogLaunch(ILogger logger, string version, Guid instantionID);\n        // EndSearchExample:LogLaunch\n        // EndExample:DurableId\n    }\n}\n</code></pre>"},{"location":"docs/Demos.0.DynamicID/#spotting-the-difference-in-your-database","title":"Spotting the difference in your database","text":"<p>The most obvious way to see the differences between this these two different methods of emitting telemetry is by looking and inspecting your database.</p> <p>Without this awareness, the suggested logging method might seem overly complex, as it requires extra effort and log record creation.</p> <p></p> <p>Upon examining each of these rows in the telemetry data, you will notice that one contains an entry in the custom definitions while the other does not. The row without a custom definition originates from a direct call to log information, resulting in the omission of these critical fields.</p> <p>At first glance, it may appear that incorporating a durable identifier incurs higher storage and compute costs; this is initially accurate and holds true in this example. However, as you optimize your database, you may end up entirely omitting the message column.</p> <p>Subsequentl what sceney, you can expand the custom dimensions values into their distinct type-specific saved columns, which are indexed and offer high performance.</p> <p>This optimization step is what really will bring dramatic cost savings, an increased diagnostic capabilities, to the table.</p>"},{"location":"docs/Demos.0.DynamicID/#seeing-the-confusion-lack-of-capability","title":"Seeing the Confusion, lack of capability","text":"<p>Let's explore some of these savings by examining where our costs are going. If we aggregate the rows of telemetry using a basic summary based on the message string, you'll observe that each row has two counts.</p> <p>One of the counts is derived from log information without a durable identifier, while the other comes from logging with the durable identifier. This results in a row count of two for each log entry, which is an intentional aspect of the demo's design.</p> <p>It's hard to get a clear picture of your telemetry without a durable identifier. At best, you'll use regular expressions to turn a telemetry row into something identifiable and traceable.</p>"},{"location":"docs/Demos.0.DynamicID/#using-the-eventname-to-locate-the-line-of-code","title":"Using the EventName to locate the line of code","text":"<p>Let's utilize our durable identifier by creating a separate event name column. Costs may rise due to the custom dimensions column.</p> <p>To reduce costs, consider dropping the message column and extracting the event name for indexing during ingestion. This leverages the strengths of a relational database and indexing efficiently.</p>"},{"location":"docs/Demos.0.DynamicID/#aggregating-based-on-the-eventname","title":"Aggregating based on the EventName","text":""},{"location":"docs/Demos.0.DynamicID/#use-azure-monitor-and-kql-language-to-locate-an-expensive-opentelemetry-log","title":"Use Azure Monitor and KQL language to locate an expensive OpenTelemetry log","text":"<p>With the event name in hand, one can appreciate the value of having a durable identifier. What was once multiple pages of rows has now been streamlined into only five rows. Some of these event names are generated by the network infrastructure itself, while the second and fourth ones are produced by our demonstration program.</p> <p>It is noticeable that the counts of the empty row are slightly higher compared to the log launch row. This discrepancy arises because not every log row corresponds to a log launch. This observation further underscores the point; in this instance, nine messages have been aggregated into a single entry. In a production system, one can expect this number to be significantly higher, which would subsequently increase potential confusion exponentially.</p>"},{"location":"docs/Demos.1.DropChattyLog/","title":"Drop a Chatty Event","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Demos.1.DropChattyLog.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Demos.1.DropChattyLog/#cost-reduction-demo-inline-kql-filtering","title":"Cost Reduction Demo : Inline KQL Filtering","text":"<p>Dynamic Telemetry can be used for many applications and in this one we will use it to reduce the cost of our services locating and dropping a highly verbose log message very quickly.</p>"},{"location":"docs/Demos.1.DropChattyLog/#demo-overview","title":"Demo Overview","text":"<p>In short this demo will</p> <ul> <li> <p>Use Azure Monitor and KQL language to locate an unexpectedly expensive Open   Telemetry log.</p> </li> <li> <p>Utilize the DurableID feature on OpenTelemetry, to locate the line of code   responsible for the expense.</p> </li> <li> <p>Instruct Dynamic Telemetry to convert the Log into a Metric</p> </li> <li> <p>Choose one of the five Dynamic Telemetry locations to apply our KQL filter.</p> </li> <li> <p>Deploy the conversion, and measure the impact</p> </li> </ul>"},{"location":"docs/Demos.1.DropChattyLog/#demo-video","title":"Demo Video","text":""},{"location":"docs/Demos.1.DropChattyLog/#use-azure-monitor-and-kql-language-to-locate-an-expensive-opentelemetry-log","title":"Use Azure Monitor and KQL language to locate an expensive OpenTelemetry log","text":"<p>By using the query below in Application Insights, we can utilize the Durable Identifier found in our logs to pinpoint specific log messages or identify any log messages that are particularly resource-intensive. This is an example, so none of these logs are notably expensive.</p> <p>However, in a real production environment with millions or billions of rows, you will observe more significant instances.</p> <p></p> <p>With the event name in hand (LogLaunch), one can appreciate the value of having a DurableIDentifier. What was once multiple pages of rows has now been streamlined into only five rows. Some of these event names are generated by the network infrastructure itself, while the second and fourth ones are produced by our demonstration program.</p> <p>It is noticeable that the counts of the empty row are slightly higher compared to the log launch row. This discrepancy arises because not every log row corresponds to a log launch. This observation further underscores the point; in this instance, nine messages have been aggregated into a single entry. In a production system, one can expect this number to be significantly higher, which would subsequently increase potential confusion exponentially.</p>"},{"location":"docs/Demos.1.DropChattyLog/#utilize-the-durableid-to-locate-the-line-of-code-responsible-for-the-expense","title":"Utilize the DurableID, to locate the line of code responsible for the expense","text":"<p>It should be immediately apparent that using a DurableIDentifier instead of a regular expression is significantly faster and more cost-effective than using flattened strings.</p> <p>As shown in the figure above, nearly 3500 messages originate from a single line of code, accounting for approximately 50% of all logging activities.</p> <p>Although this is a constructed example, it is not uncommon for around 8 lines of code to be responsible for about 50% of log-based telemetry.</p> <p>We can efficiently search our source code for this function by utilizing our source editor or various tools similar to grep.</p> <p>Consider the utility of static analysis tools that process your DLLs. These tools can easily identify mistakes like leaked secrets, such as IP addresses, MAC addresses, or user identifiers.</p> <p></p> <p>The tool will efficiently identify the specific line of code, almost as if it were equipped with a GPS. In future versions of .NET and Dynamic Telemetry, one could envision a tool capable of processing debug symbols and utilizing reflection on the DLLs to pinpoint the exact build and line of code. This subject is discussed in greater detail in the relevant sections on DurableIDentifiers.</p>"},{"location":"docs/Demos.1.DropChattyLog/#instruct-dynamic-telemetry-to-drop-the-chatty-log","title":"Instruct Dynamic Telemetry to drop the chatty Log","text":"<p>Now we will use Dynamic Telemetry to focus on and address this event.</p> <p>This topic is discussed in much greater detail in other sections that provide extensive content necessary for a full understanding. In brief, Dynamic Telemetry offers several architectural locations where modifications can be made to the data being produced.</p> <p>While avoiding full expansion in this demonstration, it should be noted that detailed explanations are available in other sections. In summary, we can now process telemetry in real-time based on various risk profiles.</p> <ol> <li> <p>In the process of the emitting agent</p> </li> <li> <p>In the kernel of the emitting agent</p> </li> <li> <p>In an aggregation / upload service</p> </li> <li> <p>At the point of ingestion, off the box.</p> </li> </ol> <p></p>"},{"location":"docs/Demos.1.DropChattyLog/#instruct-dynamic-telemetry-to-convert-the-log-into-a-metric","title":"Instruct Dynamic Telemetry to convert the Log into a Metric","text":"<p>Now we will use Dynamic Telemetry to focus on and address this event.</p> <p>This topic is discussed in much greater detail in other sections that provide extensive content necessary for a full understanding. In brief, Dynamic Telemetry offers several architectural locations where modifications can be made to the data being produced.</p> <p>While avoiding full expansion in this demonstration, it should be noted that detailed explanations are available in other sections. In summary, we can now process telemetry in real-time based on various risk profiles.</p> <ol> <li> <p>In the process of the emitting agent</p> </li> <li> <p>In the kernel of the emitting agent</p> </li> <li> <p>In an aggregation / upload service</p> </li> <li> <p>At the point of ingestion, off the box.</p> </li> </ol> <p></p>"},{"location":"docs/Demos.1.DropChattyLog/#choose-one-of-the-five-dynamic-telemetry-locations-to-apply-our-kql-filter","title":"Choose one of the five Dynamic Telemetry locations to apply our KQL filter","text":"<p>For this simple example of dropping a chatty event, we'll use an in-process emission to avoid context switches and maintain performance due to the minimal check required. The necessary risks and benefits are detailed in other sections of this document and deserve further exploration.</p> <p>As demonstrated in the above screenshot, we have developed a concise KQL filter that will be integrated into the process of the emitting agent. This filter is designed to be \"clipped or attached\" to the line of code responsible for emission in a highly efficient manner that does not impact overall or local system performance.</p> <p>In fact, with a robust implementation, there may be net CPU performance improvements due to the reduction in time and processing power needed to encode various payloads and transfer them between user mode, kernel mode, and back to user mode before network transmission.</p> <p>These efficiency gains occur even before reaching our backend databases, which was the initial focus. As a result, the log message will not be omitted, ingested, indexed, or stored.</p>"},{"location":"docs/Demos.1.DropChattyLog/#deploy-the-conversion-and-measure-the-impact","title":"Deploy the conversion, and measure the impact","text":"<p>Deployment into your environment is flexible, as Dynamic Telemetry offers various configuration methods. Depending on your needs, you may choose different techniques and deployment speeds.</p> <p>For instance, a large cloud provider might prefer a gradual deployment of Dynamic Telemetry configurations. In contrast, small or medium-sized companies might find benefits in deploying them instantaneously.</p> <p>This decision is largely personal, and the necessary information and knowledge to make an informed choice are detailed further in other sections of this documentation.</p> <p>For our purposes, we will deploy this rapidly for demonstration purposes.</p>"},{"location":"docs/Demos.1.DropChattyLog/#recap","title":"Recap","text":""},{"location":"docs/Demos.2_DynamicProbe/","title":"Dynamic Probes","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Demos.2_DynamicProbe.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Demos.2_DynamicProbe/#dynamictelemetry-demo-1-adding-telemetry-dynamically","title":"DynamicTelemetry : Demo 1, adding Telemetry dynamically","text":"<p>In this demonstration, well be utilizing DynamicTelemetry to generate telemetry for code thats already been deployed in a Production environment.</p> <p>Consider a scenario where a certain piece of code is operational within a Production Kubernetes cluster. A quick review of this code reveals a complete absence of telemetry. ...and a curiousity that we'll explore!</p> <p>Please quickly study this code, it's a simple \"Tower of Hanoi\" problem, like every college freshman studies in CS101. Unique to this code, you will notice the absence of telemetry and certainly no OpenTelemetry.</p> <p>To address this issue, we will establish a dynamic probe and connect it to the active process. This probe utilizes technology akin to what's found in symbolic debuggers such as Visual Studio, windbg, or gdb. Its function is to gather minimal amounts of memory, transform them into standard OpenTelemetry Logs, and then directly feed them into your existing OpenTelemetry pipelines.</p> <p>Once emitted, these new Logs will work no differently to any other OpenTelemetry. All your Graphana, Prometheus, or Azure Dev Explorer tooling will work as they do today.</p> <p>To set up the dynamic probe, we just need to highlight the interesting function and press F9 key in Visual Studio Code. After that, we switch to the DynamicTelemetry. If our security and privacy guidelines allow this kind of probing, it will then be implemented on the targeted machines.</p> <p>Within minutes, the new OpenTelemetry Logs and Metrics will be emitted to your existing OpenTelemetry pipeline. You'll see the values appear for use within Graphana, Azure Data Explorer, or any other OpenTelemtry compatible services you have installed.</p>"},{"location":"docs/Demos.4.AddTelemetryDemo/","title":"Adding a Memory Probe","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Demos.4.AddTelemetryDemo.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Demos.4.AddTelemetryDemo/#diagnostic-demo-dynamically-adding-a-row-of-telemetry","title":"Diagnostic Demo: Dynamically Adding a Row of Telemetry","text":"<p>In a live production system, diagnosing and debugging using only existing telemetry can be challenging. Sometimes, there is a strong need to know the value in memory or the stack of a caller.</p> <p>These data gaps can leave developers guessing about the behavior of their code. Simply knowing the value of a variable or two can provide significant insights into the problem, reducing the time to diagnose dramatically.</p> <p>In this example, we will use Dynamic Telemetry Probes to insert a specialized breakpoint into our code. This will allow us to dynamically extract small amounts of memory and insert it into our existing OpenTelemetry pipelines.</p>"},{"location":"docs/Demos.4.AddTelemetryDemo/#demo-overview-and-video","title":"Demo Overview and Video","text":"<p>In short this demo will:</p> <ol> <li>Use a Breakpoint Probe to dynamically insert a row of telemetry to emit the    contents of a variable into our standard OpenTelemetry pipelines.</li> <li>Deploy this Dynamic Telemetry probe to a small number of machines that we    expect to be impacted.</li> <li>Connect to Application Insights and View / Graph / Alert this value.</li> </ol>"},{"location":"docs/Demos.4.AddTelemetryDemo/#dynamically-insert-a-row-of-telemetry-to-emit-the-contents-of-a-variable","title":"Dynamically insert a row of telemetry to emit the contents of a variable","text":"<p>For this demo, we will make use of the Breakpoint Probe concept in Dynamic Telemetry, Our Action. Will not be a complicated action such as collecting a memory dump, starting a CPU sample, or toggling on or off diagnostic logs, even though Each of these are a possibility.</p> <p>For our application, we simply want to know the value of a memory variable when our probe is hit.</p> <p>To achieve a good developer workflow. We will use the Visual Studio Code source editor To locate the line of code where we wish to Extract some memory.</p> <p>Please quickly scan over the following piece of code. You don't need to understand all of it, just get a general idea of the page model. The key observation is that in the <code>OnGet</code> method, we receive a variable from the user and use that variable as a key in the cache, which is kept 30 minutes.</p> <p>Every time <code>OnGet</code> is called, a counter on the cached object will be incremented via the <code>AddUsage</code> function.</p> <pre><code>using Microsoft.AspNetCore.Mvc.RazorPages;\nusing Microsoft.Extensions.Caching.Memory;\nusing System.Diagnostics.Metrics;\n\nnamespace DynamicTelemetry_Demo_3_SecurityRedactions.Pages\n{\n    public partial class IndexModel : PageModel\n    {\n        private readonly ILogger&lt;IndexModel&gt; _logger;\n        private IMemoryCache _cache;\n        public CachedObject ? _me;\n\n        public IndexModel(ILogger&lt;IndexModel&gt; logger, IMeterFactory meterFactory, IMemoryCache cache)\n        {\n            _logger = logger;\n            _cache = cache;\n        }\n\n        // StartExample:InsertTelemetryOnGet\n        public void OnGet(string variable=\"\")\n        {\n            LogWelcome(_logger);\n\n            _me = _cache.GetOrCreate(variable, entry =&gt; {\n                entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(30);\n                return new CachedObject();\n            });\n\n            _me?.AddUsage();\n        }\n</code></pre> <p>Please recall this sample is just that, a sample. To illustrate the use case, let's assume that as our system scales, we notice performance issues. Our development team suspects that the cache is getting full, causing paging issues on our drives. They are considering investigating the 30-minute time span, as it might be too long.</p> <p>To better understand the problem, the developers would like to know how many items are in the cache while under load. One of the developers got the idea to use Dynamic Telemetry to simply emit the cache size as a telemetry variable and then graph it using their standard OpenTelemetry pipelines.</p> <pre><code>public void OnGet(string variable=\"\")\n{\n    LogWelcome(_logger);\n\n    _me = _cache.GetOrCreate(variable, entry =&gt; {\n        entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(30);\n        return new CachedObject();\n    });\n\n    _me?.AddUsage();\n}\n</code></pre> <p>To achieve this. We will open the Visual Studio Code. Editor and locate the piece of code where we would like to insert our Probe.</p> <p></p> <p>We simply right-click and select \"Add Dynamic Telemetry Memory Probe.\"</p> <p>Similar to standard Visual Studio conditional breakpoints, we can set emission criteria for a variable in a way that does not stop the execution pointer. This method is both fast and safe.</p> <p></p> <p>When this breakpoint is hit, the memory will be extracted and inserted into the standard and previously deployed OpenTelemetry pipelines. You can then view this data from your standard database.</p>"},{"location":"docs/Demos.4.AddTelemetryDemo/#deploy-this-probe-to-a-small-number-of-machines-that-we-expect-to-be-impacted","title":"Deploy this probe to a small number of machines that we expect to be impacted","text":"<p>Deployment into your environment is flexible, as Dynamic Telemetry offers various configuration methods. Depending on your needs, you may choose different techniques and deployment speeds.</p> <p>For instance, a large cloud provider might prefer a gradual deployment of Dynamic Telemetry configurations. In contrast, small or medium-sized companies might find benefits in deploying them instantaneously.</p> <p>This decision is largely personal, and the necessary information and knowledge to make an informed choice are detailed further in other sections of this documentation.</p> <p>For our purposes, we will deploy this rapidly for demonstration purposes.</p>"},{"location":"docs/Demos.4.AddTelemetryDemo/#connect-to-application-insights-and-view-graph-alert-this-value","title":"Connect to Application Insights and View / Graph / Alert this value","text":"<p>Because the breakpoint probe conforms to the Dynamic Telemetry specification, the collected memory will be emitted into a standard OpenTelemetry logging message that includes the desired contents.</p> <p>This is this is an interesting feature because within seconds of being deployed, telemetry is already being emitted.</p> <p>Rapid turnaround creates an environment where developers can quickly add telemetry, probe, cast nets, monitor, and learn without worrying about impacting their customers.</p> <p>In our example, we're trying to determine why or how the cache values are growing so quickly, if they are indeed growing.</p> <p>We use dynamic telemetry to deploy a scenario where we extract the number of items in the memory cache and emit it as a log message.</p> <p>As you can see in our query below, we plot the number of log welcome messages as one line and the maximum count as the other line.</p> <pre><code>//\n// Sample KQL query to monitor the CacheCount\n//\ntraces\n| extend EventName = tostring(customDimensions.EventName)\n| project EventName, message, customDimensions, timestamp\n| extend CacheCount=toint(customDimensions.cacheLength)\n| summarize countif(EventName == \"LogWelcome\"), max(CacheCount) by bin(timestamp, 1m)\n| render timechart\n</code></pre> <p>We then wait to see if the cache value increases due to some anomaly.</p> <p></p> <p>Sure enough. After a little bit of waiting. We see a case where the cash values grow. (As indicated by the red line) Whereas the number of incoming requests remains roughly steady. (As indicated by the blue line)</p> <p></p> <p>Even more interesting is the observation that the line grows very rapidly over a span of a few minutes and then flattens out before shrinking back down. Measuring the time delta across this indicates that the cache values grow linearly for a bit of time, hold for about 30 minutes, and then drop as they grew.</p> <p>A review of the code makes it obvious what is occurring.</p> <pre><code>public void OnGet(string variable=\"\")\n{\n    LogWelcome(_logger);\n\n    _me = _cache.GetOrCreate(variable, entry =&gt; {\n        entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(30);\n        return new CachedObject();\n    });\n\n    _me?.AddUsage();\n}\n</code></pre> <p>In this example for some reason. The calling clients are changing the variable coming in. In a way that each. Request is seemingly unique. They do this for a. Period. Short period of time and then it stops.</p> <p>Because this is a silly example, there's no reason that this occurring. However, the graphs make it obvious that that is what is occurring. The 30 minutes that we see is because the cash value has an absolute expiration time of 30 minutes.</p>"},{"location":"docs/Demos.HighLevel.Overview/","title":"HighLevel / Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Demos.HighLevel.Overview.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Demos.HighLevel.Overview/#high-level-overview-demo-of-dynamic-telemetry","title":"High Level Overview Demo, of Dynamic Telemetry","text":"<p>Welcome to this demonstration of Dynamic Telemetry. In this demo, we will quickly take a broad survey of Dynamic Telemetry, highlighting key usage scenarios and important architectural points.</p>"},{"location":"docs/Demos.HighLevel.Overview/#overview-of-dynamic-telemetry","title":"Overview of Dynamic Telemetry","text":"<p>Dynamic Telemetry is an open-source diagnostic tool that complements OpenTelemetry. It aims to make debugging live production systems as easy and enjoyable as debugging a single application locally. Our goal is to allow you to diagnose and explore live production systems while minimizing risks to reliability, performance, or customer privacy.</p>"},{"location":"docs/Demos.HighLevel.Overview/#value-proposition","title":"Value Proposition","text":"<p>Dynamic Telemetry builds on top of OpenTelemetry to provide advanced features for debugging, performance measurement, privacy and security hardening, as well as cost reduction. This overview will give you a broad understanding, with deeper dives into each of these scenarios available in later sections of this documentation.</p>"},{"location":"docs/Demos.HighLevel.Overview/#demonstration","title":"Demonstration","text":"<p>In this demonstration, we're going to how case the broad architecture points found in added Dynamic Telemetry. We'll build on the standard OpenTelemetry Kubernetes sample without modifying or recompiling any code. This showcases the seamless integration and powerful capabilities of Dynamic Telemetry.</p> <p>It is assumed that you already have an OpenTelemetry pipeline in place that houses your Logs, Metrics, and Traces in your preferred database. While our samples will utilize Azure technology, you are welcome to use any technology stack that suits your needs.</p>"},{"location":"docs/Demos.HighLevel.Overview/#key-architectural-concept","title":"Key Architectural Concept","text":"<p>Dynamic Telemetry, in short, is a dynamically controlled diagnostic control, that is inserted into one of four architectural locations in your existing Open Telemetry pipeline.</p> <p>Each insertion point, also called a Processor, accepts configuration from a remote configuration deployment server, and intercepts all OpenTelemetry logs metrics and traces that are being emitted and passed through that architectural point in the below diagram.</p>"},{"location":"docs/Demos.HighLevel.Overview/#standard-opentelmetry-architectural-overview","title":"Standard OpenTelmetry Architectural Overview","text":"<p>In the diagram below, you will observe a typical OpenTelemetry architecture, where multiple agents transmit their telemetry data through the kernel of their host operating system.</p> <p>In some OpenTelemetry architectures, the aggregation process and kernel are omitted in favor of direct ingestion from an agent. These architectures are usually employed in small to medium-sized installations. Although they function similarly, these variations are not the focus of this demonstration.</p> <p></p>"},{"location":"docs/Demos.HighLevel.Overview/#survey-of-a-dynamic-telemetry-processor","title":"Survey of a Dynamic Telemetry Processor","text":"<p>A Dynamic Telemetry Processor is a software component that is dynamically configured and operates within the standard OpenTelemetry OLTP pipeline. This processor is detailed further in the processor section, but essentially, it is a software module that monitors all events passing through it and allows one of the Dynamic Telemetry personas to modify the telemetry being transmitted.</p> <p>Subject to implementation a Dynamic Telemetry processor is likely to be fitting into one of several categories</p> <ol> <li> <p>A    Query Language    (SQL, KQL, etc)</p> </li> <li> <p>A    Programming Environment or Language    (eBPF, .NET, Python, Rust, etc)</p> </li> <li> <p>A textually defined    State Machine, or State Model</p> </li> </ol>"},{"location":"docs/Demos.HighLevel.Overview/#installation-points-for-dynamic-telemetry-processors","title":"Installation Points for Dynamic Telemetry Processors","text":"<p>The diagram below shows the installation of Dynamic Telemetry processors in four different architectural locations.</p> <ol> <li> <p>In    process of the emitting agent</p> </li> <li> <p>In the    kernel of the Operation System hosting the agent</p> </li> <li> <p>In the    aggregation process    that is about to emit to the ingestion gateway</p> </li> <li> <p>At the    point of ingestion</p> </li> </ol> <p>The Processor section of this document expands upon these four different insertion points more thoroughly, but in short, each installation point have capability, cost, and benefit tradeoffs.</p> <p></p>"},{"location":"docs/Demos.HighLevel.Overview/#capabilities-of-dynamic-telemetry","title":"Capabilities of Dynamic Telemetry","text":"<p>With a basic understanding of where architecturally Dynamic Telemetry can be inserted into the OpenTelemetry pipeline it's important to understand the types of operations that Dynamic Telemetry can offer.</p> <ol> <li> <p>Dropping Logs or Metrics</p> </li> <li> <p>Adding Logs or Metrics</p> </li> <li> <p>Converting Logs into Metrics</p> </li> <li> <p>Dropping fields in Logs</p> </li> <li> <p>Adding fields to Logs</p> </li> <li> <p>Maintaining state / awareness</p> </li> </ol>"},{"location":"docs/Demos.HighLevel.Overview/#simple-sample-using-kql-filter-to-drop-an-entire-log-message","title":"Simple Sample Using KQL Filter to Drop an Entire Log Message","text":"<p>Consider a scenario where you have a software agent that is emitting logs. For various reasons, you may decide that some of the logs are unnecessary or unwanted. Instead of rebuilding, retesting, and redeploying your code, you would prefer to have a pause button for these logs.</p> <p>You might want to pause the logs during high traffic times to save costs, or only enable logging when diagnosing the software. Another option could be pausing the logs to prevent the spread of accidentally logged sensitive information.</p> <p>To achieve this goal, we utilize the KQL Query Language Processor -- and quickly deploy the below KQL to the most appropriate of the four Processors.</p> <pre><code>traces\n| where customDimensions.EventName != \"LogWelcomeBanner\"\n</code></pre> <p>The above KQL could be inserted at any one of the processors described in the previous section and when the log message is being emitted at that appropriate processing location the log would be simply paused (dropped) as long as the dynamically deployed configuration was applied.</p>"},{"location":"docs/Demos.HighLevel.Overview/#simple-sample-using-kql-filter-dropping-fields-in-a-log","title":"Simple Sample Using KQL Filter dropping fields in a Log","text":"<p>A potentially more interesting application would be the removal of a particular field within a log</p> <p>In this scenario for some reason a particular field was included and then later after deployment was decided that field was unnecessary or unwanted this can happen for several reasons ranging from costs to security, database performance, and privacy it could also be simply a case of just wanting to be more tidy anesthetics</p> <p>Consider the example below from our demonstration on content redaction. This simulation code unintentionally emits a secret, which we need to remove before it is ingested into our databases.</p> <p>In this simulated workflow, we wish to remove the secret before it's egressed from the web agent.</p> <pre><code>public string WelcomeBanner\n{\n    get\n    {\n        DateTimeOffset time = DateTimeOffset.UtcNow;\n        string secret = GetSecret(); ;\n        LogWelcomeBanner(_logger, secret);\n        return $\"Welcome : {time}\";\n    }\n}\n</code></pre> <pre><code>traces\n| where customDimensions.EventName != \"LogWelcomeBanner\"\n</code></pre> <p>To achieve this goal, we utilize the KQL Query Language Processor -- and quickly deploy the below KQL to the most appropriate of the four Processors.</p> <p>Without Dynamic Telemetry a rebuild retest and redeploy be required but with Dynamic Telemetry the simple configuration below can be dynamically transmitted to any of the four described processors at which point any log named \"LogWelcomeBanner\" have it's \"secret\" field redacted.</p> <pre><code>traces\n| extend customDimensions = iif(customDimensions.EventName == \"LogWelcomeBanner\",\n    bag_remove_keys(customDimensions, dynamic(['secret'])), customDimensions)\n</code></pre>"},{"location":"docs/Demos.HighLevel.Overview/#database-view-of-the-log-that-contains-a-secret","title":"Database view of the Log that contains a secret","text":"<p>As demonstrated below, by utilizing Application Insights and KQL, it is evident that the secret in our code has been transmitted to the backend databases.</p> <p></p> <p>Because this secret was \"accidentally\" emitted; we wish to remove just the field.</p>"},{"location":"docs/Demos.HighLevel.Overview/#database-view-of-the-log-after-field-redaction","title":"Database view of the Log, after field redaction","text":"<p>As you can see in the below Screenshot, immediately after the KQL filter was deployed, just the 'secret' field is redacted.</p> <pre><code>traces\n| extend customDimensions = iif(customDimensions.EventName == \"LogWelcomeBanner\",\n    bag_remove_keys(customDimensions, dynamic(['secret'])), customDimensions)\n</code></pre> <p></p>"},{"location":"docs/Demos.HighLevel.Overview/#including-configuration-deployment-service","title":"Including Configuration Deployment Service","text":"<p>Since every deployment environment has unique characteristics and tolerances for risk, Dynamic Telemetry leverages the inherent code and configuration of the infrastructure's deployment systems. Further details on this topic are provided in subsequent sections. It is essential to consider configuration deployment as the most efficient mechanism that ensures responsible usage within the hosted environment.</p> <p></p>"},{"location":"docs/GeneratedFileStatus/","title":"Status","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/GeneratedFileStatus.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/GeneratedFileStatus/#level1b","title":"Level1b","text":"File Word Count ../docs/Applications.FlightRecorder.MemoryLeak.document.md 211 ../docs/Applications.FlightRecorder.PriorToCrash.document.md 252 ../docs/Architecture.Action.Explanation.document.md 124 ../docs/Architecture.Components.FiltersAndRouters.document.md 44 ../docs/Architecture.Components.Observer.InProcess.document.md 53 ../docs/Architecture.Components.Observer.Kernel.document.md 68 ../docs/Architecture.Components.Streaming.Observability.document.md 59 ../docs/Architecture.FlightRecorder.LongHorizons.document.md 795 ../docs/Architecture.FlightRecorder.Overview.document.md 919 ../docs/Architecture.FlightRecorder.ShortHorizons.document.md 618 ../docs/Architecture.FlightRecorder.TraceHorizons.document.md 466 ../docs/Architecture.KeyConstructs.Overview.document.md 440 ../docs/Architecture.Overview.document.md 212 ../docs/Demos.1.DropChattyLog.md 1103 ../docs/Demos.2_DynamicProbe.md 277 ../docs/Demos.4.AddTelemetryDemo.md 1078 ../docs/Demos.HighLevel.Overview.md 1187 ../docs/PositionPaper.DeliveryGuarantees.document.md 163 ../docs/PositionPaper.DynamicTelemetryTenets.document.md 67 ../docs/PositionPaper.FileAndStreaming.document.md 227 ../docs/PositionPaper.ObserverEffect.document.md 728 ../docs/PositionPaper.SharingDataAmongStakeHoldersIsHard.document.md 171 ../docs/PositionPaper.TelemetryUmbilical.document.md 95 ../docs/Rude_Q_and_A.md 748 ../docs/Scenarios.Overview.CostReduction.document.md 1368 ../docs/Scenarios.Overview.DeepDiagnostics.document.md 757 ../docs/Scenarios.Overview.document.md 180 ../docs/Scenarios.Overview.DurableDashboards.Alerts.document.md 552 ../docs/Scenarios.Overview.RedactingSecrets.document.md 1084 ../docs/Scenarios.Overview.Reliability.document.md 2247"},{"location":"docs/GeneratedFileStatus/#level1","title":"Level1","text":"File Word Count ../docs/Applications.InterestingApplications.document.md 10 ../docs/Applications.Overview.InterestingApplications.document.md 7 ../docs/Architecture.Action.ConfigCollection.document.md 13 ../docs/Architecture.Action.CPUSample.document.md 13 ../docs/Architecture.Action.FileCollection.document.md 13 ../docs/Architecture.Action.FlightRecorder.document.md 33 ../docs/Architecture.Action.MemoryDump.document.md 10 ../docs/Architecture.Action.PacketCapture.document.md 14 ../docs/Architecture.Action.ProcessExecution.document.md 13 ../docs/Architecture.Action.StateCollection.document.md 13 ../docs/Architecture.Action.VerboseLogs.document.md 13 ../docs/Architecture.Components.FileBased.Observability.document.md 10 ../docs/Architecture.Components.Observer.External.OffBox.document.md 97 ../docs/Architecture.Components.Observer.External.OnBox.document.md 62 ../docs/Architecture.Components.ProcessorInstallation.Overview.document.md 46 ../docs/Architecture.DesignPatterns.Counters.document.md 10 ../docs/Architecture.DesignPatterns.DesignPatterns.Overview.document.md 14 ../docs/Architecture.DesignPatterns.Queues.document.md 10 ../docs/Architecture.DesignPatterns.Toggles.document.md 10 ../docs/Architecture.DesignPatterns.Triggers.document.md 10 ../docs/Architecture.DesignPatterns.Valves.document.md 10 ../docs/Architecture.FlightRecorder.CubbyHole.document.md 15 ../docs/Architecture.Probe.Breakpoint.document.md 97 ../docs/Architecture.Probe.DTrace.document.md 18 ../docs/Architecture.Probe.eBPF.document.md 13 ../docs/Architecture.Probe.ETW.document.md 13 ../docs/Architecture.Probe.OpenTelemetry.document.md 13 ../docs/Architecture.Probe.ptrace.document.md 13 ../docs/Architecture.Probe.uprobes.document.md 13 ../docs/Architecture.Probe.user_events.document.md 13 ../docs/Definitions.document.md 161 ../docs/Demos.0.DynamicID.md 722 ../docs/Persona_DataAnalysis.document.md 122 ../docs/Persona_Developer.document.md 183 ../docs/Persona_DevOps.document.md 110 ../docs/Persona_ProjectManager.document.md 121 ../docs/PositionPaper.ABTestingWithRichDiagnostics.document.md 12 ../docs/PositionPaper.Actions.document.md 12 ../docs/PositionPaper.ClearFailuresViaSchema.document.md 12 ../docs/PositionPaper.CloudAndEdgeInterop.document.md 12 ../docs/PositionPaper.ConfigurationDeployment.document.md 65 ../docs/PositionPaper.ConvertLogsToMetrics.document.md 12 ../docs/PositionPaper.DataOwnershipIsntAlwaysClear.document.md 12 ../docs/PositionPaper.DefiningProduction.document.md 28 ../docs/PositionPaper.DynamicallyToggleLogs.document.md 12 ../docs/PositionPaper.ExternalAuditsOfProductionCode.document.md 12 ../docs/PositionPaper.FlightRecorder.document.md 12 ../docs/PositionPaper.GuideToLogVerbosity.document.md 12 ../docs/PositionPaper.InternalAuditsOfProductionCode.document.md 12 ../docs/PositionPaper.LeafLevelLogging.document.md 12 ../docs/PositionPaper.PositionPapers.Overview.document.md 12 ../docs/PositionPaper.ProbeRiskLevels.document.md 55 ../docs/PositionPaper.ProbeToHeader.document.md 12 ../docs/PositionPaper.ProceduralizeNets.document.md 11 ../docs/PositionPaper.ScarcityAndHumans.md 12 ../docs/PositionPaper.SelfDescribingProductionCode.document.md 12 ../docs/PositionPaper.TestingWithEntropy.document.md 12 ../docs/PositionPaper.TraditionalTesting.md 12 ../docs/PositionPaper.TriggeredCollections.document.md 12 ../docs/PositionPaper.TriggeredFlightRecorder.document.md 12 ../docs/PositionPaper.TriggeredMemoryDump.document.md 12 ../docs/PositionPaper.WhereToSuppressInProc.document.md 12 ../docs/ReviewProcess.document.md 98 ../docs/Scenarios.ChangingEnvironments.document.md 15 ../docs/Scenarios.ConvertLogsToMetrics.document.md 15 ../docs/Scenarios.EventAggregation.document.md 15 ../docs/Scenarios.EventFieldSuppression.document.md 16 ../docs/Scenarios.EventSuppression.document.md 15 ../docs/Scenarios.ExtractingMemoryWithUProbe.document.md 15 ../docs/Scenarios.MemoryLeak.document.md 14 ../docs/Slides.Overview.Presentation.md 377"},{"location":"docs/GeneratedFileStatus/#level2","title":"Level2","text":"File Word Count ../docs/Architecture.Components.Processor.Language.md 476 ../docs/Architecture.Components.Processor.Overview.document.md 952 ../docs/Architecture.Components.Processor.QueryLanguage.document.md 349 ../docs/Architecture.Components.Processor.StateMachine.document.md 475 ../docs/Architecture.Probes.Overview.document.md 1405 ../docs/index.md 362 ../docs/Personas.Overview.document.md 257 ../docs/PositionPaper.DurableIds_StructuredPayloads.document.md 1242"},{"location":"docs/Persona_DataAnalysis.document/","title":"Data Analyst","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Persona_DataAnalysis.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Persona_DataAnalysis.document/#data-analyst-persona","title":"Data Analyst Persona","text":"<p>DynamicTelemetry personas are intended as an organizational aid to group capabilities and usability of common usage scenarios. Browsing between scenarios is recommended, for the personas are intended only as an aid.</p>"},{"location":"docs/Persona_DataAnalysis.document/#introduction","title":"Introduction","text":"<p>The DATA_ANALYST Persona in DynamicTelemetry:</p> <ol> <li>Looks for patterns - has a background in math, AI, big data, statistics, etc</li> <li>Apprecates (but doesnt necessarily depend on) schematized data, with crisp    contracts</li> <li>Is well versed and comfortable with the differences between security and    privacy. Knows how to protect users.</li> </ol>"},{"location":"docs/Persona_DataAnalysis.document/#scenarios","title":"Scenarios","text":"<ol> <li>Bug Beacon</li> <li>A/B Feature Testing</li> <li>Categorized/Schematized Failures</li> <li>Triggered Flight Recorder</li> </ol>"},{"location":"docs/Persona_DataAnalysis.document/#notes-to-be-deleted","title":"Notes (To Be Deleted)","text":"<pre><code>mindmap\n    root((DataAnalysis))\n        StandardWorkflows\n            Grafana\n            Prometheus\n</code></pre>"},{"location":"docs/Persona_DevOps.document/","title":"DevOps","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Persona_DevOps.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Persona_DevOps.document/#devops-persona","title":"DEVOPS Persona","text":"<p>DynamicTelemetry personas are intended as an organizational aid to group capabilities and usability of common usage scenarios. Browsing between scenarios is recommended, for the personas are intended only as an aid.</p>"},{"location":"docs/Persona_DevOps.document/#introduction","title":"Introduction","text":"<p>The DEVOPS Persona in DynamicTelemetry:</p> <ol> <li>Scales virtual assets, like containers and VM's - firsthand</li> <li>Understands how databases, alerting, and bug tracking systems are    interconnected</li> <li>Knows when to reset virtual assets, and when to debug</li> <li>Is well versed and comfortable with the differences between security and    privacy. Knows how to protect users.</li> </ol>"},{"location":"docs/Persona_DevOps.document/#notes-to-be-deleted","title":"Notes (To Be Deleted)","text":"<pre><code>mindmap\n    root((DevOps))\n        Deployment\n        ObserverEffect\n            Usage_Caps\n</code></pre>"},{"location":"docs/Persona_Developer.document/","title":"Developer","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Persona_Developer.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Persona_Developer.document/#dynamictelemetry-persona-developer-persona","title":"DynamicTelemetry Persona : DEVELOPER Persona","text":"<p>DynamicTelemetry personas are intended as an organizational aid to group capabilities and usability of common usage scenarios. Browsing between scenarios is recommended, for the personas are intended only as an aid.</p>"},{"location":"docs/Persona_Developer.document/#introduction","title":"Introduction","text":"<p>The DEVELOPER Persona in DynamicTelemetry:</p> <ol> <li>Authors code, firsthand</li> <li>Understands technical details like data schemas, instruction pointers, and    can differentiate logs/traces from metrics.</li> <li>Comfortable with core operating system concepts, like threads, heaps, and    stacks</li> <li>Understands symbolic debuggers, code offsets, and symbols</li> <li>Is well versed and comfortable with the differences between security and    privacy. Knows how to protect users.</li> </ol>"},{"location":"docs/Persona_Developer.document/#scenarios","title":"Scenarios","text":"<ol> <li>Bug Beacon</li> <li>A/B Feature Testing</li> <li>Categorized/Schematized Failures</li> <li>Triggered Flight Recorder</li> <li>Triggered Memory Dump</li> <li>Extracting Memory - dynamic probe insertion</li> <li>Memory Leaks</li> </ol>"},{"location":"docs/Persona_Developer.document/#notes-to-be-deleted","title":"Notes (To Be Deleted)","text":"<pre><code>mindmap\n    root(Developer)\n        Triggers(Triggered Actions)\n            Collect Flight Recorder\n            Toggle Flight Recorder Verbocity\n\n            Actions\n\n        Probes(Probe Types)\n            OpenTelemetry\n                Vadim\n                Logs\n                Metrics\n                Traces\n            OS_Telemetry\n                Linux\n                    eBPF\n                    DTrace\n                    strace\n                    syslog\n                Windows\n                    ETW\n            API(DynamicTelemetry API)\n                A/B Feature Testing\n                Asserts\n\n        Actions(Actions)\n            File_Collections\n            Process_Memory_Dumps\n            CPU_Sampling\n            Flight_Recorders\n</code></pre>"},{"location":"docs/Persona_ProjectManager.document/","title":"Project Manager","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Persona_ProjectManager.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Persona_ProjectManager.document/#project-manager-persona","title":"Project Manager Persona","text":"<p>DynamicTelemetry personas are intended as an organizational aid to group capabilities and usability of common usage scenarios. Browsing between scenarios is recommended, for the personas are intended only as an aid.</p>"},{"location":"docs/Persona_ProjectManager.document/#introduction","title":"Introduction","text":"<p>The PROJECT_MANAGER Persona in DynamicTelemetry:</p> <ol> <li> <p>Focuses on solving business problems - if technology meets the needs of users</p> </li> <li> <p>Is concerned with costs</p> </li> <li> <p>Is concerned about schedule, timelines</p> </li> <li> <p>Is concerned about balancing quality, product applicability, and features</p> </li> <li> <p>Balances mutiple environments</p> </li> <li> <p>Is well versed and comfortablze with the differences between security and    privacy. Knows how to protect users.</p> </li> <li> <p>Clear Failujres via Schemas</p> </li> <li> <p>Triggered Flight Recorder</p> </li> </ol>"},{"location":"docs/Persona_ProjectManager.document/#scenarios","title":"Scenarios","text":"<pre><code>mindmap\n    root((ProjectManagement))\n</code></pre>"},{"location":"docs/Personas.Overview.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Personas.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Personas.Overview.document/#using-personas-to-help-shape-your-journey-in-dynamictelemetry","title":"Using Personas to help shape your journey in DynamicTelemetry","text":"<p>DynamicTelemetry is a complex and highly technical subject that can be challenging for various job positions to navigate.</p> <p>By framing the book with personas, I aim to facilitate your focus on the most relevant content while allowing you to bypass information that is not immediately of interest. This approach should streamline the discovery of pertinent information.</p> <p>The personas are based on fictional job descriptions that reflect my experiences at Microsoft. They represent the target audiences for this book. I will endeavor to develop these personas and highlight common needs, confusions, preferences, and pain points.</p> <p>In the context of DynamicTelemetry, personas can be particularly beneficial in guiding users to find specific information. Given the extensive and technical nature of the topic, the vast amount of existing technologies, the design patters, and the core technical principles - you'll realize how it is to become overwhelmed by the details.</p> <p>I encourage you to utilize these personas when designing and architecting key components of DynamicTelemetry. This practice will help ensure that the content remains focused and relevant to our shared target audiences, preventing the book, accompanying websites, and supplementary software from becoming too broad or unfocused. Consequently, it will be easier for our readers to locate the information they seek.</p> <p>I will strive to use these personas as an organizational tool to structure the content effectively, providing a framework for determining which topics and ideas should be included and how they should be presented.</p>"},{"location":"docs/PositionPaper.ABTestingWithRichDiagnostics.document/","title":"A/B Testing","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ABTestingWithRichDiagnostics.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ABTestingWithRichDiagnostics.document/#positionpaperabtestingwithrichdiagnosticsdocumentmd-coming-soon","title":"PositionPaper.ABTestingWithRichDiagnostics.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.Actions.document/","title":"Actions","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.Actions.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.Actions.document/#positionpaperactionsdocumentmd-coming-soon","title":"PositionPaper.Actions.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.ClearFailuresViaSchema.document/","title":"Clearly defined failures","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ClearFailuresViaSchema.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ClearFailuresViaSchema.document/#positionpaperclearfailuresviaschemadocumentmd-coming-soon","title":"PositionPaper.ClearFailuresViaSchema.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.CloudAndEdgeInterop.document/","title":"Cloud and Edge Interop","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.CloudAndEdgeInterop.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.CloudAndEdgeInterop.document/#positionpapercloudandedgeinteropdocumentmd-coming-soon","title":"PositionPaper.CloudAndEdgeInterop.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.ConfigurationDeployment.document/","title":"ConfigurationDeployment","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ConfigurationDeployment.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ConfigurationDeployment.document/#configuration-deployment","title":"Configuration Deployment","text":""},{"location":"docs/PositionPaper.ConfigurationDeployment.document/#mechanisms","title":"Mechanisms","text":"<ol> <li> <p>All PROBE's must be intentionally    read-only</p> </li> <li> <p>Configuration Code Review; two trained employees verify the    PROBE will not collect unapproved    information.</p> </li> <li> <p>Ringed Deployment; instead of deploying to all machines, intantly, deploymens    can be deployed slowly</p> </li> <li> <p>'Rip Cords'; near instant disablement in the case of emergency</p> </li> </ol>"},{"location":"docs/PositionPaper.ConfigurationDeployment.document/#observer-effect","title":"Observer Effect","text":"<p>Observer Effect</p>"},{"location":"docs/PositionPaper.ConvertLogsToMetrics.document/","title":"Convert Logs to Metrics","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ConvertLogsToMetrics.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ConvertLogsToMetrics.document/#positionpaperconvertlogstometricsdocumentmd-coming-soon","title":"PositionPaper.ConvertLogsToMetrics.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.DataOwnershipIsntAlwaysClear.document/","title":"Data Ownership isnt always Clear","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.DataOwnershipIsntAlwaysClear.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.DataOwnershipIsntAlwaysClear.document/#positionpaperdataownershipisntalwayscleardocumentmd-coming-soon","title":"PositionPaper.DataOwnershipIsntAlwaysClear.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.DefiningProduction.document/","title":"Defining Production","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.DefiningProduction.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.DefiningProduction.document/#what-is-production","title":"What is Production?","text":"<p>The term 'production' needs to be clearly defined. Separate out topics like signing, data ownership, reliability, etc.</p>"},{"location":"docs/PositionPaper.DeliveryGuarantees.document/","title":"Delivery Guarantees","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.DeliveryGuarantees.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.DeliveryGuarantees.document/#delivery-guarantees-of-dynamic-telemetry-and-opentelemetry","title":"Delivery Guarantees of Dynamic Telemetry (and OpenTelemetry)","text":"<ol> <li>Telemetry must always be lossy; when push comes to shove</li> <li>Telemetry should never be lost, unless push has come to shove</li> </ol> <p>In simpler terms:</p> <ol> <li>It's never okay to lose telemetry on machines that have surplus memory</li> <li>It's usually not a good idea to store telemetry on disk, except in dire    emergency</li> <li>A delivery guarantee cannot be given to the users of telemetry - telemetry is    not a replacement for transaction processing</li> </ol> <p>Reason:</p> <ol> <li>Assume a service is operating nominally, servicing business needs</li> <li>Assume the telemetry backend locks up - perhaps a network outage</li> <li>A good telemetry system should queue, first to RAM, and maybe to disk</li> <li>As telemetry collects, at some point, a decision must be made</li> <li>start dropping telemetry</li> <li>stop servicing customer workloads</li> </ol> <p>The right answer is to continue servicing customer loads, and to stop dropping telemetry.</p>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/","title":"DurableIds_StructuredPayloads","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.DurableIds_StructuredPayloads.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#durable-ids-and-structured-payloads","title":"Durable ID's and Structured Payloads","text":"<p>In Telemetry/Observably, we often have need to locate the exact file and line of code that emitted a log message. We also often need to be able to decode the event, in ways that allow for searching and locating for arguments passed into that log event.</p> <p>Applications are many, but include reducing financial costs, quicker time to diagnosis by leveraging database tools and techniques, graphical tooling, visual pivoting, sorting, and time ordering aggregations. More advanced applications, that will be described later in this document, include \"triggering\" - where an event being emitted can be used to trigger memory dumps, CPU sampling, or even enable the production of more telemetry on command.</p> <p>Triggering dramatically expands opportunities in \"touchless\" (non-interactive) debugging. Triggers allow \"traps\" to be set for bugs, where the telemetry system can lay in wait, watching for a bug to manifest - and when it does! ...the TRIGGER can spring in action, capturing memory dumps, CPU call stack sampling, or even can dial up extra telemetry collection.</p> <p>The importance of DurableID's and Structured Payloads cannot be overstated - projects running on millions or billions of machines, that do not make use of API's equipped with DurableID's and Structured Payloads are almost a guaranteed to be on the path to either struggle to be diagnosed, or will be migrating within a few years to a new telemetry system. Of course, there are notable exceptions with niche applications; LED's, buzzers, and oscilloscopes also still serve their purpose, as do API's like syslog and printf.</p> <p>The claim isn't that API's without structured payloads and durable ID's aren't valuable; they are valuable - however in applications where one entity/company is responsible for managing millions of machines, with potentially billions of dollars in years telemetry expenses -the claim is these API's should be procedurally banned for the reasons outlined in this document.</p>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#introduction-its-all-about-positively-identifying-the-line-of-code","title":"Introduction : It's all about positively identifying the line of code","text":"<p>Lets start the introduction, by showing an event that contains both a DurableID and Structured Payload. We will then outline why the ID and payload are both important and valuable. In both examples, it's assumed there exists a means of egressing the telemetry to a remote database</p> <pre><code>    flowchart TD\n    subgraph Computer Being Traced\n        App --&gt; |FUNCTION_CALL|TELEMETRY_LIBRARY\n        TELEMETRY_LIBRARY --&gt; |ENCODED_DATA| OS\n        OS--&gt;Network_Egress_Application\n    end\n    Network_Egress_Application --&gt; |Network| Database\n</code></pre> <p>After the example, we will then outline why the Durable ID and Structured Payload is both important and valuable.</p>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#whats-success-looks-like","title":"Whats 'success' looks like","text":"<ol> <li>EXAMPLE #1 (GOOD!)</li> </ol> <pre><code>LoggingWrite(\n        g_Handle,\n        \"MemoryStatusUpdate\",               &lt;-- DurableID\n        LoggingUInt32(value, \"UpdateValue\") &lt;-- Structured Payload (U32/string)\n        );\n</code></pre>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#example-2-bad","title":"EXAMPLE #2 (BAD!)","text":"<pre><code>LoggingWrite(\"UPDATING VALUE: updating value to %d\", value);\n</code></pre>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#materially-how-do-these-differ","title":"Materially how do these differ?","text":"<p>In both these examples, the \"UpdateValue\" will be passed to the \"TELEMETRY_LIBRARY\" using a \"FUNCTION_CALL\", the \"TELEMETRY_LIBRARY\" will then encode the data using some means (discussed below), and then passed over the network, to a database, for insertion into a table.</p> <p>Before looking at the values in the database tables, imagine each of the examples are encoded in a similarly the below; this is the \"ENCODED_DATA\" boundary below - before being passed off to the Operating Systems telemetry plumbing.</p> <pre><code># EXAMPLE1: with DurableId/Structured Payload\n[DurableID][UdateValue]                          &lt;-- potentially compact\n\nvs.\n\n# EXAMPLE2 : without DurableID and Structured Payload\nUPDATING VALUE: updating value to &lt;value&gt;      &lt;-- not as compact\n</code></pre> <p>This difference is due to what we're calling \"flattening\" in this writeup. The term is defined more below; but the gist is the dynamic portions of the log are squished, by the TELEMETRY_LIBRARY into one string, before being passed into the telemetry subsystem.</p> <p>While both are equally useful for searching once entered into a database, the first example will be easier to search and filter. For example, the search query for \"what hour of the day are updates of value &gt; 10 most common?\"</p>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#what-is-flattening","title":"What is \"flattening\"","text":"<p>Only EXAMPLE#2 is flattening the payload - at the FUNCTION_CALL boundary the TELEMETRY_LIBRARY will be passed two items</p> <ol> <li>\"UPDATING VALUE: updating value to %d\"</li> <li>10</li> </ol> <p>Inside of TELEMETRY_LIBRARY, it'll then \"flatten\" these two values into one string \"UPDATING VALUE: updating value to 10\"</p> <p>From there, this string becomes the \"ENCODED_DATA\" passed into the Operating System, heading to be ingested into a Database Table.</p> <p>To start understanding why this is fatal to a TELEMETRY_LIBRARY, imagine the code in EXAMPLE#2 code executing three times - emitting the following strings into a database</p> <p>| Time | Message | | --- | --- | | 12:01:00 | UPDATING VALUE: updating value to 10 | | 12:02:00 | UPDATING VALUE: updating value to 23 | | 12:03:00 | UPDATING VALUE: updating value to 56 |</p> <p>...this doesn't seem horrible right? ...we'll expand why this is bad in a future section.</p> <p>But for now, to provide contrast - imagine the code in EXAMPLE#1 also executing three times - emitting the telemetry into a database</p> <p>| Time | DurableID | UpdateValue | | --- | --- | --- | | 12:01:00 | MemoryStatusUpdate | 10 | | 12:02:00 | MemoryStatusUpdate | 23 | | 12:03:00 | MemoryStatusUpdate | 56 |</p> <p>Notice how each of these entries coming from EXAMPLE#1 more organized? While the data from EXAMPLE#2 potentially can be searched in an emergency, doing this programmatically will be so difficult it needs to be considered impossible in all situations but real problem.</p> <p>The root problem is that in the database, we cannot positively identify the file+line of code that produced the telemetry</p>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#applications","title":"Applications","text":"<p>Applications for DurableID's and Structured Payloads are not hard to discover, once one starts looking.</p> <p>The \"trick\" to finding applications is the realization that any event can be searched, located, and aggregated quickly.</p> <p>The searching doesn't have to be limited to a database - it's common to have on box searching (aka \"TRIGGERING\"). Triggering only means having a program (usually one that is configured dynamically) to \"trigger\" when a particular event, with particular payload, is encountered.</p>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#durableid-applications","title":"DurableID Applications","text":"<ol> <li>Cost Reduction; locating particularly expensive lines of code</li> <li>Graphical Tooling; searching/sorting/partitioning of data (WPA, Excel)</li> <li>Event Down-Sampling (eg: \"collect all events but this set ...\")</li> <li>Event Up-Sampling (eg: \"only collect this set of events ...\")</li> </ol>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#structured-payloads","title":"Structured Payloads","text":"<ol> <li> <p>Cost Reduction</p> </li> <li> <p>Locating expensive failure conditions, or cases where code changes are       needed</p> </li> <li> <p>Minimizing Database compute time, by indexing on values</p> </li> <li> <p>Diagnostic Triggering (more below)</p> </li> <li> <p>CPU Sampling</p> </li> <li>Memory Dumps</li> <li>Verbose Logging</li> <li>Packet Capture</li> </ol>"},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#appendix","title":"Appendix","text":""},{"location":"docs/PositionPaper.DurableIds_StructuredPayloads.document/#second-example","title":"Second Example","text":"<pre><code>Line 000010 : printf(\"ALLOC(%d bytes) for %s\", size, bufferName1);\n              //business logic\nLine 001000 : printf(\"FREE(%s)\", bufferName1);\n              //more business logic\nLine 100000 : printf(\"FREE(%s)\", bufferName2)\n</code></pre> <pre><code>|  Time    | Message                             |\n|    ---   | ---                                 |\n| 12:00:00 | ALLOC(10 bytes) for database_open   |\n| 12:01:00 | ERROR: unable to open file foo.txt  |\n| 12:02:02 | ALLOC(10 bytes) for network_open    |\n| 12:02:00 | ERROR: unable to open file bar.txt  |\n| 12:02:01 | FREE(network_open)                  |\n| 12:02:02 | ERROR: unable to open file bar.txt  |\n| 12:02:01 | FREE(database_open)                 |\n| 12:03:00 | ERROR: unable to open file baz.txt  |\n</code></pre> <p>While this may not superficially \"look bad\" when costs and scale are small; over time, we'll face a problem where it's unclear where this code originates.</p> <ol> <li>Lines 1000 and 100000 have identical strings (\"FREE(%s))</li> <li>Line 10 is repeated; at 12:00:00 and 12:02:02</li> </ol>"},{"location":"docs/PositionPaper.DynamicTelemetryTenets.document/","title":"Tenets","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.DynamicTelemetryTenets.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.DynamicTelemetryTenets.document/#tenets","title":"Tenets","text":"<ol> <li>Leverage existing technology, before creating new</li> <li>Be philosophically indifferent to tooling, operating systems, or    environment</li> <li>Offer recommendable decisions, make decisions, to those who ask</li> <li>By intent do not modify system state and minimize the Observer Effect</li> <li>Be clear where the Observer Effect can impact, with clear awareness and    options for mitigation</li> </ol>"},{"location":"docs/PositionPaper.DynamicallyToggleLogs.document/","title":"DynamicallyToggleLogs","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.DynamicallyToggleLogs.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.DynamicallyToggleLogs.document/#positionpaperdynamicallytogglelogsdocumentmd-coming-soon","title":"PositionPaper.DynamicallyToggleLogs.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.ExternalAuditsOfProductionCode.document/","title":"External Audits of Production Code","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ExternalAuditsOfProductionCode.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ExternalAuditsOfProductionCode.document/#positionpaperexternalauditsofproductioncodedocumentmd-coming-soon","title":"PositionPaper.ExternalAuditsOfProductionCode.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.FileAndStreaming.document/","title":"FileAndStreaming","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.FileAndStreaming.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.FileAndStreaming.document/#coming-soon-file-vs-streaming-telemetry","title":"(COMING SOON) FILE vs. STREAMING Telemetry","text":""},{"location":"docs/PositionPaper.FileAndStreaming.document/#introduction","title":"Introduction","text":"<p>DynamicTelemetry defines two types of telemetry - STREAMING, and FILE_BASED.</p> <ul> <li>STREAMING : typical Observability - intended for immediate egress, flowing   into backend databases.</li> <li>FILE_BASED : telemetry that doesn't stream well, memory dumps, CPU samples,   packet captures, or FLIGHT_RECORDERS - only transmitted upon a failure</li> </ul>"},{"location":"docs/PositionPaper.FileAndStreaming.document/#streaming-telemetry","title":"STREAMING Telemetry","text":"<p>OpenTelemetry is the recommended Observability API surface for DynamicTelemetry. The essence of STREAMING telemetry is to capture observations/logs and upload them to a network-connected backend as soon as possible.</p> <p>STREAMING telemetry has three common subtypes: Logs, Metrics, and Traces. These subtypes share the common goal of egressing the telemetry data as quickly as possible.</p> <p>A key differentiator between STREAMING telemetry and FILE_BASED telemetry is that STREAMING telemetry is always emitted, whereas FILE_BASED telemetry is only transmitted upon request, usually in the event of a failure.</p> <p>OpenTelemetrys website is a great resource to better understand STREAMING telemetry.</p>"},{"location":"docs/PositionPaper.FileAndStreaming.document/#file_based-telemetry","title":"FILE_BASED Telemetry","text":"<p>FILE_BASED telemetry is similar to STREAMING telemetry in that it can emit logs, metrics, and traces. However, the key difference lies in its ability to capture high-fidelity content, such as memory dumps, packet captures, or CPU samples.</p> <p>Unlike STREAMING telemetry, which is continuously emitted, FILE_BASED telemetry is only uploaded when necessary, typically in the event of a failure.</p>"},{"location":"docs/PositionPaper.FileAndStreaming.document/#references","title":"References","text":"<ol> <li>Flight Recorder</li> </ol>"},{"location":"docs/PositionPaper.FlightRecorder.document/","title":"FlightRecorder","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.FlightRecorder.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.FlightRecorder.document/#positionpaperflightrecorderdocumentmd-coming-soon","title":"PositionPaper.FlightRecorder.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.GuideToLogVerbosity.document/","title":"GuideToLogVerbosity","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.GuideToLogVerbosity.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.GuideToLogVerbosity.document/#positionpaperguidetologverbositydocumentmd-coming-soon","title":"PositionPaper.GuideToLogVerbosity.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.InternalAuditsOfProductionCode.document/","title":"Internal Audits of Production Code","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.InternalAuditsOfProductionCode.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.InternalAuditsOfProductionCode.document/#positionpaperinternalauditsofproductioncodedocumentmd-coming-soon","title":"PositionPaper.InternalAuditsOfProductionCode.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.LeafLevelLogging.document/","title":"Locks and Throttles","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.LeafLevelLogging.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.LeafLevelLogging.document/#positionpaperleaflevelloggingdocumentmd-coming-soon","title":"PositionPaper.LeafLevelLogging.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.ObserverEffect.document/","title":"ObserverEffect","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ObserverEffect.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ObserverEffect.document/#the-observer-effect","title":"The Observer Effect","text":"<p>The Observer Effect in physics refers to the phenomenon where the act of observing a system inevitably alters its state. This effect is often due to the instruments used for measurement, which can interfere with the system being observed. A classic example is the double-slit experiment in quantum mechanics, where the presence of a detector changes the behavior of particles.,</p> <p>Telemetry involves the collection of data that can influence the system being monitored. One of the main risks of telemetry is the potential for reliability and performance issues, as without care, its possible for the telemetry itself to negatively influence the performance of the system -- and in some cases even create crashes or failures. Both telemetry and the Observer Effect demonstrate the balance between gaining insights and the unintended consequences of measurement.</p> <p>Comparing the two, while the Observer Effect is a fundamental concept in physics that underscores the limitations of measurement at a quantum level, telemetry's risks are more practical and immediate, impacting system performance and reliability. In both cases, the challenge lies in minimizing the impact of observation to ensure accurate and reliable data collection. Techniques such as using less intrusive measurement tools in physics or implementing robust privacy safeguards in telemetry can help mitigate these risks.</p>"},{"location":"docs/PositionPaper.ObserverEffect.document/#probes-and-actions","title":"Probes and Actions","text":"<p>Different probes used in telemetry and diagnostics come with their own set of risks. For instance,dynamic probesin DynamicTelemetry can introduce performance overhead, potentially affecting the system's efficiency and reliability. These probes gather minimal amounts of memory and transform them into standard OpenTelemetry Logs, which can then be fed into existing telemetry pipelines. However, the process of setting up these probes, such as using software or hardware breakpoints and eBPF may not always align with the performance and reliability of their destination environment.</p>"},{"location":"docs/PositionPaper.ObserverEffect.document/#reliability-concerns","title":"Reliability Concerns","text":"<p>Of particular concern is the possibility that certain probe types may inadvertently alter the reliability characteristics of a monitored system. In some embodiments of telemetry, such as Event Tracing for Windows (ETW), it is possible that merely listening to an event could cause the telemetry producer to crash, hang, or otherwise enter a failing system state.</p>"},{"location":"docs/PositionPaper.ObserverEffect.document/#performance-concerns","title":"Performance Concerns","text":"<p>Lastly, theimpact on system performanceis a significant concern. Probes, especially those that enable CPU sampling or induce memory dumps, can introduce latency and affect the overall performance of the system This is particularly true for actions that involve diagnostic operations, which, while not altering the system state, can still impact performance. Therefore, it is essential to balance the need for detailed telemetry with the potential performance costs.</p>"},{"location":"docs/PositionPaper.ObserverEffect.document/#taxonomy-for-evaluating-probe-and-action-risk","title":"Taxonomy for Evaluating Probe and Action Risk","text":"<p>The Dynamic Telemetry system has developed a comprehensive taxonomy for both probes and actions, recognizing that perceptions of operational risk vary among different usage personas, and hosting environments. This taxonomy enables DevOps teams, program managers, and developers to collaboratively assess risks in a manner tailored to their specific environmental needs.</p> <p>Due to the extensive nature and potential changes in this taxonomy, a dedicated section in the architecture documents covers dynamic telemetry. This section will comprehensively describe how to quantify, measure, and communicate the risks to different personas. Each of the various probes and actions can be evaluated using a spider chart similar to, but not identical to, the example below.</p> <p> </p> <p>In the above charts you'll see that the more area is shaded the more risk the particular probe or action type brings. ETW (Windows), when configured incorrectly may inadvertency modify system behavior - whereas eBPF intentionally modifies system behavior, and therefore presents more risks to the different user personas.</p> <p>It is often also the case that with more risk comes more performance or more flexibility.</p> <p>Dynamic Telemetry mandates that a [probe must not intentionally alter system state]{.underline}. This does not preclude the use of a probe type akin to the ETW event in Windows with Dynamic Telemetry; however, it does mean that the application of ETW within dynamic telemetry must not modify the system state. Although this may initially seem prohibitively costly during a quick read of this chapter; further details and expansion can be found within the linked architecture section.</p>"},{"location":"docs/PositionPaper.ObserverEffect.document/#implications-on-deployment","title":"Implications on Deployment","text":"<p>Implementations of Dynamic Telemetry must clearly communicate these requirements at the configuration deployment stage using suitable gates, deployment rings, and communication systems for the hosting environment.</p>"},{"location":"docs/PositionPaper.PositionPapers.Overview.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.PositionPapers.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.PositionPapers.Overview.document/#positionpaperpositionpapersoverviewdocumentmd-coming-soon","title":"PositionPaper.PositionPapers.Overview.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.ProbeRiskLevels.document/","title":"ProbeRiskLevels","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ProbeRiskLevels.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ProbeRiskLevels.document/#coming-soon","title":"Coming Soon","text":""},{"location":"docs/PositionPaper.ProbeRiskLevels.document/#probe-risk-levels","title":"Probe Risk Levels","text":""},{"location":"docs/PositionPaper.ProbeRiskLevels.document/#dimensions","title":"Dimensions","text":"<ol> <li>Privacy Elevation</li> <li>Security Elevation</li> <li>Reliability(Observer Effect)</li> <li>Costs    (Durable ID's and Structured Payloads)</li> <li>Performance(Observer Effect)</li> </ol>"},{"location":"docs/PositionPaper.ProbeRiskLevels.document/#no-risk","title":"No Risk","text":""},{"location":"docs/PositionPaper.ProbeRiskLevels.document/#limited-risk","title":"Limited Risk","text":""},{"location":"docs/PositionPaper.ProbeRiskLevels.document/#high-risk","title":"High Risk","text":""},{"location":"docs/PositionPaper.ProbeRiskLevels.document/#appendix","title":"Appendix","text":"<ol> <li>Observer Effect</li> <li>Durable ID's and Structured Payloads</li> </ol>"},{"location":"docs/PositionPaper.ProbeToHeader.document/","title":"Probe to Header","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ProbeToHeader.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ProbeToHeader.document/#positionpaperprobetoheaderdocumentmd-coming-soon","title":"PositionPaper.ProbeToHeader.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.ProceduralizeNets.document/","title":"Procedural Nets","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ProceduralizeNets.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ProceduralizeNets.document/#procedural-nets","title":"Procedural Nets","text":""},{"location":"docs/PositionPaper.ScarcityAndHumans/","title":"Impacts of Scarcity","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.ScarcityAndHumans.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.ScarcityAndHumans/#positionpaperscarcityandhumansmd-coming-soon","title":"PositionPaper.ScarcityAndHumans.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.SelfDescribingProductionCode.document/","title":"Self Describing Production Code","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.SelfDescribingProductionCode.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.SelfDescribingProductionCode.document/#positionpaperselfdescribingproductioncodedocumentmd-coming-soon","title":"PositionPaper.SelfDescribingProductionCode.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.SharingDataAmongStakeHoldersIsHard.document/","title":"Loose Schemas","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.SharingDataAmongStakeHoldersIsHard.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.SharingDataAmongStakeHoldersIsHard.document/#coming-soon","title":"Coming Soon","text":"<p>Points:</p> <ol> <li>Dynamic Telemetry takes a hard position on rigid schema - \"no\"</li> <li>Dynamic Telemetry takes a hard position on    Durable ID and structured payloads    - \"YES\"</li> </ol> <p>Dynamic Telemetry requires the ability to identify and decode a log, metric, or trace. However, it does not enforce that the structured payload conforms to a schema.</p> <p>This enforcement is useful in many applications but needs to be enforced at a higher level than Dynamic Telemetry.</p> <p>If a user of Dynamic Telemetry desires a rigid schema, this is totally acceptable. They should look for, or author, a language processor to fulfill this task.</p> <p>A keen reader of the Dynamic Telemetry documentation will notice potential incongruity found in the design pattern documentation. Specifically, the design patterns discussed have rigid schemas as their core value proposition. This is potentially something that should be further discussed if the design patterns are included in Dynamic Telemetry or built atop it.</p> <p>Please see Rude Q&amp;A for more information</p>"},{"location":"docs/PositionPaper.TelemetryUmbilical.document/","title":"TelemetryUmbilical","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.TelemetryUmbilical.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.TelemetryUmbilical.document/#telemetry-umbilical-incomplete","title":"Telemetry UMBILICAL : INCOMPLETE","text":""},{"location":"docs/PositionPaper.TelemetryUmbilical.document/#talking-points","title":"Talking Points","text":"<ol> <li>Two Types of Telemetry    {file, streaming}</li> <li>All telemetry for a partition {container, VM, or Host} must only use 2x    sockets - multiple apps need to be aggregated / multiplexed</li> <li>The 'umbilical' is a choke point; that has standard 'pipe fittings'</li> <li>The umbilical can be 'cut' and rerouted - such that there are only two    locations per 'partition' {container, VM, Host} to be cut, should    (re)routing, filtering, need to occur</li> </ol>"},{"location":"docs/PositionPaper.TelemetryUmbilical.document/#importance-of-the-umbilical-on-privacy","title":"Importance of the UMBILICAL on PRIVACY","text":""},{"location":"docs/PositionPaper.TestingWithEntropy.document/","title":"Testing With Entropy","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.TestingWithEntropy.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.TestingWithEntropy.document/#positionpapertestingwithentropydocumentmd-coming-soon","title":"PositionPaper.TestingWithEntropy.document.md  : COMING SOON","text":""},{"location":"docs/PositionPaper.TraditionalTesting/","title":"Traditional Testing","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.TraditionalTesting.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.TraditionalTesting/#positionpapertraditionaltestingmd-coming-soon","title":"PositionPaper.TraditionalTesting.md : COMING SOON","text":""},{"location":"docs/PositionPaper.TriggeredCollections.document/","title":"Triggered Collections","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.TriggeredCollections.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.TriggeredCollections.document/#positionpapertriggeredcollectionsdocumentmd-coming-soon","title":"PositionPaper.TriggeredCollections.document.md : COMING SOON","text":""},{"location":"docs/PositionPaper.TriggeredFlightRecorder.document/","title":"TriggeredFlightRecorder","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.TriggeredFlightRecorder.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.TriggeredFlightRecorder.document/#positionpapertriggeredflightrecorderdocumentmd-coming-soon","title":"PositionPaper.TriggeredFlightRecorder.document.md : COMING SOON","text":""},{"location":"docs/PositionPaper.TriggeredMemoryDump.document/","title":"TriggeredMemoryDump","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.TriggeredMemoryDump.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.TriggeredMemoryDump.document/#positionpapertriggeredmemorydumpdocumentmd-coming-soon","title":"PositionPaper.TriggeredMemoryDump.document.md : COMING SOON","text":""},{"location":"docs/PositionPaper.WhereToSuppressInProc.document/","title":"Suppressing and Pushing Stack Args","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/PositionPaper.WhereToSuppressInProc.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/PositionPaper.WhereToSuppressInProc.document/#coming-soon-positionpaperwheretosuppressinprocdocumentmd","title":"Coming Soon : PositionPaper.WhereToSuppressInProc.document.md","text":""},{"location":"docs/README.EDITING.CONTAINER/","title":"Using Doc Editing Container","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/README.EDITING.CONTAINER.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/README.EDITING.CONTAINER/#using-the-markdown-editing-container","title":"Using the Markdown editing container","text":"<p>MkDocs is our markdown rendering in Dynamic Telemetry, providing a pleasant looking markdown-to-HTML converter that integrates well with GitHub.</p> <p>Because MkDocs depends on Python, versioning issues can arise. To avoid these complications, a single Docker or Podman container is used, bundling MkDocs, Python, and all required tools.</p> <p>Using the container is straightforward, involving two steps - one of which is a one-time setup.</p>"},{"location":"docs/README.EDITING.CONTAINER/#installation","title":"Installation","text":"<ol> <li> <p>Install Docker or Podman from https://www.docker.com</p> </li> <li> <p>From the tools directory in DynamicTelemetry, build the container using:</p> <pre><code>docker build -f\n      Dockerfile.mkdocs -t \"dynamictelemetry/dynamictelemetry:mkdocs\" .\n</code></pre> </li> <li> <p>Once the build process is complete, simply use the container. In a workflow    that looks something like this.</p> </li> <li> <p>In a Stand alone. terminal window, use 'docker compose up' command.    which will monitor Profile changes and update accordingly.</p> <pre><code>docker compose up\n</code></pre> <ul> <li>Make changes to the documentation.</li> <li>View the changes in your local web browser         http://localhost:8000</li> </ul> </li> </ol>"},{"location":"docs/ReviewProcess.document/","title":"Process","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/ReviewProcess.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/ReviewProcess.document/#review-process","title":"Review Process","text":"<p>Because there are many stakeholders and dynamic telemetry, each document has a header that describes the state of review.</p> <p>Below are the different stages:</p>"},{"location":"docs/ReviewProcess.document/#stages-of-review","title":"Stages of Review","text":""},{"location":"docs/ReviewProcess.document/#reviewlevel1-incomplete","title":"ReviewLevel1 (Incomplete)","text":"<p>Placeholder; incomplete or unwritten</p>"},{"location":"docs/ReviewProcess.document/#reviewlevel1b-talking-points","title":"ReviewLevel1b (Talking Points)","text":"<p>ReviewLevel1 plus talking points are enumerated</p>"},{"location":"docs/ReviewProcess.document/#reviewlevel2-pre-draft","title":"ReviewLevel2 (PRE-DRAFT)","text":"<p>ReviewLeverl 1b, plus document has been written</p>"},{"location":"docs/ReviewProcess.document/#reviewlevel3-draft","title":"ReviewLevel3 (DRAFT)","text":"<p>ReviewLevel2, but in in review</p>"},{"location":"docs/ReviewProcess.document/#reviewlevel4-pending","title":"ReviewLevel4 (PENDING)","text":"<p>ReviewLevel3, but generally accepted</p>"},{"location":"docs/ReviewProcess.document/#reviewlevel5-complete","title":"ReviewLevel5 (COMPLETE)","text":"<p>ReviewLevel4, signed off</p>"},{"location":"docs/ReviewProcess.document/#status-of-documents","title":"Status of Documents","text":""},{"location":"docs/ReviewProcess.document/#individual-status","title":"Individual Status","text":"<p>author: Generated File status: Level5</p>"},{"location":"docs/ReviewProcess.document/#level1b","title":"Level1b","text":"File Word Count ../docs/Applications.FlightRecorder.MemoryLeak.document.md 211 ../docs/Applications.FlightRecorder.PriorToCrash.document.md 252 ../docs/Architecture.Action.Explanation.document.md 124 ../docs/Architecture.Components.FiltersAndRouters.document.md 44 ../docs/Architecture.Components.Observer.InProcess.document.md 53 ../docs/Architecture.Components.Observer.Kernel.document.md 68 ../docs/Architecture.Components.Streaming.Observability.document.md 59 ../docs/Architecture.FlightRecorder.LongHorizons.document.md 795 ../docs/Architecture.FlightRecorder.Overview.document.md 919 ../docs/Architecture.FlightRecorder.ShortHorizons.document.md 618 ../docs/Architecture.FlightRecorder.TraceHorizons.document.md 466 ../docs/Architecture.KeyConstructs.Overview.document.md 440 ../docs/Architecture.Overview.document.md 212 ../docs/Demos.1.DropChattyLog.md 1103 ../docs/Demos.2_DynamicProbe.md 277 ../docs/Demos.4.AddTelemetryDemo.md 1078 ../docs/Demos.HighLevel.Overview.md 1187 ../docs/PositionPaper.DeliveryGuarantees.document.md 163 ../docs/PositionPaper.DynamicTelemetryTenets.document.md 67 ../docs/PositionPaper.FileAndStreaming.document.md 227 ../docs/PositionPaper.ObserverEffect.document.md 728 ../docs/PositionPaper.SharingDataAmongStakeHoldersIsHard.document.md 171 ../docs/PositionPaper.TelemetryUmbilical.document.md 95 ../docs/Rude_Q_and_A.md 748 ../docs/Scenarios.Overview.CostReduction.document.md 1368 ../docs/Scenarios.Overview.DeepDiagnostics.document.md 757 ../docs/Scenarios.Overview.document.md 180 ../docs/Scenarios.Overview.DurableDashboards.Alerts.document.md 552 ../docs/Scenarios.Overview.RedactingSecrets.document.md 1084 ../docs/Scenarios.Overview.Reliability.document.md 2247"},{"location":"docs/ReviewProcess.document/#level1","title":"Level1","text":"File Word Count ../docs/Applications.InterestingApplications.document.md 10 ../docs/Applications.Overview.InterestingApplications.document.md 7 ../docs/Architecture.Action.ConfigCollection.document.md 13 ../docs/Architecture.Action.CPUSample.document.md 13 ../docs/Architecture.Action.FileCollection.document.md 13 ../docs/Architecture.Action.FlightRecorder.document.md 33 ../docs/Architecture.Action.MemoryDump.document.md 10 ../docs/Architecture.Action.PacketCapture.document.md 14 ../docs/Architecture.Action.ProcessExecution.document.md 13 ../docs/Architecture.Action.StateCollection.document.md 13 ../docs/Architecture.Action.VerboseLogs.document.md 13 ../docs/Architecture.Components.FileBased.Observability.document.md 10 ../docs/Architecture.Components.Observer.External.OffBox.document.md 97 ../docs/Architecture.Components.Observer.External.OnBox.document.md 62 ../docs/Architecture.Components.ProcessorInstallation.Overview.document.md 46 ../docs/Architecture.DesignPatterns.Counters.document.md 10 ../docs/Architecture.DesignPatterns.DesignPatterns.Overview.document.md 14 ../docs/Architecture.DesignPatterns.Queues.document.md 10 ../docs/Architecture.DesignPatterns.Toggles.document.md 10 ../docs/Architecture.DesignPatterns.Triggers.document.md 10 ../docs/Architecture.DesignPatterns.Valves.document.md 10 ../docs/Architecture.FlightRecorder.CubbyHole.document.md 15 ../docs/Architecture.Probe.Breakpoint.document.md 97 ../docs/Architecture.Probe.DTrace.document.md 18 ../docs/Architecture.Probe.eBPF.document.md 13 ../docs/Architecture.Probe.ETW.document.md 13 ../docs/Architecture.Probe.OpenTelemetry.document.md 13 ../docs/Architecture.Probe.ptrace.document.md 13 ../docs/Architecture.Probe.uprobes.document.md 13 ../docs/Architecture.Probe.user_events.document.md 13 ../docs/Definitions.document.md 161 ../docs/Demos.0.DynamicID.md 722 ../docs/Persona_DataAnalysis.document.md 122 ../docs/Persona_Developer.document.md 183 ../docs/Persona_DevOps.document.md 110 ../docs/Persona_ProjectManager.document.md 121 ../docs/PositionPaper.ABTestingWithRichDiagnostics.document.md 12 ../docs/PositionPaper.Actions.document.md 12 ../docs/PositionPaper.ClearFailuresViaSchema.document.md 12 ../docs/PositionPaper.CloudAndEdgeInterop.document.md 12 ../docs/PositionPaper.ConfigurationDeployment.document.md 65 ../docs/PositionPaper.ConvertLogsToMetrics.document.md 12 ../docs/PositionPaper.DataOwnershipIsntAlwaysClear.document.md 12 ../docs/PositionPaper.DefiningProduction.document.md 28 ../docs/PositionPaper.DynamicallyToggleLogs.document.md 12 ../docs/PositionPaper.ExternalAuditsOfProductionCode.document.md 12 ../docs/PositionPaper.FlightRecorder.document.md 12 ../docs/PositionPaper.GuideToLogVerbosity.document.md 12 ../docs/PositionPaper.InternalAuditsOfProductionCode.document.md 12 ../docs/PositionPaper.LeafLevelLogging.document.md 12 ../docs/PositionPaper.PositionPapers.Overview.document.md 12 ../docs/PositionPaper.ProbeRiskLevels.document.md 55 ../docs/PositionPaper.ProbeToHeader.document.md 12 ../docs/PositionPaper.ProceduralizeNets.document.md 11 ../docs/PositionPaper.ScarcityAndHumans.md 12 ../docs/PositionPaper.SelfDescribingProductionCode.document.md 12 ../docs/PositionPaper.TestingWithEntropy.document.md 12 ../docs/PositionPaper.TraditionalTesting.md 12 ../docs/PositionPaper.TriggeredCollections.document.md 12 ../docs/PositionPaper.TriggeredFlightRecorder.document.md 12 ../docs/PositionPaper.TriggeredMemoryDump.document.md 12 ../docs/PositionPaper.WhereToSuppressInProc.document.md 12 ../docs/ReviewProcess.document.md 98 ../docs/Scenarios.ChangingEnvironments.document.md 15 ../docs/Scenarios.ConvertLogsToMetrics.document.md 15 ../docs/Scenarios.EventAggregation.document.md 15 ../docs/Scenarios.EventFieldSuppression.document.md 16 ../docs/Scenarios.EventSuppression.document.md 15 ../docs/Scenarios.ExtractingMemoryWithUProbe.document.md 15 ../docs/Scenarios.MemoryLeak.document.md 14 ../docs/Slides.Overview.Presentation.md 377"},{"location":"docs/ReviewProcess.document/#level2","title":"Level2","text":"File Word Count ../docs/Architecture.Components.Processor.Language.md 476 ../docs/Architecture.Components.Processor.Overview.document.md 952 ../docs/Architecture.Components.Processor.QueryLanguage.document.md 349 ../docs/Architecture.Components.Processor.StateMachine.document.md 475 ../docs/Architecture.Probes.Overview.document.md 1405 ../docs/index.md 362 ../docs/Personas.Overview.document.md 257 ../docs/PositionPaper.DurableIds_StructuredPayloads.document.md 1242"},{"location":"docs/Rude_Q_and_A/","title":"Rude Q&A","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Rude_Q_and_A.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Rude_Q_and_A/#rude-questions-and-answers","title":"\"Rude\" Questions and Answers","text":"<p>This section addresses commonly asked questions that are challenging or difficult. It is called \"Rude Q and A\" because it encourages asking tough, awkward, or uncomfortable questions.</p> <p>Please be polite when asking questions here, but do not feel the need to create a false sense of harmony. This page is for addressing difficult problems directly.</p>"},{"location":"docs/Rude_Q_and_A/#deployment-too-fast-accelerated-problems-too-slow-decelerated-solution","title":"Deployment; too fast = accelerated problems, too slow = decelerated solution","text":"<p>The rate of deployment is a double-edged sword. On one hand, deploying quickly can help scale solutions, such as scrubbing a security credential. On the other hand, if your attempt to diagnose or scrub itself has an error, you can end up increasing risks to a user.</p> <p>This section of Rude Q and A covers deployments in this dilemma.</p>"},{"location":"docs/Rude_Q_and_A/#q1-dont-deployments-carry-risks","title":"Q1: Don't deployments carry risks","text":"<p>Deployments carry risks; code or configuration - doesn't Dynamic Telemetry encourage accelerated deployments, and won't that carry risks?</p>"},{"location":"docs/Rude_Q_and_A/#a1-yes-there-are-risks-but-there-is-also-a-taxonomy-for-understanding","title":"A1: Yes, there are risks; but there is also a taxonomy for understanding","text":"<p>The Observer Effect document covers this topic at a high level. It's important to know that 100% of all Probes, Actions, and Processors in Dynamic Telemetry are intentionally read-only. This is not to say that Dynamic Telemetry's implementation is bug-free. However, by design and intent, no part of Dynamic Telemetry should alter your system state.</p> <p>An interesting discussion should be started about where the line is and if it can be enforced technically, or if it's strictly a business problem that can be solved through policy and taxonomy. As a thought experiment, consider a database that has update policies that are run on ingestion and used for versioning. Most reasonable people can agree that this is a useful feature of a database and is something that an administrator can apply nearly instantaneously. To reject the ability for Dynamic Telemetry to have dynamic deployments is akin to rejecting this capability. The question only seems to be where the balance is and how to map that balance into the business needs.</p> <p>Unfortunately, are cases where risks are present. For example, CPU sampling can impact performance, memory dumps will pause your threads, and extracting memory can pose security risks.</p> <p>Dynamic Telemetry offers a taxonomy of risk measurement used in actions and probes. This taxonomy clearly communicates the risks to business decision-makers, allowing them to choose which probes and actions are permissible in their environment and under what deployment constraints.</p>"},{"location":"docs/Rude_Q_and_A/#security","title":"Security","text":"<p>A serious concern in Dynamic Telemetry is that an adversary who gains the ability to deploy dynamic probes into a memory space potentially has the ability to extract sensitive information such as passwords, tokens, and credentials. Another attack vector could be enabling a row of logging that had been previously suppressed or set at a lower capture level.</p> <p>This section covers those topics.</p>"},{"location":"docs/Rude_Q_and_A/#q2-can-memory-extraction-probes-be-used-by-an-adversary-to-extract-memory","title":"Q2: Can memory extraction probes be used by an adversary to extract memory?","text":""},{"location":"docs/Rude_Q_and_A/#a2-potentially-care-must-be-taken","title":"A2: Potentially. Care must be taken","text":"<p>A memory extraction probe is one of the more flexible and useful tools in Dynamic Telemetry. Built upon technologies such as DTrace, Ptrace, uprobes, and kprobes, it allows for detailed memory analysis. However, if an adversary compromises the deployment of Dynamic Telemetry configuration, they may be able to extract memory, potentially leading to a system compromise.</p> <p>This is similar to being in control of any form of system deployment or CI/CD pipeline.</p> <p>An attacker would also need access to the backend databases to harvest the extracted memory.</p> <p>Use of a memory extraction probe should be done in a contained environment, using secure workstations, and following extra processes and procedures that likely include audits.</p>"},{"location":"docs/Rude_Q_and_A/#potentially-confused-topics","title":"Potentially Confused Topics","text":"<p>The section below focuses less on security, privacy, or logistical deployment risks and more on the architecture and potential conflicts in design. For example, it appears contradictory to state that Dynamic Telemetry does not have rigid schemas while simultaneously offering capabilities built upon rigid schemas.</p>"},{"location":"docs/Rude_Q_and_A/#q3-dynamic-telemetry-takes-a-position-of-no-rigid-schemas","title":"Q3 : Dynamic Telemetry takes a position of no rigid schemas??","text":"<p>....isn't this at odds with the value prop of Design Patterns?</p> <p>reading material</p>"},{"location":"docs/Rude_Q_and_A/#a3-maybe-its-something-we-should-discuss","title":"A3 : Maybe.. it's something we should discuss","text":"<p>A keen reader of the Dynamic Telemetry documentation will notice potential incongruity found in the design pattern documentation. Specifically, the design patterns discussed have rigid schemas as their core value proposition. This is potentially something that should be further discussed if the design patterns are included in Dynamic Telemetry or built atop it.``</p>"},{"location":"docs/Scenarios.ChangingEnvironments.document/","title":"Changing Environments","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.ChangingEnvironments.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.ChangingEnvironments.document/#changing-environments-telemetry-umbilical-coming-soon","title":"Changing Environments (Telemetry Umbilical) : COMING SOON","text":""},{"location":"docs/Scenarios.ConvertLogsToMetrics.document/","title":"Convert Logs to Metrics","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.ConvertLogsToMetrics.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.ConvertLogsToMetrics.document/#convert-logs-to-metrics-coming-soon","title":"Convert Logs To Metrics : COMING SOON","text":""},{"location":"docs/Scenarios.EventAggregation.document/","title":"Event Aggregation","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.EventAggregation.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.EventAggregation.document/#event-aggregation-and-suppression-coming-soon","title":"Event Aggregation and Suppression : Coming Soon","text":""},{"location":"docs/Scenarios.EventFieldSuppression.document/","title":"EventFieldSuppression","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.EventFieldSuppression.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.EventFieldSuppression.document/#suppressing-logtrace-fields-for-privacy-coming-soon","title":"Suppressing Log/Trace Fields (for Privacy) : COMING SOON","text":""},{"location":"docs/Scenarios.EventSuppression.document/","title":"EventSuppression","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.EventSuppression.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.EventSuppression.document/#suppressing-a-chatty-event-coming-soon","title":"Suppressing a chatty Event : COMING SOON","text":""},{"location":"docs/Scenarios.ExtractingMemoryWithUProbe.document/","title":"ExtractingMemoryWithUProbe","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.ExtractingMemoryWithUProbe.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.ExtractingMemoryWithUProbe.document/#extracting-memory-with-uprobes-coming-soon","title":"Extracting Memory With UProbes : Coming Soon","text":""},{"location":"docs/Scenarios.MemoryLeak.document/","title":"MemoryLeak","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.MemoryLeak.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.MemoryLeak.document/#scenario-memory-leaks-coming-soon","title":"Scenario Memory Leaks : Coming Soon","text":""},{"location":"docs/Scenarios.Overview.CostReduction.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.Overview.CostReduction.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.Overview.CostReduction.document/#reducing-costs","title":"Reducing Costs","text":"<p>Dynamic Telemetry is a powerful tool that can be used to significantly reduce costs by converting logs into metrics dynamically. This capability allows organizations to gain valuable insights without the overhead of storing and processing large volumes of log data. By transforming logs into metrics, businesses can focus on the most critical data points, leading to more efficient resource utilization and cost savings.</p> <p>One of the key features of Dynamic Telemetry is its ability to measure and suppress chatty telemetry. Chatty telemetry refers to the excessive and often redundant logging that can occur in a system, leading to increased storage and processing costs. With Dynamic Telemetry, organizations can rapidly turn off and turn on chatty logs, ensuring that only the most relevant data is captured and analyzed. This dynamic control over telemetry helps in maintaining a balance between comprehensive monitoring and cost efficiency.</p> <p>By leveraging Dynamic Telemetry, businesses can not only optimize their logging practices but also enhance their overall observability and diagnostics. This approach ensures that resources are allocated effectively, reducing unnecessary expenditures and improving the bottom line.</p> <p></p>"},{"location":"docs/Scenarios.Overview.CostReduction.document/#convert-logs-into-metrics","title":"Convert Logs into Metrics","text":"<p>Converting logs into metrics is a powerful technique used in Dynamic Telemetry to optimize monitoring and reduce the overhead associated with storing and processing large volumes of log data. This process involves several key steps:</p> <ol> <li> <p>Log Collection: The first step is to collect logs from various sources    within the system. These logs contain detailed information about events and    operations occurring within the system.</p> </li> <li> <p>Log Filtering and Aggregation: Once the logs are collected, they are    filtered and aggregated to extract meaningful data. This is where the query    language processor comes into play. It integrates into the logging stream,    monitoring events by applying straightforward query language filtering and    aggregate functions. This helps in reducing the volume of data by focusing on    the most critical information.</p> </li> <li> <p>Metric Conversion: After filtering and aggregation, the relevant log data    can be converted into metrics.</p> </li> <li> <p>Metric Emission: The final step is to emit the metrics into your standard    and existing metrics solution / dashboard. These metrics provide a high-level    overview of the system's performance and can be used to track key performance    indicators (KPIs) and other important metrics.</p> </li> </ol> <p>By converting logs into metrics, you can gain valuable insights without the overhead of storing and processing large volumes of log data. This approach ensures that resources are allocated effectively, reducing unnecessary costs, improving search performance, and improving the bottom line.</p>"},{"location":"docs/Scenarios.Overview.CostReduction.document/#organize-chatty-diagnostic-logs-into-toggle-traces","title":"Organize Chatty Diagnostic Logs into Toggle Traces","text":"<p>Toggle Traces are perhaps one of the most interesting features of Dynamic Telemetry. Toggle traces refer to the ability to dynamically enable or disable specific tracing points within a system. This feature is particularly useful in scenarios where you need to control the verbosity of logging without redeploying or restarting the application. By dynamically toggling traces on and off, you can focus on capturing the most relevant data for diagnostics and performance monitoring, while suppressing unnecessary or \"chatty\" logs that can lead to increased storage and processing costs.</p> <p>The on/off switch doesn't have to be manually flipped; telemetry can be bundled into themes, and these themes can be toggled on/off based on system observation.</p> <p>In the context of Dynamic Telemetry, toggle traces allow you to:</p> <ol> <li> <p>Enable or Disable Tracing Points: You can turn on or off specific tracing    points based on the current diagnostic needs. This helps in reducing the    overhead associated with continuous logging.</p> </li> <li> <p>Control Log Verbosity: By toggling traces, you can adjust the level of    detail captured in the logs. This is useful for isolating issues without    being overwhelmed by excessive log data.</p> </li> <li> <p>Dynamic Adjustments: Toggle traces provide the flexibility to make    real-time adjustments to the logging configuration. This means you can    respond to issues as they arise without waiting for a new deployment cycle.</p> </li> </ol> <p>For example, if you notice that a particular component is generating too many logs, you can dynamically disable the tracing for that component. Conversely, if you need more detailed information about a specific operation, you can enable additional tracing points to capture that data.</p> <p>This approach ensures that you have the right balance between comprehensive monitoring and cost efficiency, allowing you to maintain optimal system performance while still gathering the necessary diagnostic information.</p>"},{"location":"docs/Scenarios.Overview.CostReduction.document/#drop-chatty-unused-logs","title":"Drop Chatty / Unused Logs","text":"<p>Not all telemetry data remains valuable over time. Chatty telemetry, which refers to excessive and often redundant logging, can become a burden rather than a benefit. Initially, this type of telemetry might have been useful for diagnosing issues and understanding system behavior, but as the system evolves, the relevance of such detailed logs can diminish.</p> <p>Dropping chatty telemetry that once was useful but now is not can lead to significant improvements in system performance and cost efficiency. By eliminating unnecessary logs, organizations can reduce the storage and processing overhead associated with handling large volumes of data. This not only frees up resources but also enhances the overall observability and diagnostics of the system. With fewer logs to sift through, it becomes easier to focus on the most critical data points, leading to more effective monitoring and quicker issue resolution.</p> <p>Moreover, the dynamic control over telemetry allows for a more flexible and responsive approach to system monitoring. By selectively enabling or disabling specific tracing points, businesses can maintain a balance between comprehensive monitoring and cost efficiency. This approach ensures that only the most relevant data is captured and analyzed, reducing the noise and improving the signal-to-noise ratio in the telemetry data. Ultimately, dropping chatty telemetry that is no longer useful helps in maintaining optimal system performance while still gathering the necessary diagnostic information1.</p>"},{"location":"docs/Scenarios.Overview.CostReduction.document/#removing-scarcity","title":"Removing Scarcity","text":"<p>The fear of not having enough telemetry can be a significant source of anxiety for engineers and administrators. Telemetry data is crucial for understanding the health and performance of a system, and the absence of sufficient data can lead to a feeling of uncertainty and worry. This fear often stems from the concern that without adequate telemetry, it may be challenging to identify and resolve issues promptly, potentially leading to system downtime or degraded performance.</p> <p>Safe deployment practices, such as deploying software in rings gradually over time, can inadvertently exacerbate this anxiety. While these practices are designed to minimize the risk of widespread issues by releasing updates to a small subset of users before a broader rollout, they can also heighten the fear of missing critical telemetry during the initial deployment phases. This incremental approach may compel engineers to enable extensive logging to capture every possible issue that might arise in the early rings, fearing that any gap in data could lead to undetected problems. Consequently, the drive to ensure comprehensive monitoring in these controlled environments can result in an overwhelming volume of log data, compounding the challenges of managing and analyzing telemetry effectively.</p> <p>This anxiety can drive individuals to overvalue individual logs, believing that every piece of log data is critical for diagnostics. As a result, there is a tendency to collect and retain vast volumes of log data, regardless of its relevance or usefulness. This approach, while well-intentioned, can lead to several negative consequences. The sheer volume of logs can become overwhelming, making it difficult to sift through the data to find meaningful insights. Additionally, the storage and processing of excessive log data can incur significant costs, both in terms of infrastructure and operational overhead.</p> <p>Moreover, the overemphasis on individual logs can detract from a more strategic approach to telemetry. Instead of focusing on the most relevant and actionable data, the emphasis on quantity over quality can lead to inefficiencies and missed opportunities for optimization. By prioritizing the collection of high-value telemetry and leveraging tools like Dynamic Telemetry to convert logs into metrics and suppress chatty telemetry, organizations can achieve a more balanced and cost-effective approach to system diagnostics.</p> <p>In conclusion, while the fear of insufficient telemetry is understandable, it is essential to adopt a measured and strategic approach to data collection. By focusing on the most critical data points and utilizing advanced telemetry tools, organizations can mitigate the risks associated with inadequate telemetry while avoiding the pitfalls of excessive log collection.</p>"},{"location":"docs/Scenarios.Overview.DeepDiagnostics.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.Overview.DeepDiagnostics.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.Overview.DeepDiagnostics.document/#deep-diagnostics-at-scale","title":"Deep Diagnostics, at Scale","text":"<p>With static telemetry, you often depend on luck, intuition, a large budget, or an oracle because your logging decisions are fixed after deployment. We've all been there, you're writing a tricky function and have to decide if adding a few extra logging messages is wise. On one hand, the more logs, the easier debugging; on the other hand, the logs accumulate, slowing down databases, costing money, and increasing security and privacy profiles for you and your users.</p> <p>The complexity compounds in cases where the software cannot be easily cycled or where bugs are particularly elusive.</p> <p>Dynamic Telemetry, provides middle ground; it offers the ability to dynamically toggle telemetry, either manually or programmatically.</p> <p>As you start using and learning Dynamic Telemetry, you'll discover how to gamify debugging by dynamically collecting memory, toggling logs, and employing other techniques to effectively trap and diagnose bugs.</p>"},{"location":"docs/Scenarios.Overview.DeepDiagnostics.document/#introducing-your-tools-processors-probes-and-actions","title":"Introducing your Tools : Processors, Probes, and Actions","text":"<p>In Dynamic Telemetry, Processors, Probes, and Actions play crucial roles in monitoring and diagnosing system behavior.</p> <p>The most important concept, if you can only understand one, is the Processor.</p> <p>Think of the Processor as a virtual machine that sits in the middle of all OpenTelemetry logs. It \"sees\" all the logs and, based on what it's seeing, can perform various actions. For example, it might \"see\" a queue getting really long and capture a memory dump, or it might \"see\" connections per second dropping and start a CPU sample.</p> <p>Probes are simply \"something\" that emits into OpenTelemetry in a streaming way. This could be the simple case of logging, but through the use of adapters, can be other technologies like syslog, ETW, user_events, or even more dynamic emitters like kprobes, uprobes, eBPF, or dtrace.</p> <p>Actions, on the other hand, initiate specific operations. While they are designed to avoid altering the system state intentionally, they can be dynamically enabled or disabled. Typical actions might include enabling CPU sampling, collecting configurations, managing flight recorders, inducing memory dumps, and gathering other types of state data.</p> <p>When combined, Probes and Actions create a powerful mechanism to \"cast nets\" that catch bugs.</p> <p></p>"},{"location":"docs/Scenarios.Overview.DeepDiagnostics.document/#simple-example-dialing-up-loggingdiagnostics-when-something-goes-wrong","title":"Simple Example : dialing up Logging/Diagnostics when something goes wrong","text":"<p>For example, consider a situation where a production system works well during testing and under light load but experiences unexpectedly high CPU contention from time to time. Developers have many theories, and little data -- they suspect the machine could be entering receive livelock but are unsure why.</p> <p>If they could predict which computer would next exhibit the problem, they could turn on CPU sampling when the issue occurs. The challenge is that once the problem arises, it is resolved before they're able to:</p> <ul> <li> <p>Collect a memory dump to inspect work queues</p> </li> <li> <p>Enable CPU sampling to determine which code is heavily utilized,</p> </li> <li> <p>Enable verbose diagnostic traces.</p> </li> </ul> <p>By using Dynamic Telemetry effectively, teams can proactively manage and resolve such issues, improving overall system stability and performance.</p>"},{"location":"docs/Scenarios.Overview.DeepDiagnostics.document/#casting-nets","title":"Casting 'Nets'","text":"<p>The Diagnostic Telemetry solution to this class of problem involves casting broad 'nets' on multiple machines expected to encounter this situation. Each net is very lightweight, with negligible performance or reliability concerns.</p> <p>These nets are simply configurations for a Dynamic Telemetry Processor that remain mostly dormant, monitoring selected logging values while waiting for a triggering condition. Once a triggered, an \"Action\" is called; which in turn provides the desired diagnostic information necessary for a root cause.</p>"},{"location":"docs/Scenarios.Overview.DeepDiagnostics.document/#an-example","title":"An Example","text":"<p>By configuring the Processor to dynamically monitor these log messages, it can track the queue depth in real-time. If the queue length exceeds predefined criteria set in the Processor's configuration, the Processor can initiate various diagnostic actions such as capturing a memory dump, enabling CPU sampling, or activating more verbose logging. This dynamic monitoring allows for proactive detection and response to potential issues, ensuring abnormalities are promptly addressed, thereby maintaining system stability and performance.</p> <p>Probes are deployed to monitor specific aspects of the system and emit data when certain conditions are met. For example, a probe might monitor the return value of a particular function or track the occurrence of specific events. When a probe detects something noteworthy, it can trigger an action. This action may involve collecting additional data, enabling more detailed logging, or capturing a memory dump.</p> <p>By dynamically enabling and disabling probes and actions, you can create a flexible and responsive system that adapts to changing conditions and captures valuable diagnostic information when needed.</p> <pre><code>public void ProcessWorkQueue()\n{\n    for (; ; )\n    {\n        m_workItemReadySemaphore.WaitOne();\n        Work myWork;\n        lock (m_lock)\n        {\n            myWork = m_WorkQueue.Dequeue();\n            LogDequeueWork(m_logger, m_WorkQueue.Count);\n        }\n        myWork.DoWork();\n    }\n}\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Dequeue depth={depth}\")]\nstatic partial void LogDequeueWork(ILogger logger, int depth);\n\n[LoggerMessage(Level = LogLevel.Information, Message = \"Enqueue depth={depth}\")]\nstatic partial void LogEnqueueWork(ILogger logger, int depth);\n</code></pre>"},{"location":"docs/Scenarios.Overview.DurableDashboards.Alerts.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.Overview.DurableDashboards.Alerts.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.Overview.DurableDashboards.Alerts.document/#improving-communication-and-data-durability","title":"Improving Communication and Data Durability","text":"<p>Communicating between different personas within a project can be challenging due to varying perspectives, priorities, and levels of technical understanding. For instance, a developer might focus on the intricacies of code and system performance, while a project manager might prioritize timelines and deliverables. This disparity can lead to misunderstandings and misaligned expectations. Additionally, without a common framework or language, conveying complex technical issues to non-technical stakeholders can be particularly difficult. This communication gap can hinder the effective collaboration necessary for the successful completion of a project.</p> <p>While overly strict and managed payload schemas can enhance communication by providing clear and consistent data structures, they often introduce what is perceived as undue management friction. Strict schemas ensure that all team members, regardless of their technical background, are on the same page, thereby reducing misunderstandings and facilitating smoother collaboration. However, the rigidity of these schemas can also stifle innovation and adaptability, as developers may find themselves constrained by the need to adhere to predefined data structures. This can lead to increased time spent on management and compliance, rather than focusing on creative problem-solving and rapid iteration. As a result, while strict schemas contribute to clearer communication, they can also slow down the development process and create frustration among team members who feel restricted by the lack of flexibility.</p> <p>Maintaining the end-to-end durability of dashboards and alerts becomes even more complex when there are no predefined data schemas. Without schemas, data can be inconsistent and unpredictable, making it difficult to ensure that dashboards and alerts are accurate and reliable. This lack of structure can lead to significant challenges in data integration, validation, and transformation processes. Consequently, teams may struggle to maintain the integrity and consistency of the data, which is crucial for making informed decisions and taking timely actions.</p> <p>Durable IDs offer a solution to some of these challenges by providing a consistent and reliable way to locate specific lines of code or data points. Much like a GPS system, durable IDs allow developers to pinpoint the exact location of an issue within the codebase, facilitating quicker and more accurate debugging and troubleshooting. This precision is invaluable in complex systems where even minor errors can have significant repercussions. By using durable IDs, teams can ensure that they are addressing the correct issues without the risk of misidentification or oversight.</p> <p>Structured payloads, on the other hand, can provide loose schemas that offer a balance between flexibility and consistency. These payloads allow for the inclusion of various data types and structures while maintaining a level of standardization that facilitates data processing and analysis. This approach enables teams to adapt to changing requirements and data sources without compromising the overall integrity and usability of the data.</p> <p>Dynamic Telemetry log schemas introduce an innovative approach to system monitoring and diagnostics. Unlike static telemetry, which relies on predefined data points and structures, Dynamic Telemetry allows for the real-time adjustment and customization of log schemas based on the current needs and conditions of the system. This flexibility enables more precise and context-aware data collection, providing deeper insights into system behavior and performance. By leveraging dynamic telemetry, teams can enhance their observability and diagnostic capabilities, leading to more effective monitoring, quicker issue resolution, and overall improved system reliability.</p>"},{"location":"docs/Scenarios.Overview.RedactingSecrets.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.Overview.RedactingSecrets.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.Overview.RedactingSecrets.document/#improving-your-security-and-privacy-posture","title":"Improving Your Security and Privacy Posture","text":"<p>Dropping or redacting portions of a log involves selectively removing or obscuring specific data within log entries to protect sensitive information or reduce noise. This practice is crucial for maintaining privacy and security, as logs often contain personal or confidential data such as email addresses, credit card numbers, or API keys. Additionally, dropping unnecessary log entries helps in managing log storage efficiently and ensures that only relevant data is retained for analysis. This process can be automated using tools and scripts that identify and redact sensitive data patterns, ensuring that logs remain useful for monitoring and troubleshooting without compromising security</p>"},{"location":"docs/Scenarios.Overview.RedactingSecrets.document/#technical-backbone-of-secret-redaction","title":"Technical Backbone of Secret Redaction","text":"<p>Redacting portions of logs using durable IDs and structured payloads involves several technical steps to ensure that sensitive information is effectively removed while maintaining the integrity and usability of the logs.</p> <p>Durable IDs are unique identifiers that remain consistent across different log entries and sessions. They act like a GPS for debugging and analysis, allowing you to trace logs back to the exact line of code in the source. This consistency is crucial for accurately identifying and redacting sensitive information without losing the context of the log entries.</p> <p>Structured payloads refer to the organization of log data into a well-defined format, possibly a binary format, or as JSON or XML. This structure makes it easier to identify and redact specific fields within the log entries. For example, instead of having a flat log message, a structured payload might separate different pieces of information into distinct fields, such asuser_id,transaction_id, andtimestamp. This separation allows for more precise redaction of sensitive data, such as email addresses or credit card numbers, without affecting other parts of the log.</p>"},{"location":"docs/Scenarios.Overview.RedactingSecrets.document/#redaction-process","title":"Redaction Process","text":"<p>The process typically involves the following steps:</p> <ol> <li> <p>Identification: Using durable IDs, the system identifies the specific log    entries that contain sensitive information.</p> </li> <li> <p>Redaction: The structured payloads are then parsed to locate the fields    that need to be redacted. This can be done using regex patterns or predefined    rules that match sensitive data types.</p> </li> <li> <p>Replacement: The sensitive data is replaced with a placeholder or removed    entirely. This ensures that the logs remain useful for analysis while    protecting sensitive information.</p> </li> <li> <p>Validation: The redacted logs are validated to ensure that the redaction    process did not introduce any errors or inconsistencies.</p> </li> </ol> <p>By combining durable IDs and structured payloads, organizations can achieve a more efficient and reliable redaction process, ensuring compliance with privacy regulations and reducing the risk of data breaches</p>"},{"location":"docs/Scenarios.Overview.RedactingSecrets.document/#methods-of-redacting-secrets","title":"Methods of Redacting Secrets","text":"<p>Should you find yourself in the unenviable position where your OpenTelemetry logs/traces contain secrets, or privacy information you face a complicated journey.</p> <p>First you have to fix the code, retest, redeploy, (potentially wait for a ringed deployment), and then go scrub your databases.</p> <p>Dynamic Telemetry offers no solution to database scrubbing, but it does offer solutions into scrubbing.  Several in fact!</p> <p>In broad strokes, the two most common are</p> <ol> <li>Dynamically Toggling Off Logs;  dropping an entire log row</li> <li>Payload Scrubbing;  scrubbing portions of a log</li> </ol>"},{"location":"docs/Scenarios.Overview.RedactingSecrets.document/#dynamically-toggle-off-logs","title":"Dynamically Toggle Off Logs","text":"<p>Dynamically turning off individual logs using core operating system features such asuser_events (Linux)or Event Tracing for Windows (ETW, on Windows) involves leveraging the inherent capabilities of these systems to manage logging efficiently. This method is particularly useful for high-performance applications where logging overhead needs to be minimized.</p> <p>**Event Tracing for Windows (ETW)**is a high-performance, low-overhead tracing framework built into the Windows operating system. It allows for the dynamic enabling and disabling of event tracing without requiring application or system restarts. ETW operates with minimal performance impact due to its efficient buffering and non-blocking logging mechanisms. It uses per-processor buffers that are written to disk by a separate thread, ensuring that logging does not interfere with the application's main operations1.</p> <p>user_eventsis a powerful feature built into the Linux kernel, that has some characteristics of ETW on Windows Dynamic Telemetry. It allows for the insertion of user-defined events into the standard Linux kernel mode logging streams, which can be enabled or disabled, in user mode, or keren mode - as needed. This flexibility is crucial for maintaining high performance, as it ensures that only relevant logs are captured, reducing unnecessary data collection and processing2.</p> <p>The process typically involves the following steps:</p> <ol> <li> <p>Initialization: Register the logging providers and define the events that    need to be traced. This can be done using ETW APIs or user-defined events.</p> </li> <li> <p>Dynamic Control: Use controllers to start, stop, or update the tracing    sessions. Controllers like Xperf, PerfView, or Logman can be used to manage    ETW sessions dynamically.</p> </li> <li> <p>Buffer Management: Utilize in-memory circular buffers to store log data    temporarily. This data is only written to disk or processed further if    specific conditions are met, such as an error occurring.</p> </li> <li> <p>Filtering and Aggregation: Apply filters to capture only the necessary    events and aggregate data to reduce the volume of logs. This can be done    using query language processors or state machine processors within Dynamic    Telemetry.</p> </li> <li> <p>Validation and Analysis: Validate the captured logs to ensure they are    accurate and useful for analysis. This step may involve converting verbose    logs into metrics for easier interpretation and reduced storage    requirements6.</p> </li> </ol> <p>By leveraging these fundamental operating system capabilities, you can achieve efficient and high-performance logging. This ensures that only critical data is captured and processed, thereby maintaining optimal system performance.</p>"},{"location":"docs/Scenarios.Overview.RedactingSecrets.document/#scrub-variable-payloads","title":"Scrub variable payloads","text":"<p>Scrubbing payloads can be performed in various locations within a system to ensure sensitive information is protected and compliance requirements are met.</p> <ol> <li>In the usermode portion of an app or agent, scrubbing can occur before data    is transmitted, ensuring that any sensitive information is removed or    obfuscated at the source.</li> <li>In the kernel mode memory buffer, scrubbing can be implemented to clean data    as it is being processed, providing an additional layer of security before it    reaches usermode components.</li> <li>The usermode aggregator and network transmitter can also perform scrubbing to    ensure that aggregated data sent to backend systems is free of sensitive    information.</li> <li>In the backend, scrubbing can be done at a. the point of ingest, where data    is first received and processed, or b. within the database, where stored data    is periodically reviewed and cleaned to maintain data integrity and security.</li> </ol> <p>Each of these locations offers unique advantages and challenges, and the choice of where to implement scrubbing depends on the specific requirements and constraints of the system.</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.Overview.Reliability.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#reliability","title":"Reliability","text":"<p>After you apply some thinking into probing an action aspects of dynamic telemetry you may come to realize that using these facilities provide an interesting technique into the testing and hardening your Production systems.</p> <p>Traditional testing requires decoupling of the software from into smaller pieces each of which are tested independently, often adding unit tests to orchestrate. Is this complexity of the software grows unit tests remain useful but often struggle to detect integration type failures.</p> <p>To cope with this many developers will start using scenario testing which blends together different architectural components into one logical set which is then tested as a entire scenario. Should the scenario fail the developer will start zooming in on the area that failed and from there they will look into the logging of the subsystem looking for root cause.</p> <p>The systems aren't bad, but a problem emerges as the complexity of this system grows, espeically when multiple machines participate in one of the scenarios. As the complexity grows many developers simply get frustrated and in some ways give up.</p> <p>Dynamic Telemetry introduces an interesting set of capabilities that result in a interesting hybrid between scenario and unit tests.</p> <p>The idea is to to use the logging and metrics found within a piece of software to self describe desired and expected behavior such that the product itself could detect its own failures.</p> <p>Processors are then configured to \"look\" for problems, that emanate from the very core of the software executing.</p> <p>In itself this is not a novel or new concept in fact entire books have been written on the subject.</p> <p>What is interesting, and potentially is novel, is the idea of using a combination of one box in process/on box and off box observers to this lightly schematized telemetry to look for patterns and failures that wouldn't be necessarily caught within a unit test or scenario test.</p> <p>This is especially true as a systems complexity grows into stress testing or penetration testing where network fuzzing or payload fuzzing has been enabled.</p> <p>The remainder of this section will discuss a few different ways of thinking about testing such that your code self describes, and detects problems - and automatically generates verbose diagnostics for you, to help you fix the problem.</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#quick-thought-experiment","title":"Quick Thought Experiment","text":"<p>Imagine your software has the ability to self-described failure. Perhaps when you author a enqueue() operation you also supply nominal expectations (for example, that no item sticks in the queue more than 200 ms).</p> <p>Should the completion take longer than 200 milliseconds this would indicate a warning, that perhaps not fatal, might indicate the need for a programmer to inspect and figure out why.</p> <p>The Processor portion of Dynamic Telemetry permit a developer to craft little traps for their bugs;  you cna easily imagine using a loose schema that describes certain logs and what good and bad looks like!</p> <p>This concept of self describing operational state is extremely interesting when a when coupled with dynamic configuration in the telemetry system, because opportunity is created for these values to be trained into the system instead of programmed in. It's not tough to see applications in AI.</p> <p>These concepts will be expanded in further sections but they're worth thought.</p> <p>With Dynamic Telemetry, your test assets are broken into five themes</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#testing-themes","title":"Testing Themes","text":"<ol> <li>Failure depends on the environment;</li> <li>Self-describing Production Code</li> <li>Internal Auditing of Production Code</li> <li>External Auditing of Production Code</li> <li>Diagnostic Collection</li> </ol>"},{"location":"docs/Scenarios.Overview.Reliability.document/#failure-depends-on-the-environment","title":"Failure depends on the environment","text":"<p>After careful consideration of using the telemetry system as a means of inner processor remote communication, it becomes evident that such a system can signal an external test when a failure occurs. This realization allows developers to write code that is easy to diagnose. The code itself aims to assist in detecting bugs, and the operational environment, through Dynamic Telemetry, supports both the programmer and the program in this endeavor.</p> <p>We will introduce two key concepts that are elaborated upon further in the documentation and are essential for comprehensive understanding. These concepts are probes and actions. A probe, in its simplest form, is nothing more than a log or metric emitted by a piece of code, for example, when a file is opened. The log may include the file name and the return code from the open system call.</p> <p>An action is part of a dynamically deployed processor that monitors the operational characteristics of the system either internally within the process, externally on the same computer, or even remotely from a backend. The action listens to logging and metrics as they are generated. When a particular log or metric with a specific failure code of interest is emitted, the action can trigger rich diagnostic collections, which may include a memory dump, a CPU sample, or could enable the collection of more verbose logs.</p> <p>At this point, you may be considering innovative ways to utilize these capabilities. For instance, you could establish a queue with an external observer that initiates a failure indicator if the queue becomes completely empty or exceeds a predetermined limit. You might be wondering what this preset number should be. It is important to note that Dynamic Telemetry does not specify these details; instead, it provides the fundamental constructs necessary to build such objects.</p> <p>One could envision a queue object where, upon initialization, diagnostic configurations are provided by the developer that include the minimum and maximum expected lengths of the queue. Perhaps this queue contains an expected flow rate. You can quickly imagine how an internal external observer could initiate diagnostic collections should any of these parameters we operating outside of specification.</p> <p>Experienced programmers may understandably become concerned about the accuracy of hardcoded values. Consider a scenario where a queue is designed for specific hardware, but over time, as hardware evolves and becomes faster, the queue links could either expand or contract accordingly. Additionally, queue depths might fluctuate based on varying usage patterns throughout the day across different regions.</p> <p>The apprehension of such programmers is justified. However, the concept of Dynamic Telemetry addresses these concerns by allowing programmers to specify nominal values during the initial setup on the expected hardware. In cases where these initial guesses are incorrect, dynamic telemetry supports a training process that measures and adjusts these values based on the new hardware or environment being utilized.</p> <p>...in short, the hardcoded values are reasonable guesses; the real values will be specified during operational training, on real hardware, with real workloads.</p> <p>... if this is interesting, now imagine you have different environments where the same code is executing, each having different configurations for failure attached - for instance, in a unit testing environment, one set of configurations is applied. In contrast, a different configuration set is used for scenario testing, and yet another set for stress or fuzz testing.</p> <p>Later in this section, we will further elaborate and provide detailed examples.</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#self-describing-production-code","title":"Self-describing Production Code","text":"<p>Dynamic Telemetry takes advantage of the durable identifiers and structure payloads within your logging in order to provide loose schemas that can be used in self-describing quality characteristics of code. While these topics are discussed further in other sections, the key aspect can be summarized as Lightweight telemetry that signals positive failure, or can otherwise indicate operational characteristics</p> <p>Read more: Self Describing Production Code</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#internal-auditing-of-production-code","title":"Internal Auditing of Production Code","text":"<p>An internal audit production code involves creating classifications of errors that adhere to strict definitions, unlike the flexible classifications often found in other logging and telemetry systems. Specifically, this means that an error must clearly describe something exceptional that is not permitted. Every identified error requires investigation until resolved.</p> <p>For instance, the failure to open a key database file is an example of an error worth investigating, whereas the failure to open a user file may not be considered a failure. The distinction may seem subtle but is significant. For example, in a library that processes files, treating the failure to open a file as an error might be inappropriate. This type of failure might be flagged as a warning, whereas higher layers might treat it as a critical error, such as with a database.</p> <p>Read more: Internal Audits of Production Code</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#external-auditing-of-production-code","title":"External Auditing of Production Code","text":"<p>An external audit of the code introduces environmental characteristics to the code. For example, what might be a programmatic warning internal to the code could be treated as an error by an external observer.</p> <p>This is where the power of Dynamic Telemetry can be found. This power allows for the training of nominal operating characteristics for a particular environment on specific hardware. The external observer should be viewed as an advocate for the user within the operational environment.</p> <p>Imagine code in a unit test environment treating particular failures with extreme strictness; perhaps any file error is treated as an error worth investigating. However, as the code migrates from unit testing to scenario testing, the threshold for an investigated failure may shift.</p> <p>As the code enters the stress environment, the opposite characteristics may be applied. For instance, the inability to open a file may no longer be treated as an error but rather as a success.</p> <p>In all cases, however, failures encountered during fuzz testing are consistently regarded as errors worthy of further study.</p> <p>The ability to redefine what is a error worth investigating at runtime without recompilation is a key value of Dynamic Telemetry.</p> <p>Read more: External Audits of Production Code</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#diagnostic-collection","title":"Diagnostic Collection","text":"<p>Diagnostic collection essentially involves gathering the content that programmers or operational teams deem necessary for diagnosing system failures. Dynamic Telemetry defines an error as an issue requiring investigation, therefore providing clear guidance, and total clarity of expectation, on the subsequent steps and specifying what needs to be collected.</p> <ol> <li>Should an internal external test fail</li> <li>Collect what the developer said they need</li> </ol> <p>It cannot get simpler. Best of all, with Dynamic Telemetry, the cost of mistakes is low. Clear expectations do not guarantee unique logs, memory dumps, or CPU traces when issues arise. Different personas, such as the operational team or program management team, also set equally clear expectations.</p> <p>These balances are explored more deeply in the diagnostic collection sections. In short though; simply because a developer clearly requests a memory dump for minor issues or seek extensive CPU sampling, they may not get what they want -- because their operational team set equally clear guidance on topics like memory, disk, and CPU usage.</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#thought-provoking-ideas","title":"Thought Provoking Ideas","text":""},{"location":"docs/Scenarios.Overview.Reliability.document/#entropy-creators","title":"Entropy Creators","text":"<p>As you explore using telemetry to pass and fail tests, and consider different layers of testing as your code's execution environment changes, it becomes clear how crucial unit testing, stress testing, and scenario testing are. This method offers a powerful solution to many complex software issues by defining the characteristics you want to verify through tests that are dynamically attached to the software as external observers.</p> <p>Once these tests are attached as observers, they can be monitored from various points. At this stage, the test engineer needs to design tests that introduce enough entropy into the system to determine if the test passes or fails. This testing approach is quite fascinating and aligns with some philosophical principles in unit testing, deserving further consideration.</p> <p>Read More: Testing With Entropy</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#appropriate-alerts","title":"Appropriate Alerts","text":"<p>This innovative approach ensures that every aspect of the software is continuously monitored, providing real-time insights and enabling proactive responses to potential issues. With Dynamic Telemetry, developers can achieve unparalleled levels of observability, making it easier than ever to maintain the reliability and performance of their systems. Embrace the future of testing with Dynamic Telemetry and experience the power of comprehensive, real-time system monitoring.</p> <p>Dynamic Telemetry addresses these challenges by integrating testing into the production code and leveraging both internal and external observations. This approach bridges the gap between multiple disciplines, allowing for singular functionality runs that encompass various testing methods. By doing so, Dynamic Telemetry provides a unified and efficient testing framework that enhances system reliability and performance.</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#traditional-testing-telemetry-analysis-and-informing","title":"Traditional \"Testing\" - Telemetry, Analysis, and Informing","text":"<p>Traditional testing often involves a series of predefined tests that are run in a controlled environment to ensure that the software behaves as expected. One crucial aspect of this process is emitting signals. Often these signals are the comfortable primitives taught in school - error codes, crashs, or thrown exceptions.</p> <p>By emitting these signals during testing, developers can monitor the system's performance and identify any anomalies or failures.</p> <p>Once the signals are emitted, the next step is studying the results. This involves analyzing the collected data to understand the system's behavior and identify any potential issues. The developer will use the simplified failures (error codes, crashes, or thrown exceptions) as indication that the software is not performing to specification, and will then open up log files and source code to figure out what happened.</p> <p>Finally, it's essential to inform the operator about the test results. This can be done through alerts or dashboards that provide real-time updates on the system's status. If a test case fails or a dashboard alert goes off, the operator can quickly take action to address the issue. This proactive approach helps prevent potential problems from escalating and ensures that the system remains stable and reliable. By incorporating these steps into the test pipeline, organizations can achieve a higher level of observability and maintain the quality of their software.</p>"},{"location":"docs/Scenarios.Overview.Reliability.document/#how-to-think-about-testing-in-a-world-of-dynamic-telemetry","title":"How to Think about Testing, in a world of Dynamic Telemetry","text":""},{"location":"docs/Scenarios.Overview.document/","title":"Scenarios.Overview.document","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Scenarios.Overview.document.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Scenarios.Overview.document/#overview-of-dynamic-telemetry-scenarios","title":"Overview of Dynamic Telemetry Scenarios","text":"<p>Dynamic Telemetry can be technically intimidating and challenging. This Scenario Driven section, aims to offer a usage vantage into this complex subject.</p> <p>This Scenario section will cover various scenarios commonly used by different personas to achieve business or technical results.We will discuss several key scenario groupings in future sections, starting with the essential ones.</p> <ol> <li> <p>Reducing costs while selectively enabling or disabling telemetry dynamically    without deployments.</p> </li> <li> <p>Analyzing and evaluating the performance characteristics of software    components, including edge cases.</p> </li> <li> <p>Enhancements in security and privacy by swiftly detecting and redacting log    telemetry or fields that may unintentionally contain sensitive information.</p> </li> <li> <p>Deep diagnostics of software issues, including debugging and performance    failures.</p> </li> <li> <p>Improving software reliability through clear failure schemas, problem    detection, and AB feature selection.</p> </li> <li> <p>Creating, maintaining, and extending durable dashboards and alerts using    telemetry to ensure architectural flexibility as database and reporting    technologies evolve.</p> </li> <li> <p>Adapting to and migrating hosting environments -- perhaps by converting large    macro services into microservices or aggregating microservices and libraries</p> </li> </ol>"},{"location":"docs/Slides.Overview.Presentation/","title":"Overview","text":"Dynamic Telemetry is a PROPOSAL : please provide feedback! :-) <p>Dynamic Telemetry is not an implementation, it's a request for collaboration,  that will lead to an shared understanding, and hopefully one or more implementations.</p> <p>Your feedback and suggestions on this document are highly encouraged!</p> <p>Please:</p> <ol> <li> <p>Open this Git Hub Pull Request</p> </li> <li> <p>Locate this file ( docs/Slides.Overview.Presentation.md)</p> </li> <li> <p>Add Comments! :)</p> </li> </ol> <p>If you'd prefer to give us a PR</p> <pre><code>https://microsoft.github.io/DynamicTelemetry/\n</code></pre> <p>Learn about overall document status     here</p> <p></p>"},{"location":"docs/Slides.Overview.Presentation/#dynamic-telemetry","title":"Dynamic Telemetry","text":"<ol> <li>Stitched Together in a way that</li> </ol>"},{"location":"docs/Slides.Overview.Presentation/#previous-2-or-3-years","title":"Previous 2 or 3 years","text":"<ol> <li>Aligning our API surfaces, core tech</li> <li>Supporting changes made in .NET, OpenTelemetry, and the kernels of Windows    and Linux</li> <li>Industry / OSS Support</li> <li>Applications ranging from perf/security/cost reductions/AI</li> </ol>"},{"location":"docs/Slides.Overview.Presentation/#tldr-what-is-dynamic-telemetry","title":"TLDR; What is Dynamic Telemetry","text":"<ol> <li>Single Architecture</li> <li>That Connects bespoke telemetry / diagnostic tools</li> <li>Solving and Connecting</li> <li>'Golden Path' scenarios</li> <li>Performance and Diagnostics</li> <li>Security and Privacy</li> <li>Dashboard and Alert Durability</li> <li>Cost Reductions</li> <li>Creating Opportunities for AI</li> </ol>"},{"location":"docs/Slides.Overview.Presentation/#our-challenge","title":"Our Challenge","text":"<p>(each permutation, is often a whole new architecture requiring extensive refactoring)</p>"},{"location":"docs/Slides.Overview.Presentation/#our-opportunity","title":"Our Opportunity","text":"<ul> <li>Organize API's; Language, OS under OpenTelemetry</li> <li>Tackle the connections under 'Dynamic Telemetry'; using Scenarios as golden   paths</li> </ul>"},{"location":"docs/Slides.Overview.Presentation/#actions","title":"Actions","text":"<ul> <li>Seek 1P/3P (OSS) Community Agreement on Scenario Workflow; 'Golden Paths'</li> <li>Focus on architectural North Star (Probe, Action, Processors, DurableID's)</li> <li>Dynamic Telemetry vTeam creates aspirational samples</li> <li>As time permits, we collectively turn my Dynamic Telemetry samples, into   reality</li> </ul>"},{"location":"docs/Slides.Overview.Presentation/#why-durableids-and-structured-payloads-are-helpful","title":"Why DurableID's and structured payloads are helpful","text":"<ul> <li>Regular Expressions are fragile, confusing, and expensive</li> <li>Durable ID provides a sort of 'GPS' to find the file and line</li> <li>Structured Payloads allow easier reasoning over data</li> </ul>"},{"location":"docs/Slides.Overview.Presentation/#risks","title":"Risks","text":""},{"location":"docs/Slides.Overview.Presentation/#scenarios","title":"Scenarios","text":"<ul> <li>Performance and Diagnostics</li> <li>Security and Privacy</li> <li>Reliability</li> <li>Durable Dashboards and Alerts</li> <li>Cost Reduction</li> <li>Opportunities for AI</li> </ul>"},{"location":"docs/Slides.Overview.Presentation/#architecture","title":"Architecture","text":""},{"location":"docs/Slides.Overview.Presentation/#diagnostics-aka-touch-reduction","title":"Diagnostics (aka Touch Reduction)","text":"<ul> <li>DurableID's and Structured Payloads can be used to Trigger</li> <li>Memory Dumps, CPU samples, more verbose Logging</li> </ul>"},{"location":"docs/Slides.Overview.Presentation/#security-and-privacy","title":"Security and Privacy","text":"<ul> <li>in SFI/Azure we've had problems with embedded PATs, certs</li> <li>in GDPR/Client we've had problems with IP addresses, MAC/BSSID/SSID's</li> </ul>"},{"location":"docs/Slides.Overview.Presentation/#cost-reduction","title":"Cost Reduction","text":"<ul> <li>Logging is expensive</li> <li>Not all Logs are great or always needed</li> <li>Through positive identification</li> <li>we can toggle</li> <li>we can drop/modify</li> </ul>"},{"location":"docs/Slides.Overview.Presentation/#opens-up-new-opportunities-for-ai","title":"Opens up new Opportunities for AI","text":"<ul> <li>With Strings being CHEAP - more options</li> <li>Reduce Volume</li> <li>Reduce Costs</li> <li>Reduce Privacy / Security Exposure</li> </ul>"}]}